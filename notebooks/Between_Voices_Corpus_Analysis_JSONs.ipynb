{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bernardes7/Paredes/blob/main/notebooks/Between_Voices_Corpus_Analysis_from_JSONs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Environment Setup & Imports"
      ],
      "metadata": {
        "id": "daVdDfgK9sI3"
      },
      "id": "daVdDfgK9sI3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479cfb9b",
      "metadata": {
        "id": "479cfb9b"
      },
      "outputs": [],
      "source": [
        "!pip install dtaidistance\n",
        "%pip install EMD-signal\n",
        "!pip -q install gdown\n",
        "\n",
        "\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from PyEMD import EMD\n",
        "from dtaidistance import dtw\n",
        "from google.colab import drive\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Load Data (JSON)"
      ],
      "metadata": {
        "id": "R_yuw4LT98po"
      },
      "id": "R_yuw4LT98po"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Config: set your shared folder URL and local destination\n",
        "DRIVE_FOLDER_URL = 'https://drive.google.com/drive/folders/1aKt0FP2U8ONcRo0cXrrYDdiqnuM9YkrZ?usp=sharing'\n",
        "DEST_DIR = Path('/content/Results')\n",
        "DEST_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the shared folder into /content/Results\n",
        "!gdown --fuzzy --folder \"{DRIVE_FOLDER_URL}\" -O \"{DEST_DIR}\"\n",
        "\n",
        "# Find the actual downloaded folder (Drive folder name)\n",
        "downloaded_root = DEST_DIR\n",
        "\n",
        "print(f\"Downloaded into: {downloaded_root}\")\n",
        "\n",
        "# Helper: load all JSON files recursively\n",
        "def load_json_files(root_dir: Path):\n",
        "    all_data = []\n",
        "    json_paths = list(root_dir.rglob('*.json'))\n",
        "    if not json_paths:\n",
        "        print(f\"No JSON files found under {root_dir}\")\n",
        "    for jp in json_paths:\n",
        "        try:\n",
        "            with open(jp, 'r', encoding='utf-8') as f:\n",
        "                all_data.append(json.load(f))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding {jp}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {jp}: {e}\")\n",
        "    return all_data\n",
        "\n",
        "data = load_json_files(downloaded_root)\n",
        "\n",
        "print(f\"Loaded {len(data)} JSON objects.\")"
      ],
      "metadata": {
        "id": "VodbJKLYopNx"
      },
      "id": "VodbJKLYopNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Apply EMD"
      ],
      "metadata": {
        "id": "XxoaKdHMZLwA"
      },
      "id": "XxoaKdHMZLwA"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PyEMD import EMD\n",
        "import warnings\n",
        "\n",
        "# Feature configuration\n",
        "features_config_emd = [\n",
        "    ('rhythmic', ['tempo_deviations'], 'Tempo Deviation'),\n",
        "    ('rhythmic', ['voice_rhythmic_density'], 'Voice Rhythmic Density'),\n",
        "    ('rhythmic', ['guitars_rhythmic_density'], 'Guitars Rhythmic Density'),\n",
        "    ('dynamic', ['voice_loudness'], 'Voice Loudness'),\n",
        "    ('dynamic', ['guitars_loudness'], 'Guitars Loudness'),\n",
        "    ('harmonic', ['tonal_dissonance'], 'Tonal Dissonance'),\n",
        "    ('harmonic', ['tonal_dispersion'], 'Tonal Dispersion'),\n",
        "    ('melodic', ['voice_melodic_contour'], 'Melodic Voice Contour'),\n",
        "    ('melodic', ['guitars_harmonic_contour'], 'Harmonic Guitars Contour')\n",
        "]\n",
        "\n",
        "data_processed = []\n",
        "\n",
        "for row_idx, row in enumerate(data):\n",
        "    processed_row = {\n",
        "        'metadata': row.get('metadata', {}),\n",
        "        'features': {}\n",
        "    }\n",
        "\n",
        "    for domain, keys, label in features_config_emd:\n",
        "        if domain not in row:\n",
        "            warnings.warn(f\"Row {row_idx}: Domain '{domain}' not found.\")\n",
        "            continue\n",
        "\n",
        "        for key in keys:\n",
        "            if key not in row[domain]:\n",
        "                warnings.warn(f\"Row {row_idx}: Feature '{key}' not found in domain '{domain}'.\")\n",
        "                continue\n",
        "\n",
        "            values = row[domain].get(key, [])\n",
        "            if values and isinstance(values, list) and all(isinstance(v, (int, float)) for v in values):\n",
        "                signal = np.array(values)\n",
        "                if np.all(signal == signal[0]):  # Skip constant signals\n",
        "                    continue\n",
        "                try:\n",
        "                    emd = EMD()\n",
        "                    imfs = emd(signal)\n",
        "                    if imfs.shape[0] > 1:\n",
        "                        processed_signal = np.sum(imfs[2:], axis=0).tolist()\n",
        "                    else:\n",
        "                        processed_signal = signal.tolist()\n",
        "                    processed_row['features'][label] = processed_signal\n",
        "                except Exception as e:\n",
        "                    warnings.warn(f\"Row {row_idx}: EMD failed for '{label}' ({e}). Using original signal.\")\n",
        "                    processed_row['features'][label] = signal.tolist()\n",
        "            else:\n",
        "                warnings.warn(f\"Row {row_idx}: Invalid or empty values for feature '{key}' in domain '{domain}'.\")\n",
        "\n",
        "    data_processed.append(processed_row)"
      ],
      "metadata": {
        "id": "YMDDNsSeZKWK"
      },
      "id": "YMDDNsSeZKWK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Apply Loudness Masks"
      ],
      "metadata": {
        "id": "Aq36IWVfPEkf"
      },
      "id": "Aq36IWVfPEkf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loudness Masks for Voice and Guitars\n",
        "# Stored in the original raw 'data' as v_mark and g_mask\n",
        "\n",
        "loudness_threshold = -40\n",
        "\n",
        "for row in data:\n",
        "    # Get original loudness arrays\n",
        "    loudness_voice_orig = row.get('dynamic', {}).get('voice_loudness', [])\n",
        "    loudness_guitars_orig = row.get('dynamic', {}).get('guitars_loudness', [])\n",
        "\n",
        "    # Compute masks from original signals\n",
        "    voice_mask = [val >= loudness_threshold if val is not None else False for val in loudness_voice_orig]\n",
        "    guitar_mask = [val >= loudness_threshold if val is not None else False for val in loudness_guitars_orig]\n",
        "\n",
        "    # Store masks for later use (e.g., in row or separate dict)\n",
        "    row['dynamic']['v_mask'] = voice_mask\n",
        "    row['dynamic']['g_mask'] = guitar_mask\n",
        "\n",
        "print(\"Loudness masks computed and stored from original signals.\")\n",
        "\n",
        "\n",
        "for original_row, processed_row in zip(data, data_processed):\n",
        "    # Get masks from original data\n",
        "    voice_mask = original_row.get('dynamic', {}).get('v_mask', [])\n",
        "    guitar_mask = original_row.get('dynamic', {}).get('g_mask', [])\n",
        "\n",
        "    title = processed_row.get('metadata', {}).get('title', 'Unknown')\n",
        "    artist = processed_row.get('metadata', {}).get('artist', 'Unknown')\n",
        "\n",
        "    print(f\"\\n=== Applying Masks for Piece: {title} by {artist} ===\")\n",
        "\n",
        "    # Skip if both masks are empty\n",
        "    if not voice_mask and not guitar_mask:\n",
        "        print(\"⚠️ No masks available for this piece.\")\n",
        "        continue\n",
        "\n",
        "    for feature_name, values in processed_row['features'].items():\n",
        "        if isinstance(values, list) and values:  # Only process non-empty lists\n",
        "            masked_values = None\n",
        "\n",
        "            # Apply voice mask\n",
        "            if ('Voice' in feature_name or 'Vocals' in feature_name) and voice_mask and len(values) == len(voice_mask):\n",
        "                masked_values = [val if mask else np.nan for val, mask in zip(values, voice_mask)]\n",
        "\n",
        "            # Apply guitar mask\n",
        "            elif ('Guitars' in feature_name or 'Harmonic' in feature_name) and guitar_mask and len(values) == len(guitar_mask):\n",
        "                masked_values = [val if mask else np.nan for val, mask in zip(values, guitar_mask)]\n",
        "\n",
        "            # Update and print if masking applied\n",
        "            if masked_values is not None:\n",
        "                processed_row['features'][feature_name] = masked_values\n",
        "                print(f\"Feature: {feature_name} → masked values: {masked_values[:20]}{'...' if len(masked_values) > 20 else ''}\")"
      ],
      "metadata": {
        "id": "TfoKHBnWR9Wy"
      },
      "id": "TfoKHBnWR9Wy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_processed_song(data_processed, title):\n",
        "    title = title.lower()\n",
        "    for row in data_processed:\n",
        "        if title in row.get('metadata', {}).get('title', '').lower():\n",
        "            return row['features']\n",
        "    return None\n",
        "\n",
        "# Usage:\n",
        "features = get_processed_song(data_processed, \"Não Choro por me Deixares\")\n",
        "if features:\n",
        "    print(f\"\\n✅ Processed features for 'Não Choro por me Deixares':\")\n",
        "    for name, vals in features.items():\n",
        "        if isinstance(vals, list):\n",
        "            print(f\"{name}: length={len(vals)}, values={vals[:10]}{'...' if len(vals) > 10 else ''}\")\n",
        "else:\n",
        "    print(\"Song not found or no processed features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yACdp4hkeEv4",
        "outputId": "b2624220-ba65-42d6-df5b-fbed90a3be17"
      },
      "id": "yACdp4hkeEv4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Processed features for 'Não Choro por me Deixares':\n",
            "Tempo Deviation: length=114, values=[4.822848464881643, 4.774652474714926, 4.419294465274571, 3.8390889895376508, 3.1445364309609474, 2.4461371730012527, 1.8444827084240596, 1.4005289672297034, 1.165322988727219, 1.1899118122256485]...\n",
            "Voice Rhythmic Density: length=114, values=[nan, nan, nan, nan, nan, nan, nan, nan, 1.176625632824447, 1.1853332210780558]...\n",
            "Guitars Rhythmic Density: length=114, values=[4.453942197571792, 4.427195520200733, 4.406462377106016, 4.396288202831304, 4.401218431920264, 4.422655992044713, 4.449433783389079, 4.467242199265943, 4.461771632987887, 4.418712477867488]...\n",
            "Voice Loudness: length=114, values=[nan, nan, nan, nan, nan, nan, nan, nan, -45.48807951990585, -41.574990739502084]...\n",
            "Guitars Loudness: length=114, values=[-15.831148479395624, -15.818744212238206, -15.617814506194819, -15.409014456122318, -15.400950332688275, -15.692660674422536, -16.315562085382346, -17.140151163872225, -17.996694506758544, -18.735110956951402]...\n",
            "Tonal Dissonance: length=114, values=[0.7027691499795325, 0.7024366087128644, 0.6996800071681493, 0.695106598916021, 0.6895496296676796, 0.6838573565583279, 0.678898015311797, 0.6753945846464069, 0.6740299761731005, 0.6754871015028201]...\n",
            "Tonal Dispersion: length=114, values=[0.22010012192854328, 0.20595658974453745, 0.19579653853510204, 0.19158261960120462, 0.1943686137404342, 0.20157281973686578, 0.20970466587119552, 0.21536573595495972, 0.21552623592305445, 0.2079372278399749]...\n",
            "Melodic Voice Contour: length=114, values=[nan, nan, nan, nan, nan, nan, nan, nan, 76.02550366437522, 76.60741011252075]...\n",
            "Harmonic Guitars Contour: length=114, values=[74.08944648329998, 74.14068054978428, 74.19968514091416, 74.260184932642, 74.31507957054173, 74.35744380225242, 74.38035237541303, 74.37688003766259, 74.34010153664018, 74.26524304144459]...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Descriptive Statistics"
      ],
      "metadata": {
        "id": "dR1C4HS1-Q0y"
      },
      "id": "dR1C4HS1-Q0y"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "song_stats_raw = []\n",
        "\n",
        "for row in data:\n",
        "    title = row.get('metadata', {}).get('title', 'Unknown')\n",
        "    artist = row.get('metadata', {}).get('artist', 'Unknown Artist')\n",
        "    year = row.get('metadata', {}).get('project_year', None)\n",
        "\n",
        "    # Convert year to numeric or NaN\n",
        "    try:\n",
        "        year = int(year)\n",
        "    except (ValueError, TypeError):\n",
        "        year = np.nan\n",
        "\n",
        "    # Loop through features_config_emd (3 elements per tuple)\n",
        "    for feature_category, feature_key_path, feature_name in features_config_emd:\n",
        "        # Navigate nested dict without helper\n",
        "        nested_data = row.get(feature_category, {})\n",
        "        for key in feature_key_path:\n",
        "            nested_data = nested_data.get(key, {})\n",
        "\n",
        "        # Ensure it's a list of numeric values\n",
        "        feature_values_raw = nested_data if isinstance(nested_data, list) else []\n",
        "        numeric_values = [v for v in feature_values_raw if isinstance(v, (int, float)) and np.isfinite(v)]\n",
        "\n",
        "        if numeric_values:\n",
        "            song_stats_raw.append({\n",
        "                'title': title,\n",
        "                'artist': artist,\n",
        "                'year': year,\n",
        "                'feature': feature_name,\n",
        "                'mean': np.mean(numeric_values),\n",
        "                'std': np.std(numeric_values)\n",
        "            })\n",
        "\n",
        "# Build DataFrame if data exists\n",
        "if song_stats_raw:\n",
        "    df_song_stats_raw = pd.DataFrame(song_stats_raw)\n",
        "\n",
        "    # Combine mean and std into one column\n",
        "    df_song_stats_raw['mean_std'] = df_song_stats_raw.apply(\n",
        "        lambda row: f\"{row['mean']:.2f} ({row['std']:.2f})\", axis=1\n",
        "    )\n",
        "\n",
        "    # Pivot table\n",
        "    df_final_raw = df_song_stats_raw.pivot_table(\n",
        "        index=['title', 'artist', 'year'],\n",
        "        columns='feature',\n",
        "        values='mean_std',\n",
        "        aggfunc='first'\n",
        "    )\n",
        "\n",
        "    # Sort by year (NaN goes last)\n",
        "    df_final_raw = df_final_raw.reset_index().sort_values(by='year', na_position='last').set_index(['title', 'artist', 'year'])\n",
        "\n",
        "    display(df_final_raw)\n",
        "else:\n",
        "    print(\"No raw feature data available to calculate song statistics.\")"
      ],
      "metadata": {
        "id": "_Db5aTqK-kIb"
      },
      "id": "_Db5aTqK-kIb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Pearson Correlation"
      ],
      "metadata": {
        "id": "ujm-eGRZ7NIo"
      },
      "id": "ujm-eGRZ7NIo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort and group processed data by artist\n",
        "data_sorted_by_artist = sorted(data_processed, key=lambda x: x.get('metadata', {}).get('artist', 'Unknown Artist'))\n",
        "artist_groups = itertools.groupby(data_sorted_by_artist, key=lambda x: x.get('metadata', {}).get('artist', 'Unknown Artist'))\n",
        "\n",
        "global_matrices = []\n",
        "artist_correlation_matrices = [] # New list to store artist-level matrices\n",
        "\n",
        "for artist, pieces in artist_groups:\n",
        "    artist_pieces = list(pieces)\n",
        "    piece_correlation_matrices_artist = {}\n",
        "\n",
        "    for row in artist_pieces:\n",
        "        title = row.get('metadata', {}).get('title', 'Unknown')\n",
        "        features = row.get('features', {})\n",
        "\n",
        "        # Filter out masks and keep only numeric features\n",
        "        piece_data = {k: v for k, v in features.items()\n",
        "                      if isinstance(v, list) and k not in ['Voice Mask', 'Guitar Mask'] and len(v) > 0}\n",
        "\n",
        "        # Ensure all features have equal length\n",
        "        if len(piece_data) > 1:\n",
        "            lengths = {len(vals) for vals in piece_data.values()}\n",
        "            if len(lengths) == 1:  # All equal length\n",
        "                df_piece = pd.DataFrame(piece_data)\n",
        "\n",
        "                # Compute correlation\n",
        "                correlation_matrix = df_piece.corr(method='pearson')\n",
        "                piece_correlation_matrices_artist[title] = correlation_matrix\n",
        "                global_matrices.append(correlation_matrix) # These are the per-piece matrices\n",
        "\n",
        "                # Plot per-piece heatmap\n",
        "                plt.figure(figsize=(8, 6))\n",
        "                sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
        "                plt.title(f\"Correlation Matrix - {title} by {artist}\")\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(f\"⚠️ Skipping {title}: features have different lengths.\")\n",
        "\n",
        "    # Artist-level average absolute mean correlation matrix\n",
        "    if piece_correlation_matrices_artist:\n",
        "        stacked = np.stack([m.values for m in piece_correlation_matrices_artist.values()])\n",
        "        avg_abs_matrix = np.mean(np.abs(stacked), axis=0)\n",
        "        artist_matrix = pd.DataFrame(\n",
        "            avg_abs_matrix,\n",
        "            index=piece_correlation_matrices_artist[next(iter(piece_correlation_matrices_artist))].index,\n",
        "            columns=piece_correlation_matrices_artist[next(iter(piece_correlation_matrices_artist))].columns\n",
        "        )\n",
        "        artist_correlation_matrices.append((artist, artist_matrix)) # Store artist matrix with label\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(artist_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=0, vmax=1)\n",
        "        plt.title(f\"Average Absolute Correlation Matrix - {artist}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Global average absolute mean correlation matrix\n",
        "if global_matrices:\n",
        "    stacked_global = np.stack([m.values for m in global_matrices])\n",
        "    avg_abs_global = np.mean(np.abs(stacked_global), axis=0)\n",
        "    global_matrix = pd.DataFrame(\n",
        "        avg_abs_global,\n",
        "        index=global_matrices[0].index,\n",
        "        columns=global_matrices[0].columns\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(global_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=0, vmax=1)\n",
        "    plt.title(\"Global Average Absolute Correlation Matrix (All Pieces)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "pukCkcHH-QLw"
      },
      "id": "pukCkcHH-QLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Mutual Information"
      ],
      "metadata": {
        "id": "U_Khz76Itp73"
      },
      "id": "U_Khz76Itp73"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# Sort and group processed data by artist\n",
        "data_sorted_by_artist = sorted(data_processed, key=lambda x: x.get('metadata', {}).get('artist', 'Unknown Artist'))\n",
        "artist_groups = itertools.groupby(data_sorted_by_artist, key=lambda x: x.get('metadata', {}).get('artist', 'Unknown Artist'))\n",
        "\n",
        "global_mi_matrices = []\n",
        "\n",
        "for artist, pieces in artist_groups:\n",
        "    artist_pieces = list(pieces)\n",
        "    piece_mi_matrices_artist = {}\n",
        "\n",
        "    for row in artist_pieces:\n",
        "        title = row.get('metadata', {}).get('title', 'Unknown')\n",
        "        features = row.get('features', {})\n",
        "\n",
        "        # Filter out masks and keep only numeric features\n",
        "        piece_data = {k: v for k, v in features.items()\n",
        "                      if isinstance(v, list) and k not in ['Voice Mask', 'Guitar Mask'] and len(v) > 0}\n",
        "\n",
        "        # Ensure all features have equal length\n",
        "        if len(piece_data) > 1:\n",
        "            lengths = {len(vals) for vals in piece_data.values()}\n",
        "            if len(lengths) == 1:  # All equal length\n",
        "                df_piece = pd.DataFrame(piece_data)\n",
        "\n",
        "                # Initialize MI matrix\n",
        "                mi_matrix = pd.DataFrame(np.zeros((df_piece.shape[1], df_piece.shape[1])),\n",
        "                                         index=df_piece.columns,\n",
        "                                         columns=df_piece.columns)\n",
        "\n",
        "                # Compute Mutual Information for each pair\n",
        "                for i, col_i in enumerate(df_piece.columns):\n",
        "                    for j, col_j in enumerate(df_piece.columns):\n",
        "                        if i != j:\n",
        "                            valid_rows = df_piece[[col_i, col_j]].dropna()\n",
        "                            if valid_rows.shape[0] > 1:\n",
        "                                mi = mutual_info_regression(valid_rows[[col_i]], valid_rows[col_j], discrete_features=False)[0]\n",
        "                                mi_matrix.iloc[i, j] = mi\n",
        "\n",
        "                piece_mi_matrices_artist[title] = mi_matrix\n",
        "                global_mi_matrices.append(mi_matrix)\n",
        "\n",
        "                # Plot per-piece MI heatmap\n",
        "                plt.figure(figsize=(8, 6))\n",
        "                sns.heatmap(mi_matrix, annot=True, cmap='viridis', fmt=\".2f\")\n",
        "                plt.title(f\"Mutual Information Matrix - {title} by {artist}\")\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(f\"⚠️ Skipping {title}: features have different lengths.\")\n",
        "\n",
        "    # Artist-level median MI matrix\n",
        "    if piece_mi_matrices_artist:\n",
        "        stacked = np.stack([m.values for m in piece_mi_matrices_artist.values()])\n",
        "        median_matrix = np.median(stacked, axis=0)\n",
        "        artist_mi_matrix = pd.DataFrame(median_matrix,\n",
        "                                        index=piece_mi_matrices_artist[next(iter(piece_mi_matrices_artist))].index,\n",
        "                                        columns=piece_mi_matrices_artist[next(iter(piece_mi_matrices_artist))].columns)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(artist_mi_matrix, annot=True, cmap='viridis', fmt=\".2f\")\n",
        "        plt.title(f\"Median Mutual Information Matrix - {artist}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Global median MI matrix\n",
        "if global_mi_matrices:\n",
        "    stacked_global = np.stack([m.values for m in global_mi_matrices])\n",
        "    median_global = np.median(stacked_global, axis=0)\n",
        "    global_mi_matrix = pd.DataFrame(median_global,\n",
        "                                    index=global_mi_matrices[0].index,\n",
        "                                    columns=global_mi_matrices[0].columns)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(global_mi_matrix, annot=True, cmap='viridis', fmt=\".2f\")\n",
        "    plt.title(\"Global Median Mutual Information Matrix (All Pieces)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BgdPfibFr7TL"
      },
      "id": "BgdPfibFr7TL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) Phrase Clustering"
      ],
      "metadata": {
        "id": "OwHrvMPD-JJ6"
      },
      "id": "OwHrvMPD-JJ6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de9182e",
      "metadata": {
        "id": "6de9182e"
      },
      "outputs": [],
      "source": [
        "def get_nested_value(d, keys):\n",
        "    \"\"\"Safely retrieve nested values from a dictionary using a list of keys.\"\"\"\n",
        "    for key in keys:\n",
        "        if isinstance(d, dict):\n",
        "            d = d.get(key, {})\n",
        "        else:\n",
        "            return []\n",
        "    return d if isinstance(d, list) else []\n",
        "\n",
        "def analyze_feature(data, feature_category, feature_key_path, time_key, time_category):\n",
        "    phrase_data = []\n",
        "    for row in data:\n",
        "        title = row.get('metadata', {}).get('title', 'Unknown')\n",
        "        feature_values = get_nested_value(row.get(feature_category, {}), feature_key_path)\n",
        "        time_values = row.get(time_category, {}).get(time_key, [])\n",
        "        structural = row.get('structural', {})\n",
        "        phrase_labels = structural.get('phrase_labels', [])\n",
        "        phrase_times = structural.get('phrase_times', [])\n",
        "        phrase_durations = structural.get('phrase_durations', [])\n",
        "\n",
        "        if not (len(phrase_labels) == len(phrase_times) == len(phrase_durations)):\n",
        "            continue\n",
        "        if not (isinstance(time_values, list) and isinstance(feature_values, list)):\n",
        "            continue\n",
        "\n",
        "        for label, start, duration in zip(phrase_labels, phrase_times, phrase_durations):\n",
        "            end = start + duration\n",
        "            # Extract all values within the phrase's time window, including NaNs\n",
        "            segment_values = []\n",
        "            for t, v in zip(time_values, feature_values):\n",
        "                if start - 1e-9 <= t <= end + 1e-9:\n",
        "                    segment_values.append(v)\n",
        "\n",
        "            # Convert to numpy array for consistent handling later (e.g., NaN checks)\n",
        "            values_np = np.array(segment_values, dtype=float)\n",
        "            phrase_data.append({'title': title, 'phrase_label': label, 'values': values_np})\n",
        "\n",
        "    # Filter out entries where 'values' was empty after extraction (e.g., no time points matched)\n",
        "    df_phrases = pd.DataFrame([p for p in phrase_data if len(p['values']) > 0])\n",
        "    if df_phrases.empty:\n",
        "        print(f\"No valid phrase data found for {'/'.join(feature_key_path)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Determine max_len based on initial extracted sequence lengths\n",
        "    max_len = df_phrases['values'].apply(len).max()\n",
        "    if max_len == 0:\n",
        "        print(f\"Max length is 0 for {'/'.join(feature_key_path)}, returning empty DataFrame.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    def interpolate_and_smooth_and_normalize(sequences_of_np_arrays, target_length, sigma=1):\n",
        "        interpolated_smoothed_normalized = []\n",
        "        for seq_np in sequences_of_np_arrays: # seq_np is already a numpy array, potentially with NaNs\n",
        "            valid_count = np.count_nonzero(~np.isnan(seq_np))\n",
        "            total_count = len(seq_np)\n",
        "\n",
        "            # Handle empty sequences or sequences that are mostly NaNs (less than 80% valid)\n",
        "            if total_count == 0 or valid_count == 0 or (valid_count / total_count < 0.8 and total_count > 0):\n",
        "                interpolated_smoothed_normalized.append(np.zeros(target_length).tolist())\n",
        "                continue\n",
        "\n",
        "            # Step 1: Interpolate NaNs using pandas Series interpolate (handles leading/trailing NaNs)\n",
        "            interpolated_seq_pre_resample = seq_np.copy() # Make a copy to avoid modifying original array\n",
        "            if valid_count >= 2: # Need at least 2 non-NaN points for linear interpolation to work effectively\n",
        "                interpolated_seq_pre_resample = pd.Series(interpolated_seq_pre_resample).interpolate(method='linear', limit_direction='both').values\n",
        "                # If there are still NaNs (e.g., only one non-NaN point and limit_direction couldn't fill),\n",
        "                # fill remaining with the mean of non-NaN values or 0 if no valid points (should be caught by valid_count check)\n",
        "                if np.isnan(interpolated_seq_pre_resample).any():\n",
        "                    if valid_count > 0: # This case covers when valid_count >= 2 but interpolate couldn't fill all (e.g., all same value)\n",
        "                        fill_value = np.nanmean(interpolated_seq_pre_resample)\n",
        "                        interpolated_seq_pre_resample = np.nan_to_num(interpolated_seq_pre_resample, nan=fill_value)\n",
        "                    else:\n",
        "                        interpolated_seq_pre_resample = np.zeros_like(interpolated_seq_pre_resample)\n",
        "            elif valid_count == 1: # If only one valid point, fill the entire sequence with that point\n",
        "                interpolated_seq_pre_resample = np.full_like(seq_np, seq_np[~np.isnan(seq_np)][0])\n",
        "            # If valid_count is 0, it's handled by the earlier 'if' condition.\n",
        "\n",
        "\n",
        "            # Step 2: Resample, Smooth, and Normalize\n",
        "            if len(interpolated_seq_pre_resample) >= 2:\n",
        "                x_old = np.arange(len(interpolated_seq_pre_resample))\n",
        "                f_interp = interp1d(x_old, interpolated_seq_pre_resample, kind='linear', fill_value=\"extrapolate\")\n",
        "                x_new = np.linspace(0, len(interpolated_seq_pre_resample) - 1, target_length)\n",
        "                resampled_seq = f_interp(x_new)\n",
        "                smoothed = gaussian_filter1d(resampled_seq, sigma=sigma)\n",
        "\n",
        "                mean = np.mean(smoothed)\n",
        "                std = np.std(smoothed)\n",
        "                if std != 0:\n",
        "                    normalized = (smoothed - mean) / std\n",
        "                else:\n",
        "                    normalized = smoothed - mean # Center but don't scale if std is 0\n",
        "                interpolated_smoothed_normalized.append(normalized.tolist())\n",
        "            elif len(interpolated_seq_pre_resample) == 1:\n",
        "                # If after interpolation, there's effectively one point, normalize it to 0 and fill target_length\n",
        "                interpolated_smoothed_normalized.append(np.zeros(target_length).tolist()) # Center to 0 for a flat line\n",
        "            else: # Empty sequence after all steps (should be caught by previous conditions)\n",
        "                interpolated_smoothed_normalized.append(np.zeros(target_length).tolist())\n",
        "\n",
        "        return interpolated_smoothed_normalized\n",
        "\n",
        "\n",
        "    df_phrases['values'] = interpolate_and_smooth_and_normalize(df_phrases['values'].tolist(), max_len, sigma=1)\n",
        "    return df_phrases\n",
        "\n",
        "\n",
        "def plot_feature_clusters_cosine(df_feature, feature_name):\n",
        "    if df_feature.empty or 'values' not in df_feature.columns:\n",
        "        print(f\"Skipping {feature_name}: missing data.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Plotting dendrogram and clusters for {feature_name} (Cosine)...\")\n",
        "    sequences = df_feature['values'].tolist()\n",
        "    array_sequences = np.array(sequences)\n",
        "\n",
        "    if array_sequences.ndim != 2:\n",
        "        print(f\"Error: Expected 2D array for clustering, got shape {array_sequences.shape}\")\n",
        "        return\n",
        "\n",
        "    valid_indices = [i for i, seq in enumerate(array_sequences) if np.linalg.norm(seq) > 0]\n",
        "    if len(valid_indices) < 2:\n",
        "        print(f\"Skipping {feature_name}: not enough valid sequences for cosine distance.\")\n",
        "        return\n",
        "\n",
        "    array_sequences = array_sequences[valid_indices]\n",
        "    df_feature = df_feature.iloc[valid_indices].reset_index(drop=True)\n",
        "\n",
        "    distance_matrix = pdist(array_sequences, metric='cosine')\n",
        "    linked = linkage(distance_matrix, method='average')\n",
        "\n",
        "    heights = linked[:, 2]\n",
        "    height_diffs = np.diff(heights)\n",
        "    threshold = np.percentile(height_diffs, 98)\n",
        "    split_indices = np.where(height_diffs > threshold)[0]\n",
        "    estimated_clusters = len(array_sequences) - split_indices[0] if len(split_indices) > 0 else 5\n",
        "\n",
        "    clusters = fcluster(linked, t=estimated_clusters, criterion='maxclust')\n",
        "    df_feature['cluster'] = clusters\n",
        "\n",
        "    # Ajuste do color_threshold para corresponder ao número de clusters\n",
        "    if estimated_clusters < len(linked) + 1:\n",
        "        color_threshold = linked[-estimated_clusters + 1, 2]\n",
        "    else:\n",
        "        color_threshold = linked[-1, 2] + 1\n",
        "\n",
        "    combined_labels = [f\"{row['title']}_{row['phrase_label']}\" for index, row in df_feature.iterrows()]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.title(f\"Dendrogram - {feature_name} (Clusters: {estimated_clusters})\")\n",
        "    dendrogram(linked,\n",
        "               labels=combined_labels,\n",
        "               leaf_rotation=90,\n",
        "               leaf_font_size=7,\n",
        "               color_threshold=color_threshold)\n",
        "    plt.xlabel(\"Phrase Label\")\n",
        "    plt.ylabel(\"Cosine Distance\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot clusters com 10 ou mais sequências\n",
        "    for cluster_id in sorted(df_feature['cluster'].unique()):\n",
        "        cluster_df = df_feature[df_feature['cluster'] == cluster_id]\n",
        "        if len(cluster_df) < 10:\n",
        "            continue\n",
        "        cluster_sequences = cluster_df['values'].tolist()\n",
        "        cluster_cosine_distances = squareform(pdist(np.array(cluster_sequences), metric='cosine'))\n",
        "        total_distances = np.sum(cluster_cosine_distances, axis=1)\n",
        "        medoid_index = np.argmin(total_distances)\n",
        "        medoid_sequence = np.array(cluster_sequences[medoid_index])\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        for seq in cluster_sequences:\n",
        "            plt.plot(seq, color='lightgray', linewidth=0.5)\n",
        "        plt.plot(medoid_sequence, color='red', linewidth=2, label='Medoid')\n",
        "        plt.title(f\"{feature_name} - Cluster {cluster_id} (n={len(cluster_df)})\")\n",
        "        plt.xlabel(\"Interpolated Index\")\n",
        "        plt.ylabel(\"Feature Value (Normalized)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nSequences in {feature_name} - Cluster {cluster_id}:\")\n",
        "        for index, row in cluster_df.iterrows():\n",
        "            print(f\"- {row['title']}_{row['phrase_label']}\")\n",
        "\n",
        "\n",
        "def plot_feature_clusters_dtw(df_feature, feature_name):\n",
        "    if df_feature.empty or 'values' not in df_feature.columns:\n",
        "        print(f\"Skipping {feature_name}: missing data.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Plotting dendrogram and clusters for {feature_name} (DTW)...\")\n",
        "    sequences = df_feature['values'].tolist()\n",
        "    array_sequences = np.array(sequences)\n",
        "\n",
        "    if array_sequences.ndim != 2:\n",
        "        print(f\"Error: Expected 2D array for clustering, got shape {array_sequences.shape}\")\n",
        "        return\n",
        "    dtw_distances = np.zeros((len(sequences), len(sequences)))\n",
        "    for i in range(len(sequences)):\n",
        "        for j in range(i + 1, len(sequences)):\n",
        "            dist = dtw.distance(sequences[i], sequences[j])\n",
        "            dtw_distances[i, j] = dist\n",
        "            dtw_distances[j, i] = dist\n",
        "\n",
        "    linked = linkage(squareform(dtw_distances), method='average')\n",
        "\n",
        "    heights = linked[:, 2]\n",
        "    height_diffs = np.diff(heights)\n",
        "    threshold = np.percentile(height_diffs, 98)\n",
        "    split_indices = np.where(height_diffs > threshold)[0]\n",
        "    estimated_clusters = len(sequences) - split_indices[0] if len(split_indices) > 0 else 5\n",
        "\n",
        "    clusters = fcluster(linked, t=estimated_clusters, criterion='maxclust')\n",
        "    df_feature['cluster'] = clusters\n",
        "\n",
        "    # Ajuste do color_threshold para corresponder ao número de clusters\n",
        "    if estimated_clusters < len(linked) + 1:\n",
        "        color_threshold = linked[-estimated_clusters + 1, 2]\n",
        "    else:\n",
        "        color_threshold = linked[-1, 2] + 1\n",
        "\n",
        "    combined_labels = [f\"{row['title']}_{row['phrase_label']}\" for index, row in df_feature.iterrows()]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.title(f\"DTW Dendrogram - {feature_name} (Clusters: {estimated_clusters})\")\n",
        "    dendrogram(linked,\n",
        "               labels=combined_labels,\n",
        "               leaf_rotation=90,\n",
        "               leaf_font_size=7,\n",
        "               color_threshold=color_threshold)\n",
        "    plt.xlabel(\"Phrase Label\")\n",
        "    plt.ylabel(\"DTW Distance\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot clusters com 10 ou mais sequências\n",
        "    for cluster_id in sorted(df_feature['cluster'].unique()):\n",
        "        cluster_df = df_feature[df_feature['cluster'] == cluster_id]\n",
        "        if len(cluster_df) < 10:\n",
        "            continue\n",
        "        cluster_sequences = cluster_df['values'].tolist()\n",
        "        cluster_dtw_distances = np.zeros((len(cluster_sequences), len(cluster_sequences)))\n",
        "        for i in range(len(cluster_sequences)):\n",
        "            for j in range(i + 1, len(cluster_sequences)):\n",
        "                dist = dtw.distance(cluster_sequences[i], cluster_sequences[j])\n",
        "                cluster_dtw_distances[i, j] = dist\n",
        "                cluster_dtw_distances[j, i] = dist\n",
        "\n",
        "        total_distances = np.sum(cluster_dtw_distances, axis=1)\n",
        "        medoid_index = np.argmin(total_distances)\n",
        "        medoid_sequence = np.array(cluster_sequences[medoid_index])\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        for seq in cluster_sequences:\n",
        "            plt.plot(seq, color='lightgray', linewidth=0.5)\n",
        "        plt.plot(medoid_sequence, color='red', linewidth=2, label='Medoid')\n",
        "        plt.title(f\"{feature_name} - DTW Cluster {cluster_id} (n={len(cluster_df)})\")\n",
        "        plt.xlabel(\"Interpolated Index\")\n",
        "        plt.ylabel(\"Feature Value (Normalized)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nSequences in {feature_name} - DTW Cluster {cluster_id}:\")\n",
        "        for index, row in cluster_df.iterrows():\n",
        "            print(f\"- {row['title']}_{row['phrase_label']}\")\n",
        "\n",
        "method_selector = 'cosine'  # ou 'dtw'\n",
        "\n",
        "features_config = [\n",
        "    ('rhythmic', ['tempo_deviations'], 'beat_times', 'rhythmic', 'Tempo Deviations'),\n",
        "    ('rhythmic', ['guitars_rhythmic_density'], 'beat_times', 'rhythmic', 'Guitars Rhythmic Density'),\n",
        "    ('rhythmic', ['voice_rhythmic_density'], 'beat_times', 'rhythmic', 'Voice Rhythmic Density'),\n",
        "    ('melodic', ['voice_melodic_contour'], 'beat_times', 'rhythmic', 'Melodic Voice Contour'),\n",
        "    ('melodic', ['guitars_harmonic_contour'], 'beat_times', 'rhythmic', 'Harmonic Guitars Contour'),\n",
        "    ('dynamic', ['voice_loudness'], 'beat_times', 'rhythmic', 'Voice Loudness'),\n",
        "    ('dynamic', ['guitars_loudness'], 'beat_times', 'rhythmic', 'Guitars Loudness'),\n",
        "    ('harmonic', ['tonal_dissonance'], 'beat_times', 'rhythmic', 'Tonal Dissonance'),\n",
        "    ('harmonic', ['tonal_dispersion'], 'beat_times', 'rhythmic', 'Tonal Dispersion'),\n",
        "]\n",
        "\n",
        "feature_names = { '/'.join(config[1]): config[4] for config in features_config }\n",
        "\n",
        "results = {}\n",
        "for feature_category, feature_key_path, time_key, time_category, feature_name in features_config:\n",
        "    print(f\"Analyzing {feature_name}\")\n",
        "    results['/'.join(feature_key_path)] = analyze_feature(data, feature_category, feature_key_path, time_key, time_category)\n",
        "\n",
        "for feature_key, df_feature in results.items():\n",
        "    friendly_name = feature_names.get(feature_key, feature_key)\n",
        "    if method_selector == 'cosine':\n",
        "        plot_feature_clusters_cosine(df_feature, friendly_name)\n",
        "    elif method_selector == 'dtw':\n",
        "        plot_feature_clusters_dtw(df_feature, friendly_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMD plots\n"
      ],
      "metadata": {
        "id": "e0qu5o5-rw2g"
      },
      "id": "e0qu5o5-rw2g"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1760c80"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "from PyEMD import EMD\n",
        "\n",
        "# --- BEGIN MODIFICATION: Moved from cell 79_Yrn2ma15u ---\n",
        "# Ensure `data` and `data_processed` are available globally\n",
        "# Assuming `data` holds the original raw song objects and `data_processed` holds the EMD processed ones\n",
        "# If these variables are not present, this will raise an error.\n",
        "if 'data' not in globals() or not isinstance(data, list) or not data:\n",
        "    raise NameError(\"Global variable 'data' (raw song data) not found or is empty.\")\n",
        "if 'data_processed' not in globals() or not isinstance(data_processed, list) or not data_processed:\n",
        "    raise NameError(\"Global variable 'data_processed' (EMD data) not found or is empty.\")\n",
        "\n",
        "ALL_RAW_DATA = data\n",
        "ALL_EMD_DATA = data_processed\n",
        "\n",
        "# This list defines all features, their raw data paths, and EMD processed labels\n",
        "PARAM_INFO = [\n",
        "    {\"display_name\": \"Tempo Deviation\", \"raw_path\": \"rhythmic.tempo_deviations\", \"emd_label\": \"Tempo Deviation\"},\n",
        "    {\"display_name\": \"Voice Rhythmic Density\", \"raw_path\": \"rhythmic.voice_rhythmic_density\", \"emd_label\": \"Voice Rhythmic Density\"},\n",
        "    {\"display_name\": \"Guitars Rhythmic Density\", \"raw_path\": \"rhythmic.guitars_rhythmic_density\", \"emd_label\": \"Guitars Rhythmic Density\"},\n",
        "    {\"display_name\": \"Voice Loudness\", \"raw_path\": \"dynamic.voice_loudness\", \"emd_label\": \"Voice Loudness\"},\n",
        "    {\"display_name\": \"Guitars Loudness\", \"raw_path\": \"dynamic.guitars_loudness\", \"emd_label\": \"Guitars Loudness\"},\n",
        "    {\"display_name\": \"Tonal Dissonance\", \"raw_path\": \"harmonic.tonal_dissonance\", \"emd_label\": \"Tonal Dissonance\"},\n",
        "    {\"display_name\": \"Tonal Dispersion\", \"raw_path\": \"harmonic.tonal_dispersion\", \"emd_label\": \"Tonal Dispersion\"},\n",
        "    {\"display_name\": \"Melodic Voice Contour\", \"raw_path\": \"melodic.voice_melodic_contour\", \"emd_label\": \"Melodic Voice Contour\"},\n",
        "    {\"display_name\": \"Harmonic Guitars Contour\", \"raw_path\": \"melodic.guitars_harmonic_contour\", \"emd_label\": \"Harmonic Guitars Contour\"},\n",
        "]\n",
        "# --- END MODIFICATION ---\n",
        "\n",
        "# Ensure ALL_RAW_DATA and PARAM_INFO are available from previous cells\n",
        "# This check is now redundant as they are defined above\n",
        "# if 'ALL_RAW_DATA' not in globals() or not isinstance(ALL_RAW_DATA, list) or not ALL_RAW_DATA:\n",
        "#     raise NameError(\"Global variable 'ALL_RAW_DATA' not found or is empty. Please run previous cells.\")\n",
        "\n",
        "# if 'PARAM_INFO' not in globals() or not isinstance(PARAM_INFO, list) or not PARAM_INFO:\n",
        "#     raise NameError(\"Global variable 'PARAM_INFO' not found or is empty. Please run previous cells.\")\n",
        "\n",
        "# Re-using helper functions from the previous plotting widget (assuming they are in global scope)\n",
        "def to_float_array(v):\n",
        "    if v is None:\n",
        "        return None\n",
        "    try:\n",
        "        if hasattr(v, \"to_numpy\"):\n",
        "            arr = v.to_numpy(dtype=float)\n",
        "        else:\n",
        "            arr = np.asarray(v, dtype=float)\n",
        "    except Exception:\n",
        "        return None\n",
        "    if arr.ndim == 0:\n",
        "        arr = arr.reshape(1)\n",
        "    elif arr.ndim > 1:\n",
        "        arr = arr.squeeze()\n",
        "        if arr.ndim > 1:\n",
        "            arr = arr.ravel()\n",
        "    return arr\n",
        "\n",
        "def get_path(dct, path):\n",
        "    if dct is None or not isinstance(path, str) or not path:\n",
        "        return None\n",
        "    cur = dct\n",
        "    for part in path.split('.'):\n",
        "        if isinstance(cur, dict) and part in cur:\n",
        "            cur = cur.get(part)\n",
        "        else:\n",
        "            return None\n",
        "    return cur\n",
        "\n",
        "def _get_param_info_by_display_name(display_name):\n",
        "    for p in PARAM_INFO:\n",
        "        if p['display_name'] == display_name:\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def _get_feature_values_raw(song_obj, display_name):\n",
        "    # This function specifically gets raw data, ignoring EMD data source option\n",
        "    param_info = _get_param_info_by_display_name(display_name)\n",
        "    if not param_info:\n",
        "        return None\n",
        "    return to_float_array(get_path(song_obj, param_info['raw_path']))\n",
        "\n",
        "def _song_label(song_obj):\n",
        "    md = song_obj.get(\"metadata\", {})\n",
        "    title = md.get(\"title\", \"Untitled\")\n",
        "    artist = md.get(\"artist\", \"Unknown\")\n",
        "    year = md.get(\"project_year\", \"\")\n",
        "    return f\"{title} — {artist}\" + (f\" ({year})\" if str(year).strip() else \"\")\n",
        "\n",
        "def _is_1d_numeric_series(x):\n",
        "    if x is None:\n",
        "        return False\n",
        "    try:\n",
        "        arr = np.asarray(x)\n",
        "    except Exception:\n",
        "        return False\n",
        "    return arr.ndim == 1 and np.issubdtype(arr.dtype, np.number)\n",
        "\n",
        "def _make_structural_dfs(song_obj):\n",
        "    \"\"\"Creates DataFrames for sections and phrases from a raw song object.\"\"\"\n",
        "    S = song_obj.get(\"structural\", {})\n",
        "    df_sections = None\n",
        "    df_phrases = None\n",
        "    st, sl = S.get(\"section_times\"), S.get(\"section_labels\")\n",
        "    if _is_1d_numeric_series(st) and isinstance(sl, (list, tuple)) and len(st) == len(sl):\n",
        "        df_sections = pd.DataFrame({\"Initial_Time\": st, \"Label\": sl})\n",
        "    pt, pl = S.get(\"phrase_times\"), S.get(\"phrase_labels\")\n",
        "    if _is_1d_numeric_series(pt) and isinstance(pl, (list, tuple)) and len(pt) == len(pl):\n",
        "        df_phrases = pd.DataFrame({\"Initial_Time\": pt, \"Label\": pl})\n",
        "    return df_sections, df_phrases\n",
        "\n",
        "def format_axes_emd(ax, x_axis, df_sections, df_phrases, title=None, mode=\"time\", beat_times=None):\n",
        "    \"\"\"Bottom axis: time or beats; top axis: the other. Adds sections & phrases.\"\"\"\n",
        "    def sec_to_minsec(t):\n",
        "        m = int(t // 60)\n",
        "        s = int(round(t % 60))\n",
        "        return f\"{m}:{s:02d}\"\n",
        "\n",
        "    x_axis = np.asarray(x_axis)\n",
        "    if x_axis.size == 0:\n",
        "        return\n",
        "\n",
        "    n_ticks = 10\n",
        "    x_lo = x_axis[0] if x_axis.size > 0 else 0\n",
        "    x_hi = x_axis[-1] if x_axis.size > 0 else 1\n",
        "    tick_positions = np.linspace(x_lo, x_hi, n_ticks)\n",
        "\n",
        "    bt = np.asarray(beat_times) if beat_times is not None else x_axis\n",
        "\n",
        "    if mode == \"beats\":\n",
        "        ax.set_xticks(tick_positions)\n",
        "        beat_indices = np.searchsorted(bt, tick_positions)\n",
        "        ax.set_xticklabels([f\"{b+1}\" for b in beat_indices], fontsize=9)\n",
        "        ax.set_xlabel(\"Beat\")\n",
        "\n",
        "        ax_top = ax.secondary_xaxis('top')\n",
        "        ax_top.set_xticks(tick_positions)\n",
        "        ax_top.set_xticklabels([sec_to_minsec(t) for t in tick_positions], fontsize=9)\n",
        "        ax_top.set_xlabel(\"Time (mm:ss)\")\n",
        "    else:\n",
        "        ax.set_xticks(tick_positions)\n",
        "        ax.set_xticklabels([sec_to_minsec(t) for t in tick_positions], fontsize=9)\n",
        "        ax.set_xlabel(\"Time (mm:ss)\")\n",
        "\n",
        "        ax_top = ax.secondary_xaxis('top')\n",
        "        ax_top.set_xticks(tick_positions)\n",
        "        beat_indices = np.searchsorted(bt, tick_positions)\n",
        "        ax_top.set_xticklabels([f\"{b+1}\" for b in beat_indices], fontsize=9)\n",
        "        ax_top.set_xlabel(\"Beat\")\n",
        "\n",
        "    # Sections\n",
        "    if df_sections is not None and all(c in df_sections.columns for c in [\"Initial_Time\", \"Label\"]):\n",
        "        for time, label in zip(df_sections[\"Initial_Time\"], df_sections[\"Label\"]):\n",
        "            ax.axvline(x=time, color=\"black\", lw=1.2, alpha=0.9)\n",
        "            ax.text(time, -0.18, label, rotation=90, ha=\"center\", va=\"top\",\n",
        "                    fontsize=8, color=\"black\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
        "\n",
        "    # Phrases\n",
        "    if df_phrases is not None and all(c in df_phrases.columns for c in [\"Initial_Time\", \"Label\"]):\n",
        "        for t, lab in zip(df_phrases[\"Initial_Time\"], df_phrases[\"Label\"]):\n",
        "            ax.axvline(x=t, color=\"lightgrey\", lw=1.0, alpha=0.7)\n",
        "            ax.text(t, 1.15, lab, rotation=90, ha=\"center\", va=\"bottom\",\n",
        "                    fontsize=8, color=\"grey\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
        "\n",
        "    if title:\n",
        "        ax.set_title(title, pad=70)\n",
        "\n",
        "    ax.margins(x=0.05)\n",
        "    ax.grid(False)\n",
        "\n",
        "\n",
        "# Build song list for dropdown\n",
        "song_options_emd = []\n",
        "title_to_index_emd = {}\n",
        "for idx, song in enumerate(ALL_RAW_DATA): # Use ALL_RAW_DATA for consistent song indexing and metadata\n",
        "    lbl = _song_label(song)\n",
        "    while lbl in title_to_index_emd:\n",
        "        lbl = f\"{lbl}  #{idx}\"\n",
        "    title_to_index_emd[lbl] = idx\n",
        "    song_options_emd.append(lbl)\n",
        "\n",
        "feature_options_emd = sorted([p['display_name'] for p in PARAM_INFO])\n",
        "\n",
        "# Widgets\n",
        "song_dd_emd = widgets.Dropdown(options=song_options_emd, description='Song:', layout=widgets.Layout(width='60%'))\n",
        "feature_dd_emd = widgets.Dropdown(options=feature_options_emd, description='Feature:', layout=widgets.Layout(width='50%'))\n",
        "\n",
        "out_emd = widgets.Output()\n",
        "\n",
        "def plot_emd_components(song_obj, display_name):\n",
        "    with out_emd:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        raw_signal = _get_feature_values_raw(song_obj, display_name)\n",
        "\n",
        "        if raw_signal is None or len(raw_signal) == 0 or np.all(np.isnan(raw_signal)):\n",
        "            print(f\"No raw data found for '{display_name}' in selected song or signal is constant/all NaN.\")\n",
        "            return\n",
        "\n",
        "        # Handle NaNs before EMD, replace with interpolation or 0 for EMD processing\n",
        "        signal_for_emd = np.copy(raw_signal)\n",
        "        finite_mask = np.isfinite(signal_for_emd)\n",
        "        if np.any(finite_mask) and not np.all(finite_mask):\n",
        "            # Interpolate NaNs if there are enough non-NaN values\n",
        "            series = pd.Series(signal_for_emd)\n",
        "            signal_for_emd = series.interpolate(method='linear', limit_direction='both').values\n",
        "            # If still NaNs (e.g., all NaNs initially or only one data point), fill with 0 or mean\n",
        "            if np.any(np.isnan(signal_for_emd)):\n",
        "                 signal_for_emd = np.nan_to_num(signal_for_emd, nan=np.nanmean(signal_for_emd) if np.any(finite_mask) else 0.0)\n",
        "        elif not np.any(finite_mask):\n",
        "             signal_for_emd = np.zeros_like(signal_for_emd)\n",
        "\n",
        "        if np.all(signal_for_emd == signal_for_emd[0]):\n",
        "             print(f\"EMD cannot be applied to a constant signal for '{display_name}'.\")\n",
        "             return\n",
        "\n",
        "        emd = EMD()\n",
        "        try:\n",
        "            imfs = emd(signal_for_emd)\n",
        "        except Exception as e:\n",
        "            print(f\"EMD failed for '{display_name}': {e}\")\n",
        "            return\n",
        "\n",
        "        # Prepare components for plotting\n",
        "        imf1 = imfs[0] if imfs.shape[0] > 0 else np.zeros_like(raw_signal)\n",
        "        imf2 = imfs[1] if imfs.shape[0] > 1 else np.zeros_like(raw_signal)\n",
        "        imf3_plus = np.sum(imfs[2:], axis=0) if imfs.shape[0] > 2 else np.zeros_like(raw_signal)\n",
        "\n",
        "        # X-axis (beat times from raw song object)\n",
        "        beat_times = get_path(song_obj, \"rhythmic.beat_times\")\n",
        "        if _is_1d_numeric_series(beat_times):\n",
        "            x_axis = np.asarray(beat_times, dtype=float)\n",
        "            mode = \"time\"\n",
        "        else:\n",
        "            x_axis = np.arange(len(raw_signal))\n",
        "            mode = \"index\"\n",
        "\n",
        "        # Ensure all signals have the same length as x_axis\n",
        "        min_len = min(len(x_axis), len(raw_signal))\n",
        "        x_axis = x_axis[:min_len]\n",
        "        raw_signal = raw_signal[:min_len]\n",
        "        imf1 = imf1[:min_len]\n",
        "        imf2 = imf2[:min_len]\n",
        "        imf3_plus = imf3_plus[:min_len]\n",
        "\n",
        "        # Structural info from raw song object\n",
        "        df_sections, df_phrases = _make_structural_dfs(song_obj)\n",
        "\n",
        "        md = song_obj.get(\"metadata\", {})\n",
        "        plot_title = f\"EMD Components for {display_name}\\n{md.get('title', 'Untitled')} by {md.get('artist', 'Unknown')}\"\n",
        "\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(18, 12), sharex=True, constrained_layout=True)\n",
        "\n",
        "        # Plot Raw Signal\n",
        "        axes[0].plot(x_axis, raw_signal, label='Raw Signal', color='blue')\n",
        "        axes[0].set_title('Raw Signal')\n",
        "        axes[0].legend()\n",
        "        format_axes_emd(axes[0], x_axis, df_sections, df_phrases, title=plot_title, mode=mode, beat_times=beat_times)\n",
        "\n",
        "        # Plot IMF1\n",
        "        axes[1].plot(x_axis, imf1, label='IMF1', color='green')\n",
        "        axes[1].set_title('IMF1')\n",
        "        axes[1].legend()\n",
        "        format_axes_emd(axes[1], x_axis, df_sections, df_phrases, mode=mode, beat_times=beat_times)\n",
        "\n",
        "        # Plot IMF2\n",
        "        axes[2].plot(x_axis, imf2, label='IMF2', color='red')\n",
        "        axes[2].set_title('IMF2')\n",
        "        axes[2].legend()\n",
        "        format_axes_emd(axes[2], x_axis, df_sections, df_phrases, mode=mode, beat_times=beat_times)\n",
        "\n",
        "        # Plot IMF3+\n",
        "        axes[3].plot(x_axis, imf3_plus, label='IMF3+', color='purple')\n",
        "        axes[3].set_title('IMF3+ (Sum of IMF3 and higher)')\n",
        "        axes[3].legend()\n",
        "        format_axes_emd(axes[3], x_axis, df_sections, df_phrases, mode=mode, beat_times=beat_times)\n",
        "\n",
        "        plt.xlabel(f\"Time ({mode})\")\n",
        "        plt.show()\n",
        "\n",
        "def on_change_emd(*args):\n",
        "    selected_song_label = song_dd_emd.value\n",
        "    selected_feature_name = feature_dd_emd.value\n",
        "\n",
        "    if selected_song_label and selected_feature_name:\n",
        "        idx = title_to_index_emd[selected_song_label]\n",
        "        song_obj = ALL_RAW_DATA[idx] # Always use raw data for EMD input\n",
        "        plot_emd_components(song_obj, selected_feature_name)\n",
        "\n",
        "# Wire up the widgets\n",
        "song_dd_emd.observe(on_change_emd, names='value')\n",
        "feature_dd_emd.observe(on_change_emd, names='value')\n",
        "\n",
        "# Layout and display\n",
        "display(widgets.VBox([\n",
        "    song_dd_emd,\n",
        "    feature_dd_emd,\n",
        "]), out_emd)\n",
        "\n",
        "# Initial plot\n",
        "on_change_emd()"
      ],
      "id": "c1760c80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Plots (Raw and EMD)"
      ],
      "metadata": {
        "id": "UWYz6DfOazuc"
      },
      "id": "UWYz6DfOazuc"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Imports ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 0) DATASET DISCOVERY (Now directly uses global data and data_processed)\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Ensure `data` and `data_processed` are available globally\n",
        "# Assuming `data` holds the original raw song objects and `data_processed` holds the EMD processed ones\n",
        "# If these variables are not present, this will raise an error.\n",
        "if 'data' not in globals() or not isinstance(data, list) or not data:\n",
        "    raise NameError(\"Global variable 'data' (raw song data) not found or is empty.\")\n",
        "if 'data_processed' not in globals() or not isinstance(data_processed, list) or not data_processed:\n",
        "    raise NameError(\"Global variable 'data_processed' (EMD data) not found or is empty.\")\n",
        "\n",
        "ALL_RAW_DATA = data\n",
        "ALL_EMD_DATA = data_processed\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 1) CORE HELPERS\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "def to_float_array(v):\n",
        "    \"\"\"Convert array-like to 1D float numpy array; preserve NaNs.\"\"\"\n",
        "    if v is None:\n",
        "        return None\n",
        "    try:\n",
        "        if hasattr(v, \"to_numpy\"):\n",
        "            arr = v.to_numpy(dtype=float)\n",
        "        else:\n",
        "            arr = np.asarray(v, dtype=float)\n",
        "    except Exception:\n",
        "        return None\n",
        "    if arr.ndim == 0:\n",
        "        arr = arr.reshape(1)\n",
        "    elif arr.ndim > 1:\n",
        "        arr = np.squeeze(arr)\n",
        "        if arr.ndim > 1:\n",
        "            arr = arr.ravel()\n",
        "    return arr\n",
        "\n",
        "def get_path(dct, path):\n",
        "    \"\"\"Traverse nested dict with dot-path (e.g., 'rhythmic.bpms_raw').\"\"\"\n",
        "    if dct is None or not isinstance(path, str) or not path:\n",
        "        return None\n",
        "    cur = dct\n",
        "    for part in path.split('.'):\n",
        "        if isinstance(cur, dict) and part in cur:\n",
        "            cur = cur.get(part)\n",
        "        else:\n",
        "            return None\n",
        "    return cur\n",
        "\n",
        "def format_title_from_metadata(template, song):\n",
        "    \"\"\"Fill template using metadata keys.\"\"\"\n",
        "    md = (song or {}).get(\"metadata\", {}) if isinstance(song, dict) else {}\n",
        "    return template.format(\n",
        "        title=md.get(\"title\", \"Untitled\"),\n",
        "        artist=md.get(\"artist\", \"Unknown\"),\n",
        "        project_year=md.get(\"project_year\", \"\"),\n",
        "        sample_rate=md.get(\"sample_rate\", \"\")\n",
        "    )\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Helper functions for feature access based on data source type\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# This list defines all features, their raw data paths, and EMD processed labels\n",
        "PARAM_INFO = [\n",
        "    {\"display_name\": \"Tempo Deviation\", \"raw_path\": \"rhythmic.tempo_deviations\", \"emd_label\": \"Tempo Deviation\"},\n",
        "    {\"display_name\": \"Voice Rhythmic Density\", \"raw_path\": \"rhythmic.voice_rhythmic_density\", \"emd_label\": \"Voice Rhythmic Density\"},\n",
        "    {\"display_name\": \"Guitars Rhythmic Density\", \"raw_path\": \"rhythmic.guitars_rhythmic_density\", \"emd_label\": \"Guitars Rhythmic Density\"},\n",
        "    {\"display_name\": \"Voice Loudness\", \"raw_path\": \"dynamic.voice_loudness\", \"emd_label\": \"Voice Loudness\"},\n",
        "    {\"display_name\": \"Guitars Loudness\", \"raw_path\": \"dynamic.guitars_loudness\", \"emd_label\": \"Guitars Loudness\"},\n",
        "    {\"display_name\": \"Tonal Dissonance\", \"raw_path\": \"harmonic.tonal_dissonance\", \"emd_label\": \"Tonal Dissonance\"},\n",
        "    {\"display_name\": \"Tonal Dispersion\", \"raw_path\": \"harmonic.tonal_dispersion\", \"emd_label\": \"Tonal Dispersion\"},\n",
        "    {\"display_name\": \"Melodic Voice Contour\", \"raw_path\": \"melodic.voice_melodic_contour\", \"emd_label\": \"Melodic Voice Contour\"},\n",
        "    {\"display_name\": \"Harmonic Guitars Contour\", \"raw_path\": \"melodic.guitars_harmonic_contour\", \"emd_label\": \"Harmonic Guitars Contour\"},\n",
        "]\n",
        "\n",
        "# PARAM_MAP will now just map display_name to itself for dropdown purposes\n",
        "PARAM_MAP = {p['display_name']: p['display_name'] for p in PARAM_INFO}\n",
        "\n",
        "def _get_param_info_by_display_name(display_name):\n",
        "    for p in PARAM_INFO:\n",
        "        if p['display_name'] == display_name:\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def _get_feature_values(song_obj, display_name, data_source_type):\n",
        "    param_info = _get_param_info_by_display_name(display_name)\n",
        "    if not param_info:\n",
        "        return None\n",
        "\n",
        "    if data_source_type == 'Raw Data':\n",
        "        return to_float_array(get_path(song_obj, param_info['raw_path']))\n",
        "    elif data_source_type == 'EMD Data':\n",
        "        return to_float_array(song_obj.get('features', {}).get(param_info['emd_label'], None))\n",
        "    return None\n",
        "\n",
        "def _is_feature_available(song_obj, display_name, data_source_type):\n",
        "    val = _get_feature_values(song_obj, display_name, data_source_type)\n",
        "    return val is not None and val.size > 0 # Check if it's not empty array either\n",
        "\n",
        "def _available_params_for_song(song_obj, data_source_type):\n",
        "    avail = []\n",
        "    for p_info in PARAM_INFO:\n",
        "        if _is_feature_available(song_obj, p_info['display_name'], data_source_type):\n",
        "            avail.append(p_info['display_name'])\n",
        "    return sorted(avail)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2) PLOTTING UTILITIES\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "def minmax_normalize(x):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    finite = np.isfinite(x)\n",
        "    if not np.any(finite):\n",
        "        return np.zeros_like(x)\n",
        "    lo, hi = np.nanmin(x[finite]), np.nanmax(x[finite])\n",
        "    if hi - lo < 1e-9:\n",
        "        y = np.zeros_like(x)\n",
        "    else:\n",
        "        y = (x - lo) / (hi - lo)\n",
        "    y[~finite] = np.nan\n",
        "    return y\n",
        "\n",
        "def format_axes(ax, x_axis, df_sections, df_phrases, title=None, mode=\"time\", beat_times=None):\n",
        "    \"\"\"Bottom axis: time or beats; top axis: the other. Adds sections & phrases.\"\"\"\n",
        "    def sec_to_minsec(t):\n",
        "        m = int(t // 60)\n",
        "        s = int(round(t % 60))\n",
        "        return f\"{m}:{s:02d}\"\n",
        "\n",
        "    x_axis = np.asarray(x_axis)\n",
        "    if x_axis.size == 0:\n",
        "        return\n",
        "\n",
        "    n_ticks = 10\n",
        "    x_lo = x_axis[0] if x_axis.size > 0 else 0\n",
        "    x_hi = x_axis[-1] if x_axis.size > 0 else 1\n",
        "    tick_positions = np.linspace(x_lo, x_hi, n_ticks)\n",
        "\n",
        "    bt = np.asarray(beat_times) if beat_times is not None else x_axis\n",
        "\n",
        "    if mode == \"beats\":\n",
        "        ax.set_xticks(tick_positions)\n",
        "        beat_indices = np.searchsorted(bt, tick_positions)\n",
        "        ax.set_xticklabels([f\"{b+1}\" for b in beat_indices], fontsize=9)\n",
        "        ax.set_xlabel(\"Beat\")\n",
        "\n",
        "        ax_top = ax.secondary_xaxis('top')\n",
        "        ax_top.set_xticks(tick_positions)\n",
        "        ax_top.set_xticklabels([sec_to_minsec(t) for t in tick_positions], fontsize=9)\n",
        "        ax_top.set_xlabel(\"Time (mm:ss)\")\n",
        "    else:\n",
        "        ax.set_xticks(tick_positions)\n",
        "        ax.set_xticklabels([sec_to_minsec(t) for t in tick_positions], fontsize=9)\n",
        "        ax.set_xlabel(\"Time (mm:ss)\")\n",
        "\n",
        "        ax_top = ax.secondary_xaxis('top')\n",
        "        ax_top.set_xticks(tick_positions)\n",
        "        beat_indices = np.searchsorted(bt, tick_positions)\n",
        "        ax_top.set_xticklabels([f\"{b+1}\" for b in beat_indices], fontsize=9)\n",
        "        ax_top.set_xlabel(\"Beat\")\n",
        "\n",
        "    # Sections\n",
        "    if df_sections is not None and all(c in df_sections.columns for c in [\"Initial_Time\", \"Label\"]):\n",
        "        for time, label in zip(df_sections[\"Initial_Time\"], df_sections[\"Label\"]):\n",
        "            ax.axvline(x=time, color=\"black\", lw=1.2, alpha=0.9)\n",
        "            ax.text(time, -0.18, label, rotation=90, ha=\"center\", va=\"top\",\n",
        "                    fontsize=8, color=\"black\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
        "\n",
        "    # Phrases\n",
        "    if df_phrases is not None and all(c in df_phrases.columns for c in [\"Initial_Time\", \"Label\"]):\n",
        "        for t, lab in zip(df_phrases[\"Initial_Time\"], df_phrases[\"Label\"]):\n",
        "            ax.axvline(x=t, color=\"lightgrey\", lw=1.0, alpha=0.7)\n",
        "            ax.text(t, 1.15, lab, rotation=90, ha=\"center\", va=\"bottom\",\n",
        "                    fontsize=8, color=\"grey\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
        "\n",
        "    if title:\n",
        "        ax.set_title(title, pad=70)\n",
        "\n",
        "    ax.margins(x=0.05)\n",
        "    ax.grid(False)\n",
        "\n",
        "def plot(variables, norm=False, smoothing=0, x_axis=None, df_sections=None, df_phrases=None,\n",
        "         title=None, mode=\"time\", plot_index=None, peaks=None, y_label=None,\n",
        "         song=None, title_template=None, beat_times=None, data_source_type='Raw Data'): # Added data_source_type\n",
        "    \"\"\"\n",
        "    variables: list of specs; each can be\n",
        "      - \"Guitars Loudness\" (display name)\n",
        "      - (\"Guitars Loudness\", True, 2, \"Guitars Loudness\")\n",
        "    song: required for feature lookup (either raw or processed song object)\n",
        "    data_source_type: 'Raw Data' or 'EMD Data'\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    def resolve_series(display_name):\n",
        "        \"\"\"Return a float array and apply masks (for raw data) based on display_name.\"\"\"\n",
        "        y = _get_feature_values(song, display_name, data_source_type)\n",
        "\n",
        "        if y is None:\n",
        "            return None\n",
        "\n",
        "        # Apply masks only if data_source_type is 'Raw Data'\n",
        "        # For 'EMD Data', masks (NaNs) are already part of the processed features.\n",
        "        if data_source_type == 'Raw Data':\n",
        "            low = display_name.lower()\n",
        "            # Apply masks where appropriate\n",
        "            if \"guitar\" in low:\n",
        "                m = to_float_array(get_path(song, \"dynamic.g_mask\"))\n",
        "                if m is not None and m.size > 0:\n",
        "                    L = min(len(y), len(m))\n",
        "                    y = y[:L].copy()\n",
        "                    m = m[:L].astype(bool)\n",
        "                    y[~m] = np.nan\n",
        "            if \"voice\" in low:\n",
        "                m = to_float_array(get_path(song, \"dynamic.v_mask\"))\n",
        "                if m is not None and m.size > 0:\n",
        "                    L = min(len(y), len(m))\n",
        "                    y = y[:L].copy()\n",
        "                    m = m[:L].astype(bool)\n",
        "                    y[~m] = np.nan\n",
        "        return y\n",
        "\n",
        "    # Final title (template uses metadata)\n",
        "    final_title = title\n",
        "    if final_title is None and title_template:\n",
        "        final_title = format_title_from_metadata(title_template, song)\n",
        "    elif final_title and \"{\" in final_title:\n",
        "        final_title = format_title_from_metadata(final_title, song)\n",
        "\n",
        "    if isinstance(variables, list):\n",
        "        fig, ax = plt.subplots(figsize=(18, 6), constrained_layout=True)\n",
        "\n",
        "        global_min, global_max = np.inf, -np.inf\n",
        "        plotted_any = False\n",
        "\n",
        "        for var in variables:\n",
        "            if isinstance(var, tuple):\n",
        "                # Expecting (display_name, nrm, smooth, label)\n",
        "                if len(var) == 4:\n",
        "                    display_name, nrm, smooth, label = var\n",
        "                elif len(var) == 3:\n",
        "                    display_name, nrm, smooth = var\n",
        "                    label = str(display_name)\n",
        "                else:\n",
        "                    display_name, nrm, smooth, label = var, norm, smoothing, str(var)\n",
        "            else:\n",
        "                display_name, nrm, smooth, label = var, norm, smoothing, str(var)\n",
        "\n",
        "            y = resolve_series(display_name)\n",
        "            if y is None or len(y) == 0:\n",
        "                print(f\"Variable '{display_name}' not found or empty for {data_source_type}.\")\n",
        "                continue\n",
        "\n",
        "            y_plot = np.copy(y)\n",
        "            if nrm:\n",
        "                y_plot = minmax_normalize(y_plot)\n",
        "            if smooth > 0:\n",
        "                finite_mask = np.isfinite(y_plot)\n",
        "                if np.any(finite_mask):\n",
        "                    y_plot[finite_mask] = gaussian_filter1d(y_plot[finite_mask], sigma=smooth)\n",
        "\n",
        "            # x-values\n",
        "            if x_axis is not None:\n",
        "                x_vals = np.asarray(x_axis)\n",
        "                min_len = min(len(x_vals), len(y_plot))\n",
        "                x_vals = x_vals[:min_len]\n",
        "                y_plot = y_plot[:min_len]\n",
        "            else:\n",
        "                x_vals = np.arange(len(y_plot))\n",
        "\n",
        "            y_masked = np.ma.masked_invalid(y_plot)\n",
        "            ax.plot(x_vals, y_masked, label=label)\n",
        "            plotted_any = True\n",
        "\n",
        "            finite_y_plot = y_plot[np.isfinite(y_plot)]\n",
        "            if finite_y_plot.size > 0 and not nrm:\n",
        "                global_min = min(global_min, np.min(finite_y_plot))\n",
        "                global_max = max(global_max, np.max(finite_y_plot))\n",
        "\n",
        "            if peaks and display_name in peaks: # peaks should now map to display names\n",
        "                peak_indices = np.asarray(peaks[display_name])\n",
        "                valid_peak_indices = peak_indices[peak_indices < len(x_vals)]\n",
        "                ax.scatter(x_vals[valid_peak_indices], y_plot[valid_peak_indices],\n",
        "                           color='red', label=f\"{label} Peaks\")\n",
        "\n",
        "        # Y-limits\n",
        "        if not norm and np.isfinite(global_min) and np.isfinite(global_max):\n",
        "            y_range = global_max - global_min\n",
        "            if y_range < 1e-9:\n",
        "                ax.set_ylim(global_min - 0.1, global_max + 0.1)\n",
        "            else:\n",
        "                ax.set_ylim(global_min - y_range * 0.05, global_max + y_range * 0.05)\n",
        "        elif norm:\n",
        "            ax.set_ylim(-0.05, 1.05)\n",
        "\n",
        "        # Axes formatting\n",
        "        if x_axis is not None and isinstance(x_axis, (list, np.ndarray)) and len(x_axis) > 0:\n",
        "            format_axes(ax, x_axis, df_sections, df_phrases, title=final_title, mode=mode, beat_times=beat_times)\n",
        "        else:\n",
        "            if final_title:\n",
        "                ax.set_title(final_title, pad=70)\n",
        "\n",
        "        if y_label is not None:\n",
        "            ax.set_ylabel(y_label)\n",
        "\n",
        "        if plotted_any:\n",
        "            ax.legend()\n",
        "\n",
        "        if plot_index is not None:\n",
        "            os.makedirs(\"./saved_plots\", exist_ok=True)\n",
        "            plot_path = os.path.join(\"./saved_plots\", f\"plot_{plot_index}.pdf\")\n",
        "            plt.savefig(plot_path, bbox_inches=\"tight\")\n",
        "            print(f\"Saved plot to {plot_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3) UI (Song, Var1, Var2 + Normalize/Smooth) LIMITED TO REQUESTED PARAMETERS\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "def _is_1d_numeric_series(x):\n",
        "    if x is None:\n",
        "        return False\n",
        "    try:\n",
        "        arr = np.asarray(x)\n",
        "    except Exception:\n",
        "        return False\n",
        "    return arr.ndim == 1 and np.issubdtype(arr.dtype, np.number)\n",
        "\n",
        "def _make_structural_dfs(song_obj):\n",
        "    \"\"\"Creates DataFrames for sections and phrases from a raw song object.\"\"\"\n",
        "    S = song_obj.get(\"structural\", {})\n",
        "    df_sections = None\n",
        "    df_phrases = None\n",
        "    st, sl = S.get(\"section_times\"), S.get(\"section_labels\")\n",
        "    if _is_1d_numeric_series(st) and isinstance(sl, (list, tuple)) and len(st) == len(sl):\n",
        "        df_sections = pd.DataFrame({\"Initial_Time\": st, \"Label\": sl})\n",
        "    pt, pl = S.get(\"phrase_times\"), S.get(\"phrase_labels\")\n",
        "    if _is_1d_numeric_series(pt) and isinstance(pl, (list, tuple)) and len(pt) == len(pl):\n",
        "        df_phrases = pd.DataFrame({\"Initial_Time\": pt, \"Label\": pl})\n",
        "    return df_sections, df_phrases\n",
        "\n",
        "def _song_label(song_obj):\n",
        "    md = song_obj.get(\"metadata\", {})\n",
        "    title = md.get(\"title\", \"Untitled\")\n",
        "    artist = md.get(\"artist\", \"Unknown\")\n",
        "    year = md.get(\"project_year\", \"\")\n",
        "    return f\"{title} — {artist}\" + (f\" ({year})\" if str(year).strip() else \"\")\n",
        "\n",
        "# Build song list for dropdown (always based on raw data for consistent indexing/labeling)\n",
        "song_options = []\n",
        "title_to_index = {}\n",
        "for idx, song in enumerate(ALL_RAW_DATA):\n",
        "    lbl = _song_label(song)\n",
        "    while lbl in title_to_index:\n",
        "        lbl = f\"{lbl}  #{idx}\"\n",
        "    title_to_index[lbl] = idx\n",
        "    song_options.append(lbl)\n",
        "\n",
        "# Widgets\n",
        "data_source_dd = widgets.Dropdown(options=['Raw Data', 'EMD Data'], description='Data Source:')\n",
        "song_dd = widgets.Dropdown(options=song_options, description='Song:', layout=widgets.Layout(width='60%'))\n",
        "\n",
        "var1_dd  = widgets.Dropdown(options=[], description='Var 1:', layout=widgets.Layout(width='50%'))\n",
        "norm1_cb = widgets.Checkbox(value=False, description='Normalize 1')\n",
        "smooth1_sl = widgets.IntSlider(value=0, min=0, max=6, step=1, description='Smooth 1σ', layout=widgets.Layout(width='35%'))\n",
        "\n",
        "var2_dd  = widgets.Dropdown(options=[], description='Var 2:', layout=widgets.Layout(width='50%'))\n",
        "norm2_cb = widgets.Checkbox(value=False, description='Normalize 2')\n",
        "smooth2_sl = widgets.IntSlider(value=0, min=0, max=6, step=1, description='Smooth 2σ', layout=widgets.Layout(width='35%'))\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "# State variables\n",
        "current_song = None             # The song object currently selected for plotting (raw or processed)\n",
        "current_raw_song = None         # The corresponding raw song object (for structural info)\n",
        "beat_times_for_axes = None\n",
        "AVAILABLE_PARAMS = []           # list of display names available in current song/data source\n",
        "\n",
        "def _rebuild_song_state(selected_label, data_source_type):\n",
        "    \"\"\"Load the selected song and compute x-axis, structures, and available parameters.\"\"\"\n",
        "    global current_song, current_raw_song, beat_times_for_axes, AVAILABLE_PARAMS\n",
        "\n",
        "    # 1. Determine which list of songs to use for features\n",
        "    if data_source_type == 'Raw Data':\n",
        "        current_features_list = ALL_RAW_DATA\n",
        "    else: # 'EMD Data'\n",
        "        current_features_list = ALL_EMD_DATA\n",
        "\n",
        "    # 2. Get the index from the selected label (which refers to ALL_RAW_DATA's index)\n",
        "    idx = title_to_index[selected_label]\n",
        "\n",
        "    # 3. Set the current song object for feature plotting\n",
        "    current_song = current_features_list[idx]\n",
        "\n",
        "    # 4. Always get the *raw* song object for structural info (sections, phrases, beat_times)\n",
        "    current_raw_song = ALL_RAW_DATA[idx]\n",
        "\n",
        "    # 5. Determine available parameters for the selected song and data source type\n",
        "    AVAILABLE_PARAMS = _available_params_for_song(current_song, data_source_type)\n",
        "\n",
        "    # 6. Extract x-axis data and structural markers from the raw song object\n",
        "    bt = get_path(current_raw_song, \"rhythmic.beat_times\")\n",
        "    if _is_1d_numeric_series(bt):\n",
        "        beat_times_for_axes = np.asarray(bt, dtype=float)\n",
        "        x_axis = beat_times_for_axes\n",
        "        mode = \"time\"\n",
        "    else:\n",
        "        pt = get_path(current_raw_song, \"structural.phrase_times\")\n",
        "        if _is_1d_numeric_series(pt):\n",
        "            x_axis = np.asarray(pt, dtype=float)\n",
        "            beat_times_for_axes = None\n",
        "            mode = \"time\"\n",
        "        else:\n",
        "            # If no beat_times or phrase_times, use index over the longest available param series\n",
        "            longest = 0\n",
        "            for p_info in PARAM_INFO:\n",
        "                s = _get_feature_values(current_song, p_info['display_name'], data_source_type)\n",
        "                if s is not None:\n",
        "                    longest = max(longest, len(s))\n",
        "            x_axis = np.arange(longest) if longest > 0 else np.array([])\n",
        "            beat_times_for_axes = None\n",
        "            mode = \"time\"\n",
        "\n",
        "    df_sections, df_phrases = _make_structural_dfs(current_raw_song)\n",
        "    plot_title_template = \"{title} — {artist} ({project_year})\\n\" + f\"Data Source: {data_source_type}\"\n",
        "\n",
        "    return AVAILABLE_PARAMS, x_axis, df_sections, df_phrases, plot_title_template, mode\n",
        "\n",
        "def _refresh_var_dropdowns():\n",
        "    keys = AVAILABLE_PARAMS\n",
        "    var1_dd.options = keys\n",
        "    var2_dd.options = keys\n",
        "    # sensible defaults\n",
        "    prefs = [\n",
        "        \"Tempo Deviation\",\n",
        "        \"Voice Loudness\",\n",
        "        \"Guitars Loudness\",\n",
        "        \"Voice Rhythmic Density\",\n",
        "        \"Guitars Rhythmic Density\",\n",
        "        \"Tonal Dissonance\",\n",
        "        \"Tonal Dispersion\",\n",
        "        \"Melodic Voice Contour\",\n",
        "        \"Harmonic Guitars Contour\",\n",
        "    ]\n",
        "    var1_dd.value = next((k for k in prefs if k in keys), (keys[0] if keys else None))\n",
        "    var2_dd.value = next((k for k in prefs if k in keys and k != var1_dd.value),\n",
        "                         (keys[1] if len(keys) > 1 else None))\n",
        "\n",
        "def _draw_plot(*_):\n",
        "    out.clear_output(wait=True)\n",
        "    if current_song is None or current_raw_song is None:\n",
        "        with out:\n",
        "            print(\"Please select a song.\")\n",
        "        return\n",
        "\n",
        "    data_source_type = data_source_dd.value # Get data source type from widget\n",
        "    params_local, x_axis, df_sections, df_phrases, plot_title_template, mode = \\\n",
        "        _rebuild_song_state(song_dd.value, data_source_type)\n",
        "\n",
        "    variables = []\n",
        "    # Build specs using selected display names and carry normalization/smoothing\n",
        "    if var1_dd.value is not None and var1_dd.value in params_local:\n",
        "        variables.append((var1_dd.value, norm1_cb.value, smooth1_sl.value, var1_dd.value))\n",
        "    if var2_dd.value is not None and var2_dd.value in params_local:\n",
        "        variables.append((var2_dd.value, norm2_cb.value, smooth2_sl.value, var2_dd.value))\n",
        "\n",
        "    with out:\n",
        "        plot(\n",
        "            variables=variables,\n",
        "            x_axis=x_axis,\n",
        "            df_sections=df_sections,\n",
        "            df_phrases=df_phrases,\n",
        "            title=None, # title template is set inside rebuild_song_state\n",
        "            title_template=plot_title_template,\n",
        "            mode=mode,\n",
        "            y_label=None,\n",
        "            plot_index=None,\n",
        "            peaks=None,\n",
        "            song=current_song, # current_song is either raw or processed, for feature data\n",
        "            beat_times=beat_times_for_axes,\n",
        "            data_source_type=data_source_type # Pass data source type to plot function\n",
        "        )\n",
        "\n",
        "def _on_song_change(change):\n",
        "    if change['name'] == 'value' and change['new'] is not None:\n",
        "        _rebuild_song_state(change['new'], data_source_dd.value)\n",
        "        _refresh_var_dropdowns()\n",
        "        _draw_plot()\n",
        "\n",
        "def _on_data_source_change(change):\n",
        "    if change['name'] == 'value' and change['new'] is not None:\n",
        "        _rebuild_song_state(song_dd.value, change['new'])\n",
        "        _refresh_var_dropdowns()\n",
        "        _draw_plot()\n",
        "\n",
        "# Initialize & wire\n",
        "if song_options:\n",
        "    # Initial state rebuild with default selections\n",
        "    _rebuild_song_state(song_options[0], data_source_dd.value)\n",
        "    _refresh_var_dropdowns()\n",
        "\n",
        "song_dd.observe(_on_song_change, names='value')\n",
        "data_source_dd.observe(_on_data_source_change, names='value') # New observer for data source\n",
        "var1_dd.observe(lambda ch: _draw_plot(), names='value')\n",
        "var2_dd.observe(lambda ch: _draw_plot(), names='value')\n",
        "norm1_cb.observe(lambda ch: _draw_plot(), names='value')\n",
        "norm2_cb.observe(lambda ch: _draw_plot(), names='value')\n",
        "smooth1_sl.observe(lambda ch: _draw_plot(), names='value')\n",
        "smooth2_sl.observe(lambda ch: _draw_plot(), names='value')\n",
        "\n",
        "# Layout & display\n",
        "controls = widgets.VBox([\n",
        "    data_source_dd, # Add data source dropdown to the layout\n",
        "    song_dd,\n",
        "    widgets.HBox([var1_dd, norm1_cb, smooth1_sl]),\n",
        "    widgets.HBox([var2_dd, norm2_cb, smooth2_sl]),\n",
        "])\n",
        "display(controls, out)\n",
        "\n",
        "# Initial render\n",
        "_draw_plot()"
      ],
      "metadata": {
        "id": "79_Yrn2ma15u"
      },
      "id": "79_Yrn2ma15u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Viz"
      ],
      "metadata": {
        "id": "6hb0AsV9zwZC"
      },
      "id": "6hb0AsV9zwZC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ce58dda"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "# --- 1. Prepare all correlation matrices for MDS ---\n",
        "# Re-generate piece-level correlation matrices with associated metadata\n",
        "\n",
        "piece_correlation_matrices_with_metadata = []\n",
        "\n",
        "def flatten_upper_triangle(matrix):\n",
        "    # Extract upper triangle (excluding diagonal) to get unique correlations\n",
        "    mask = np.triu(np.ones(matrix.shape), k=1).astype(bool)\n",
        "    return matrix.values[mask]\n",
        "\n",
        "for processed_row in data_processed:\n",
        "    title = processed_row.get('metadata', {}).get('title', 'Unknown Title')\n",
        "    artist = processed_row.get('metadata', {}).get('artist', 'Unknown Artist')\n",
        "    features = processed_row.get('features', {})\n",
        "\n",
        "    # Filter out masks and keep only numeric features\n",
        "    piece_data = {k: v for k, v in features.items()\n",
        "                  if isinstance(v, list) and k not in ['Voice Mask', 'Guitar Mask'] and len(v) > 0}\n",
        "\n",
        "    # Ensure all features have equal length and enough data for correlation\n",
        "    if len(piece_data) > 1:\n",
        "        lengths = {len(vals) for vals in piece_data.values()}\n",
        "        if len(lengths) == 1 and list(lengths)[0] > 1: # Ensure at least 2 data points for correlation\n",
        "            df_piece = pd.DataFrame(piece_data)\n",
        "            correlation_matrix = df_piece.corr(method='pearson')\n",
        "\n",
        "            piece_correlation_matrices_with_metadata.append({\n",
        "                'title': title,\n",
        "                'artist': artist,\n",
        "                'matrix': correlation_matrix\n",
        "            })\n",
        "\n",
        "# Filter to include only piece-level data for MDS\n",
        "flattened_vectors = []\n",
        "labels = [] # Will be track titles\n",
        "artists_for_plot = [] # Will be artists for coloring\n",
        "\n",
        "for entry in piece_correlation_matrices_with_metadata:\n",
        "    flat_vec = flatten_upper_triangle(entry['matrix'])\n",
        "    flattened_vectors.append(flat_vec)\n",
        "    labels.append(entry['title'])\n",
        "    artists_for_plot.append(entry['artist'])\n",
        "\n",
        "# Convert to numpy array\n",
        "X = np.array(flattened_vectors)\n",
        "\n",
        "# --- 2. Compute pairwise distances ---\n",
        "# Using Euclidean distance between the flattened vectors\n",
        "distance_matrix = pairwise_distances(X, metric='euclidean')\n",
        "\n",
        "# --- 3. Apply MDS ---\n",
        "# n_components=2 for a 2D plot\n",
        "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
        "X_transformed = mds.fit_transform(distance_matrix)\n",
        "\n",
        "# Create a DataFrame for easy plotting\n",
        "df_mds = pd.DataFrame(X_transformed, columns=['MDS1', 'MDS2'])\n",
        "df_mds['Label'] = labels # Track title\n",
        "df_mds['Artist'] = artists_for_plot # Artist for coloring\n",
        "\n",
        "# --- 4. Visualize the results ---\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.scatterplot(data=df_mds, x='MDS1', y='MDS2', hue='Artist', s=150, alpha=0.8)\n",
        "\n",
        "# Annotate points with their labels (track names)\n",
        "for i, row in df_mds.iterrows():\n",
        "    plt.annotate(row['Label'], (row['MDS1'] + 0.02, row['MDS2'] + 0.02), fontsize=9)\n",
        "\n",
        "plt.title('MDS of Pearson Correlation Matrices (Individual Pieces)')\n",
        "plt.xlabel('MDS Dimension 1')\n",
        "plt.ylabel('MDS Dimension 2')\n",
        "plt.grid(True)\n",
        "plt.axhline(0, color='grey', linestyle='--', linewidth=0.8)\n",
        "plt.axvline(0, color='grey', linestyle='--', linewidth=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "1ce58dda",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "daVdDfgK9sI3",
        "R_yuw4LT98po",
        "XxoaKdHMZLwA",
        "Aq36IWVfPEkf",
        "dR1C4HS1-Q0y",
        "ujm-eGRZ7NIo",
        "U_Khz76Itp73",
        "OwHrvMPD-JJ6",
        "UWYz6DfOazuc"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
