{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bernardes7/Paredes/blob/main/notebooks/Between_Voices_Main(preprocessed_notes).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yK94WsD0eD4V",
      "metadata": {
        "id": "yK94WsD0eD4V"
      },
      "source": [
        "# Between Voices — Colab Notebook:\n",
        "- **Structural**: Annotations (beats, sections, phrases)\n",
        "- **Rhythmic**: BPM series, tempo deviations (anchored to median BPM from Section 2), onset peak counts per beat\n",
        "- **Harmonic**: NNLS chromas, TIVs, TIV qualities, dissonance and dispersion, Harmonic Change Function (frames & beats)\n",
        "- **Melodic**: Beat-sync spectral centroids on CQT Spectra for voice and guitars\n",
        "- **Dynamic**: RMS-based loudness (dB) per beat\n",
        "\n",
        "> **Export rule**: The final JSON contains **raw values only** for all series **except chromas** (which remain the usual normalized/thresheld representations).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b67-8kLgeD4X",
      "metadata": {
        "id": "b67-8kLgeD4X"
      },
      "source": [
        "## 1) Environment Setup & Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AF4mc8ofeD4X",
      "metadata": {
        "id": "AF4mc8ofeD4X"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -q \"numpy>=2.0,<2.3\" \"scipy>=1.14\" \"pandas>=2.2\" librosa==0.11.0 ipywidgets PyPDF2 dissonant\n",
        "!git clone -q https://github.com/aframires/TIVlib.git /content/TIVlib\n",
        "%pip install -q PyMuPDF\n",
        "%pip install EMD-signal\n",
        "%pip install fastdtw\n",
        "\n",
        "\n",
        "import sys, os, math, glob, re, json, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa, librosa.display\n",
        "from scipy.ndimage import gaussian_filter1d, median_filter, convolve, convolve1d\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.optimize import nnls\n",
        "from scipy.stats import zscore\n",
        "from IPython.display import Audio, display\n",
        "import seaborn as sns\n",
        "from PyEMD import EMD\n",
        "import fitz\n",
        "from google.colab import files, drive\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from matplotlib.colors import Normalize, ListedColormap\n",
        "from matplotlib.collections import LineCollection\n",
        "import ipywidgets as widgets\n",
        "from dissonant import dissonance\n",
        "\n",
        "\n",
        "sys.path.insert(0, '/content/TIVlib')\n",
        "from TIVlib import TIV as tiv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8i5U07ZGeD4Y",
      "metadata": {
        "id": "8i5U07ZGeD4Y"
      },
      "source": [
        "## 2) Utilities, Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OgxqSZHAeD4Y",
      "metadata": {
        "id": "OgxqSZHAeD4Y"
      },
      "outputs": [],
      "source": [
        "# --- Select Project by Uncommenting One Line ---\n",
        "# PROJECT_NAME = '1958_Augusto Camacho/Quando os Sinos Dobram'\n",
        "# PROJECT_NAME = '1958_Augusto Camacho/Adeus a Coimbra'\n",
        "# PROJECT_NAME = '1958_Augusto Camacho/Água da Fonte'\n",
        "# PROJECT_NAME = '1958_Augusto Camacho/A Luz do Teu Olhar'\n",
        "# PROJECT_NAME = '1970_Cecília de Melo/Não Choro por me Deixares'\n",
        "# PROJECT_NAME = '1970_Cecília de Melo/O Render dos Heróis'\n",
        "# PROJECT_NAME = '1967_Luiz Goes/Balada do Mar'\n",
        "PROJECT_NAME = '1967_Luiz Goes/Canção da Infância'\n",
        "\n",
        "# Utilities\n",
        "\n",
        "# Create Log and Plot Containers\n",
        "LOG_FILE = \"./execution_log.txt\"\n",
        "PLOT_DIR = \"./saved_plots\"\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "\n",
        "# Clear previous plots\n",
        "for file_name in os.listdir(PLOT_DIR):\n",
        "    file_path = os.path.join(PLOT_DIR, file_name)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting file {file_path}: {e}\")\n",
        "\n",
        "\n",
        "# Clear the log file at the beginning of the run\n",
        "with open(LOG_FILE, \"w\") as f:\n",
        "    f.write(\"\") # Write an empty string to clear the file\n",
        "\n",
        "# Log messages for Final Report\n",
        "def log_message(message):\n",
        "    print(message)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(message + \"\\n\")\n",
        "\n",
        "# Numerical array to list\n",
        "def _nan_to_none_list(arr):\n",
        "    out = []\n",
        "    for v in np.asarray(arr, dtype=float):\n",
        "        out.append(float(v) if np.isfinite(v) else None)\n",
        "    return out\n",
        "\n",
        "# Cosine Distance\n",
        "def cosine_distance_complex(vec1, vec2):\n",
        "    dot_product = np.vdot(vec1, vec2)\n",
        "    n1 = np.linalg.norm(vec1)\n",
        "    n2 = np.linalg.norm(vec2)\n",
        "    if n1 < 1e-12 or n2 < 1e-12:\n",
        "        return 1.0\n",
        "    cos_sim = np.real(dot_product) / (n1 * n2)\n",
        "    cos_sim = np.clip(cos_sim, -1.0, 1.0)\n",
        "    return 1.0 - cos_sim\n",
        "\n",
        "# Extracts TIV objects to NumPy arrays\n",
        "def extract_tiv_vector(tiv_obj):\n",
        "    if tiv_obj is None:\n",
        "        return None\n",
        "    if hasattr(tiv_obj, 'vector'):\n",
        "        return np.array(tiv_obj.vector)\n",
        "    elif isinstance(tiv_obj, (np.ndarray, list, tuple)):\n",
        "        return np.array(tiv_obj)\n",
        "    raise ValueError(f\"Unsupported TIV type: {type(tiv_obj)}\")\n",
        "\n",
        "def call_tiv_method_safe(tiv_obj, method_name):\n",
        "    if tiv_obj is None:\n",
        "        return np.nan\n",
        "    method = getattr(tiv_obj, method_name, None)\n",
        "    if callable(method):\n",
        "        try:\n",
        "            return method()\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    return np.nan\n",
        "\n",
        "# Aggregates Frames to Beats\n",
        "def aggregate_to_beats(frame_times, values, beat_times, pad_last=False):\n",
        "    n_beats = len(beat_times) - 1\n",
        "    out = []\n",
        "    for b in range(n_beats):\n",
        "        t0, t1 = beat_times[b], beat_times[b+1]\n",
        "        idx = np.where((frame_times >= t0) & (frame_times < t1))[0]\n",
        "        out.append(np.mean(values[idx]) if len(idx) > 0 else np.nan)\n",
        "    if pad_last:\n",
        "        out.append(out[-1] if len(out) > 0 else np.nan)\n",
        "    return np.asarray(out)\n",
        "\n",
        "# Centralized masking function\n",
        "def apply_mask(data, mask):\n",
        "    import numpy as np\n",
        "    return np.where(mask, np.nan, data)\n",
        "\n",
        "\n",
        "# DSP Parameters\n",
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "window = 'hann'\n",
        "\n",
        "# CQT / Chroma\n",
        "bins_per_octave = 36\n",
        "n_octaves = 5\n",
        "cqt_normalize = False\n",
        "cqt_norm_type = 'max'\n",
        "cqt_denoise_median = None\n",
        "\n",
        "# NNLS dictionary (best-performing configuration)\n",
        "s = 0.5                 # optimized harmonic decay\n",
        "apply_whitening = True  # whitening ON\n",
        "chroma_threshold = 0.02 # keep as in your pipeline (works well)\n",
        "\n",
        "\n",
        "# HCF\n",
        "hcf_method = 'tiv_full'  # or '3_5_phases'\n",
        "\n",
        "# Sensory dissonance\n",
        "N_partials = 60\n",
        "\n",
        "# Define onset parameters\n",
        "track_params = {\n",
        "    'Vocals': {\n",
        "        'min_peak_distance_s': 0.25,\n",
        "        'threshold_std': 1.2,\n",
        "        'prominence_factor': 1.0\n",
        "    },\n",
        "    'Guitars': {\n",
        "        'min_peak_distance_s': 0.08,\n",
        "        'threshold_std': 0.3,\n",
        "        'prominence_factor': 0.5\n",
        "    },\n",
        "    'Full': {\n",
        "        'min_peak_distance_s': 0.05,\n",
        "        'threshold_std': 0.5,\n",
        "        'prominence_factor': 0.4\n",
        "    }\n",
        "}\n",
        "\n",
        "# Data path\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/Between Voices/Corpus de Colaborações'\n",
        "\n",
        "GOOGLE_DRIVE_DATA_PATH = os.path.join(BASE_DIR, PROJECT_NAME)\n",
        "full_audio_path  = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'full_audio.m4a')\n",
        "guitars_path     = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'guitars.wav')\n",
        "vocals_path      = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'voice.wav')\n",
        "beats_path       = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'beats.txt')\n",
        "chords_path      = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'chords.txt')\n",
        "phrases_path     = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'phrases.txt')\n",
        "sections_path    = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'sections.txt')\n",
        "notes_path       = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'notes.txt')\n",
        "\n",
        "print(\"GOOGLE_DRIVE_DATA_PATH =\", GOOGLE_DRIVE_DATA_PATH)\n",
        "print(\"Assuming files at:\")\n",
        "for p in [full_audio_path, guitars_path, vocals_path, beats_path, notes_path, chords_path, phrases_path, sections_path]:\n",
        "    print(\" -\", p, \"exists:\", os.path.exists(p))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gw7BiuTseD4Y",
      "metadata": {
        "id": "gw7BiuTseD4Y"
      },
      "source": [
        "## 3) Structural — Load Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uAwprRjIeD4Y",
      "metadata": {
        "id": "uAwprRjIeD4Y"
      },
      "outputs": [],
      "source": [
        "# Audio loader\n",
        "def load_audio_file(file_path, sr=None):\n",
        "    if os.path.exists(file_path):\n",
        "        y_loaded, sr_loaded = librosa.load(file_path, sr=sr)\n",
        "        y_loaded = np.nan_to_num(y_loaded, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        print(f\"Loaded {os.path.basename(file_path)} @ {sr_loaded} Hz, duration {len(y_loaded)/sr_loaded:.2f}s\")\n",
        "        return y_loaded, sr_loaded\n",
        "    print(f\"Warning: file not found: {file_path}\")\n",
        "    return None, None\n",
        "\n",
        "y_full, sr_full = load_audio_file(full_audio_path, sr=None)\n",
        "y_guitars, sr_guitars = load_audio_file(guitars_path, sr=None)\n",
        "y_vocals, sr_vocals = load_audio_file(vocals_path, sr=None)\n",
        "\n",
        "valid_srs = [s for s in [sr_full, sr_guitars, sr_vocals] if s is not None]\n",
        "if len(valid_srs)==0:\n",
        "    raise RuntimeError('No audio loaded')\n",
        "if not all(s==valid_srs[0] for s in valid_srs):\n",
        "    raise RuntimeError(f\"Sample rate mismatch: {sr_full, sr_guitars, sr_vocals}\")\n",
        "sr = valid_srs[0]\n",
        "\n",
        "# Beats\n",
        "if os.path.exists(beats_path):\n",
        "    df_beats = pd.read_csv(beats_path, sep='\t', header=None, names=['Beat_Time_Seconds','Metrical_Position'])\n",
        "    beat_times = df_beats['Beat_Time_Seconds'].values\n",
        "else:\n",
        "    raise FileNotFoundError(beats_path)\n",
        "\n",
        "# Notes\n",
        "if os.path.exists(notes_path):\n",
        "    df_notes = pd.read_csv(notes_path, sep='\t', header=None, names=['Note_onset','Note_duration','Frequency'])\n",
        "else:\n",
        "    raise FileNotFoundError(beats_path)\n",
        "\n",
        "# Sections / Phrases\n",
        "df_sections = pd.read_csv(sections_path, sep='\t', header=None, names=['Initial_Time','Track','Duration','Label'])\n",
        "df_phrases  = pd.read_csv(phrases_path,  sep='\t', header=None, names=['Initial_Time','Track','Duration','Label'])\n",
        "\n",
        "# Chords\n",
        "if os.path.exists(chords_path):\n",
        "    df_chords = pd.read_csv(chords_path, sep='\t', header=None, names=['Chord_Times_Seconds','Chord_Type'])\n",
        "    chord_times_seconds = df_chords['Chord_Times_Seconds'].values\n",
        "    chord_types = df_chords['Chord_Type'].values\n",
        "else:\n",
        "    df_chords = None\n",
        "    chord_times_seconds = None\n",
        "    chord_types = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tJnjjkeHeD4Z",
      "metadata": {
        "id": "tJnjjkeHeD4Z"
      },
      "source": [
        "## 4) Harmonic — Preprocess, Chroma, TIVs, HCF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kxeXSLS5eD4Z",
      "metadata": {
        "id": "kxeXSLS5eD4Z"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import nnls\n",
        "from scipy.ndimage import convolve1d\n",
        "\n",
        "def nnls_chroma_ptg(y, sr):\n",
        "    \"\"\"NNLS-based chroma: WHI+DEC+ODD+RES, INH & MED OFF\"\"\"\n",
        "    A0 = librosa.note_to_hz('A0')\n",
        "    C = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length, bins_per_octave=bins_per_octave,\n",
        "                           n_bins=bins_per_octave * n_octaves, fmin=A0)).astype(np.float32)\n",
        "    freqs = librosa.cqt_frequencies(C.shape[0], fmin=A0, bins_per_octave=bins_per_octave)\n",
        "\n",
        "    if cqt_normalize:\n",
        "        C = C / np.maximum(C.max(axis=0, keepdims=True) if cqt_norm_type == 'max' else np.linalg.norm(C, axis=0, keepdims=True), 1e-8)\n",
        "\n",
        "    if apply_whitening:\n",
        "        win_len = int(round(0.5 * bins_per_octave))\n",
        "        if win_len % 2 == 0: win_len += 1\n",
        "        kernel = np.hamming(win_len).astype(np.float32)\n",
        "        kernel /= kernel.sum()\n",
        "        mu = convolve1d(C, kernel, axis=0, mode='reflect')\n",
        "        var = convolve1d((C - mu)**2, kernel, axis=0, mode='reflect')\n",
        "        C = np.maximum((C - mu) / np.maximum(np.sqrt(var), 1e-8), 0.0).astype(np.float32)\n",
        "\n",
        "    s, odd_boost, res_gain_scale = 0.5, 0.95, 1.4\n",
        "    body_resonances = [(120.0, 30.0, 0.9*res_gain_scale), (470.0, 80.0, 0.7*res_gain_scale), (1000.0, 150.0, 0.5*res_gain_scale)]\n",
        "    spread_semitones, max_harmonics = 0.35, 20\n",
        "\n",
        "    bin_semitone_pos = np.log2(freqs / A0) * 12.0\n",
        "    note_freqs = librosa.midi_to_hz(np.arange(21, 21 + n_octaves * 12))\n",
        "    E = np.zeros((len(freqs), len(note_freqs)), dtype=np.float32)\n",
        "\n",
        "    for j, f0 in enumerate(note_freqs):\n",
        "        col = np.zeros(len(freqs), dtype=np.float32)\n",
        "        for k in range(1, max_harmonics + 1):\n",
        "            fk = f0 * k\n",
        "            if fk > freqs[-1] * 1.001: break\n",
        "            ak = (s ** (k - 1)) * (odd_boost if (k % 2) == 1 else 1.0)\n",
        "            diff = bin_semitone_pos - np.log2(fk / A0) * 12.0\n",
        "            col += (ak * np.exp(-0.5 * (diff**2) / (spread_semitones**2))).astype(np.float32)\n",
        "        nrm = np.linalg.norm(col)\n",
        "        if nrm > 0: col /= nrm\n",
        "        E[:, j] = col\n",
        "\n",
        "    body_gain = np.ones(len(freqs), dtype=np.float32)\n",
        "    for f_res, width_hz, gain in body_resonances:\n",
        "        body_gain += gain * np.exp(-0.5 * ((freqs - f_res)**2) / (width_hz**2)).astype(np.float32)\n",
        "    E *= body_gain[:, None]\n",
        "    for j in range(E.shape[1]):\n",
        "        nrm = np.linalg.norm(E[:, j])\n",
        "        if nrm > 0: E[:, j] /= nrm\n",
        "\n",
        "    semitone_acts = np.zeros((len(note_freqs), C.shape[1]), dtype=np.float32)\n",
        "    for t in range(C.shape[1]):\n",
        "        x, _ = nnls(E, C[:, t])\n",
        "        semitone_acts[:, t] = x\n",
        "\n",
        "    midi_numbers = np.arange(21, 21 + len(note_freqs))\n",
        "    pcs = midi_numbers % 12\n",
        "    chroma = np.zeros((12, semitone_acts.shape[1]), dtype=np.float32)\n",
        "    for j, pc in enumerate(pcs):\n",
        "        chroma[pc, :] += semitone_acts[j, :]\n",
        "\n",
        "    chroma /= np.maximum(chroma.max(axis=0, keepdims=True), 1e-8)\n",
        "    if chroma_threshold > 0:\n",
        "        chroma[chroma < chroma_threshold] = 0.0\n",
        "    return chroma\n",
        "\n",
        "def hcf_raw_from_tivs(tiv_vectors, method='tiv_full'):\n",
        "    if tiv_vectors is None or len(tiv_vectors) == 0: return np.array([])\n",
        "    Tv = np.array(tiv_vectors)\n",
        "    if Tv.ndim != 2: raise ValueError('TIV array must be 2D')\n",
        "    if Tv.shape[0] < Tv.shape[1] and Tv.shape[0] != 6: Tv = Tv.T\n",
        "    D, T = Tv.shape\n",
        "    Tv_pad = np.column_stack([np.zeros(D, dtype=Tv.dtype), Tv, np.zeros(D, dtype=Tv.dtype)])\n",
        "\n",
        "    if method == 'tiv_full':\n",
        "        diff = Tv_pad[:, 2:] - Tv_pad[:, :-2]\n",
        "        return np.linalg.norm(diff, axis=0)\n",
        "    elif method == '3_5_phases':\n",
        "        vals = []\n",
        "        for i in range(T):\n",
        "            v1, v2 = Tv_pad[[2, 4], i], Tv_pad[[2, 4], i+2]\n",
        "            n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
        "            if n1 < 1e-9 or n2 < 1e-9:\n",
        "                vals.append(1.0)\n",
        "            else:\n",
        "                sim = np.abs(np.vdot(v1, v2)) / (n1 * n2)\n",
        "                vals.append(np.clip(1.0 - sim, 0.0, 1.0))\n",
        "        return np.asarray(vals)\n",
        "    else:\n",
        "        raise ValueError('Invalid hcf_method')\n",
        "\n",
        "# HPSS\n",
        "y_harmonic, y_percussive = librosa.effects.hpss(y_guitars, margin=(1.0, 6.0), power=2.0)\n",
        "\n",
        "# Initialize variables\n",
        "chroma_frames = None\n",
        "frame_times = None\n",
        "chroma_beats = None\n",
        "tiv_beats_objs = []\n",
        "tiv_beats = np.array([])\n",
        "hcf_raw_beats = np.array([])\n",
        "tiv_frames_objs = []\n",
        "tiv_frames = np.array([])\n",
        "hcf_raw_frames = np.array([])\n",
        "global_chroma_beats_all = np.zeros(12)\n",
        "global_chroma_beats_sec2 = np.zeros(12)\n",
        "key_global = \"C:maj\"\n",
        "key_section2 = \"C:maj\"\n",
        "df_qualities = pd.DataFrame()\n",
        "\n",
        "# Process if harmonic audio exists\n",
        "if y_harmonic is not None:\n",
        "    chroma_frames = nnls_chroma_ptg(y_harmonic, sr)\n",
        "    frame_times = librosa.frames_to_time(np.arange(chroma_frames.shape[1]), sr=sr, hop_length=hop_length)\n",
        "\n",
        "    # Beat-sync chroma\n",
        "    n_beats = len(beat_times) - 1\n",
        "    chroma_beats = np.zeros((12, n_beats), dtype=np.float32)\n",
        "    for b in range(n_beats):\n",
        "        t0, t1 = beat_times[b], beat_times[b+1]\n",
        "        idx = np.where((frame_times >= t0) & (frame_times < t1))[0]\n",
        "        if len(idx) > 0:\n",
        "            chroma_beats[:, b] = np.median(chroma_frames[:, idx], axis=1)\n",
        "\n",
        "    chroma_beats /= np.maximum(chroma_beats.max(axis=0, keepdims=True), 1e-8)\n",
        "    if chroma_threshold > 0:\n",
        "        chroma_beats[chroma_beats < chroma_threshold] = 0.0\n",
        "\n",
        "    # Global chromas\n",
        "    global_chroma_beats_all = np.sum(chroma_beats, axis=1)\n",
        "\n",
        "    if df_sections is not None and len(df_sections) > 1:\n",
        "        sec2 = df_sections.iloc[1]\n",
        "        sec2_start, sec2_end = sec2['Initial_Time'], sec2['Initial_Time'] + sec2['Duration']\n",
        "        beat_times_eff = beat_times[:chroma_beats.shape[1]]\n",
        "        mask_b = (beat_times_eff >= sec2_start) & (beat_times_eff < sec2_end)\n",
        "        if np.any(mask_b):\n",
        "            global_chroma_beats_sec2 = np.sum(chroma_beats[:, mask_b], axis=1)\n",
        "\n",
        "    key_global = tiv.key(tiv.from_pcp(global_chroma_beats_all), mode=\"Shaath\")\n",
        "    key_section2 = tiv.key(tiv.from_pcp(global_chroma_beats_sec2), mode=\"Shaath\")\n",
        "\n",
        "    log_message(f\"Key (Global - All Beats): {key_global}\")\n",
        "    log_message(f\"Key (Section 2 Only): {key_section2}\")\n",
        "    log_message(\"-\" * 20)\n",
        "\n",
        "    # TIVs and HCF\n",
        "    tiv_beats_objs = [tiv.from_pcp(chroma_beats[:, i]) for i in range(chroma_beats.shape[1])]\n",
        "    tiv_beats = np.array([obj.vector for obj in tiv_beats_objs])\n",
        "    hcf_raw_beats = hcf_raw_from_tivs(tiv_beats.T, hcf_method)\n",
        "\n",
        "    tiv_frames_objs = [tiv.from_pcp(chroma_frames[:, i]) for i in range(chroma_frames.shape[1])]\n",
        "    tiv_frames = np.array([obj.vector for obj in tiv_frames_objs])\n",
        "    hcf_raw_frames = hcf_raw_from_tivs(tiv_frames.T, hcf_method)\n",
        "\n",
        "    # Tonal qualities\n",
        "    global_tiv_beats = tiv.from_pcp(global_chroma_beats_all)\n",
        "    gvec = extract_tiv_vector(global_tiv_beats)\n",
        "    quality_data = []\n",
        "    for tobj in tiv_beats_objs:\n",
        "        tv = extract_tiv_vector(tobj)\n",
        "        disp = cosine_distance_complex(gvec, tv)\n",
        "        quality_data.append({\n",
        "            'Chromaticity': call_tiv_method_safe(tobj, 'chromaticity'),\n",
        "            'Diatonicity': call_tiv_method_safe(tobj, 'diatonicity'),\n",
        "            'Dyadicity': call_tiv_method_safe(tobj, 'dyadicity'),\n",
        "            'Triadicity': call_tiv_method_safe(tobj, 'triadicity'),\n",
        "            'Dim_Quality': call_tiv_method_safe(tobj, 'dim_quality'),\n",
        "            'Wholetoneness': call_tiv_method_safe(tobj, 'wholetoneness'),\n",
        "            'Tonal_Dissonance': call_tiv_method_safe(tobj, 'dissonance'),\n",
        "            'Tonal_Dispersion': disp,\n",
        "        })\n",
        "    df_qualities = pd.DataFrame(quality_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pyl-8DnDeD4a",
      "metadata": {
        "id": "pyl-8DnDeD4a"
      },
      "source": [
        "## 5) Melodic and Harmonic Contour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ubu_QqqdeD4a",
      "metadata": {
        "id": "Ubu_QqqdeD4a"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def spectral_centroid_frames(y, sr, n_fft, hop_length, window='hann'):\n",
        "    \"\"\"\n",
        "    Compute spectral centroid using CQT instead of STFT.\n",
        "    Returns time (ft) and centroid in MIDI (cent_midi).\n",
        "    \"\"\"\n",
        "    # CQT parameters\n",
        "    fmin = librosa.note_to_hz('C1')  # lowest frequency\n",
        "    n_bins = 84                      # 7 octaves\n",
        "    bins_per_octave = 12             # semitone resolution\n",
        "\n",
        "    # Compute magnitude of CQT\n",
        "    cqt = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length, fmin=fmin,\n",
        "                             n_bins=n_bins, bins_per_octave=bins_per_octave))\n",
        "\n",
        "    # Frequencies corresponding to each bin\n",
        "    freqs = librosa.cqt_frequencies(n_bins=n_bins, fmin=fmin, bins_per_octave=bins_per_octave)\n",
        "\n",
        "    # Compute weighted spectral centroid (Hz)\n",
        "    numerator = np.sum(cqt * freqs[:, np.newaxis], axis=0)\n",
        "    denominator = np.sum(cqt, axis=0)\n",
        "    cent = numerator / (denominator + 1e-6)  # avoid division by zero\n",
        "\n",
        "    # Convert to MIDI\n",
        "    cent_midi = librosa.hz_to_midi(cent)\n",
        "\n",
        "    # Time axis\n",
        "    ft = librosa.frames_to_time(np.arange(len(cent_midi)), sr=sr, hop_length=hop_length)\n",
        "\n",
        "    return ft, cent_midi\n",
        "\n",
        "# Aplicação\n",
        "ft_v, cent_v = spectral_centroid_frames(y_vocals, sr, n_fft, hop_length, window)\n",
        "ft_g, cent_g = spectral_centroid_frames(y_harmonic, sr, n_fft, hop_length, window)\n",
        "\n",
        "melodic_centroid_raw  = aggregate_to_beats(ft_v, cent_v, beat_times)\n",
        "harmonic_centroid_raw = aggregate_to_beats(ft_g, cent_g, beat_times)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GpTXdFwFeD4Z",
      "metadata": {
        "id": "GpTXdFwFeD4Z"
      },
      "source": [
        "## 6) Rhythmic — BPM, Tempo Deviations & Rhythmic Density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UiAvQhfHeD4Z",
      "metadata": {
        "id": "UiAvQhfHeD4Z"
      },
      "outputs": [],
      "source": [
        "def compute_bpm_deviation_series(df_beats, df_sections, beat_times):\n",
        "    beat_times = np.asarray(df_beats['Beat_Time_Seconds'].values, dtype=float)\n",
        "    if beat_times.size < 2:\n",
        "        raise ValueError('Need at least 2 beats to compute BPM')\n",
        "\n",
        "    ibi = np.diff(beat_times)\n",
        "    valid = ibi > 1e-9\n",
        "    bpms_raw = np.full_like(ibi, np.nan, dtype=float)\n",
        "    bpms_raw[valid] = 60.0 / ibi[valid]\n",
        "    bpm_times = beat_times[:-1]\n",
        "\n",
        "    median_bpm = np.nan\n",
        "    if df_sections is not None and len(df_sections) >= 2:\n",
        "        sec2 = df_sections.iloc[1]\n",
        "        s0, s1 = float(sec2['Initial_Time']), float(sec2['Initial_Time']) + float(sec2['Duration'])\n",
        "        mask = (bpm_times >= s0) & (bpm_times < s1)\n",
        "        pool = bpms_raw[mask & np.isfinite(bpms_raw)]\n",
        "        if pool.size >= 1:\n",
        "            median_bpm = float(np.nanmedian(pool))\n",
        "\n",
        "    if not np.isfinite(median_bpm):\n",
        "        pool = bpms_raw[np.isfinite(bpms_raw)]\n",
        "        median_bpm = float(np.nanmedian(pool)) if pool.size > 0 else np.nan\n",
        "\n",
        "    bpm_diff_raw = bpms_raw - median_bpm if np.isfinite(median_bpm) else np.zeros_like(bpms_raw)\n",
        "    subdiv_beats = np.asarray(beat_times[:len(bpm_diff_raw)], dtype=float)\n",
        "\n",
        "    if bpm_times.size == 0:\n",
        "        bpm_diff_aligned_raw = np.zeros_like(subdiv_beats)\n",
        "    else:\n",
        "        idx = np.searchsorted(bpm_times, subdiv_beats, side='right') - 1\n",
        "        idx = np.clip(idx, 0, len(bpm_diff_raw) - 1)\n",
        "        bpm_diff_aligned_raw = bpm_diff_raw[idx]\n",
        "\n",
        "    # Log data\n",
        "    median_bpm_display = f\"{median_bpm:.2f}\" if np.isfinite(median_bpm) else \"NaN\"\n",
        "    log_message(f\"Computed median BPM: {median_bpm_display}\")\n",
        "    log_message(\"-\" * 20)\n",
        "\n",
        "    return {\n",
        "        'beat_times': beat_times,\n",
        "        'bpm_times': bpm_times,\n",
        "        'bpms_raw': bpms_raw,\n",
        "        'median_bpm': median_bpm,\n",
        "        'bpm_diff_raw': bpm_diff_raw,\n",
        "        'bpm_diff_aligned_raw': bpm_diff_aligned_raw\n",
        "    }\n",
        "\n",
        "bpm_series = compute_bpm_deviation_series(df_beats, df_sections, df_beats['Beat_Time_Seconds'].values)\n",
        "bpm_diff_raw = bpm_series['bpm_diff_raw']\n",
        "bpm_diff_aligned_raw = bpm_series['bpm_diff_aligned_raw']\n",
        "\n",
        "\n",
        "# --- Spectral flux computation ---\n",
        "def compute_flux(y_input, sr, hop_length, n_fft):\n",
        "    S = np.abs(librosa.stft(y_input, n_fft=n_fft, hop_length=hop_length))\n",
        "    S /= (np.max(S) + 1e-8)\n",
        "    flux = np.sqrt(np.sum(np.diff(S, axis=1, append=np.zeros((S.shape[0], 1)))**2, axis=0))\n",
        "    times = librosa.frames_to_time(np.arange(len(flux)), sr=sr, hop_length=hop_length)\n",
        "    return flux, times\n",
        "\n",
        "def detect_peaks_from_flux(flux, sr, hop_length,\n",
        "                           min_peak_distance_s=0.08,  # 80 ms\n",
        "                           threshold_std=0.5,\n",
        "                           prominence_factor=0.25):\n",
        "    if len(flux) == 0:\n",
        "        return np.array([], dtype=int), {}\n",
        "\n",
        "    # Compute thresholds\n",
        "    median_flux = np.median(flux)\n",
        "    std_flux = np.std(flux)\n",
        "    height_thr = median_flux + threshold_std * std_flux\n",
        "    prominence_thr = max(1e-8, prominence_factor * std_flux)\n",
        "\n",
        "    # Convert min distance in seconds to frames\n",
        "    frame_rate = sr / hop_length\n",
        "    min_dist_frames = max(1, int(round(min_peak_distance_s * frame_rate)))\n",
        "\n",
        "    # Initial peak detection\n",
        "    peaks, props = find_peaks(flux, height=height_thr,\n",
        "                               distance=min_dist_frames,\n",
        "                               prominence=prominence_thr)\n",
        "\n",
        "    # Remove duplicates that are too close (for guitars only; vocals won't use this path)\n",
        "    if len(peaks) > 1:\n",
        "        filtered_peaks = [peaks[0]]\n",
        "        for p in peaks[1:]:\n",
        "            if (p - filtered_peaks[-1]) >= min_dist_frames:\n",
        "                filtered_peaks.append(p)\n",
        "        peaks = np.array(filtered_peaks)\n",
        "\n",
        "    return peaks, props\n",
        "\n",
        "# --- Helper: read vocal onsets from df_notes without de-duplication ---\n",
        "def get_vocal_onsets_from_df(df_notes,\n",
        "                             col='Note_onset',\n",
        "                             t_max=None,\n",
        "                             sort_times=True,\n",
        "                             remove_negative=True,\n",
        "                             remove_nans=True):\n",
        "    \"\"\"\n",
        "    Read vocal note onset times (in seconds) from a DataFrame column.\n",
        "    - Optionally removes NaNs and negative values\n",
        "    - Optionally sorts the times\n",
        "    - Optionally clamps to t_max (audio duration)\n",
        "    No de-duplication is performed.\n",
        "    \"\"\"\n",
        "    if df_notes is None or col not in df_notes.columns:\n",
        "        raise ValueError(f\"df_notes must contain a '{col}' column with onset times in seconds.\")\n",
        "\n",
        "    ptimes = df_notes[col].to_numpy(dtype=float)\n",
        "\n",
        "    if remove_nans:\n",
        "        ptimes = ptimes[np.isfinite(ptimes)]\n",
        "    if remove_negative:\n",
        "        ptimes = ptimes[ptimes >= 0.0]\n",
        "    if sort_times:\n",
        "        ptimes = np.sort(ptimes)\n",
        "\n",
        "    if t_max is not None:\n",
        "        ptimes = ptimes[ptimes <= t_max]\n",
        "\n",
        "    # Return as numpy array (unchanged duplicates allowed)\n",
        "    return np.array(ptimes, dtype=float)\n",
        "\n",
        "# --- (Optional) Vocal onset detector (kept for reference, not used now) ---\n",
        "def detect_vocal_onsets(y, sr, hop_length=1024, frame_length=2048,\n",
        "                        fmin=librosa.note_to_hz('C2'),\n",
        "                        fmax=librosa.note_to_hz('C7'),\n",
        "                        energy_thresh_db=-40,\n",
        "                        midi_delta_thresh=1.2,\n",
        "                        smoothing_size=12,\n",
        "                        min_time_between_onsets=0.2):\n",
        "    # Compute RMS energy\n",
        "    rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    rms_db = librosa.amplitude_to_db(rms, ref=np.max)\n",
        "    energy_mask = rms_db > energy_thresh_db\n",
        "\n",
        "    # Compute pitch using YIN\n",
        "    f0 = librosa.yin(y, fmin=fmin, fmax=fmax, sr=sr, frame_length=frame_length, hop_length=hop_length)\n",
        "    times = librosa.frames_to_time(np.arange(len(f0)), sr=sr, hop_length=hop_length)\n",
        "\n",
        "    # Convert pitch to MIDI and apply smoothing\n",
        "    midi = librosa.hz_to_midi(f0)\n",
        "    midi[~np.isfinite(midi)] = np.nan\n",
        "    midi[~energy_mask] = np.nan\n",
        "    midi_smooth = median_filter(midi, size=smoothing_size)\n",
        "\n",
        "    # Compute pitch changes\n",
        "    midi_diff = np.abs(np.diff(midi_smooth, prepend=midi_smooth[0]))\n",
        "    midi_diff[np.isnan(midi_diff)] = 0\n",
        "\n",
        "    # Detect significant pitch changes\n",
        "    pitch_peaks, _ = find_peaks(midi_diff, height=midi_delta_thresh)\n",
        "    onset_times = times[pitch_peaks]\n",
        "\n",
        "    # Enforce minimum time between onsets\n",
        "    if len(onset_times) > 1:\n",
        "        filtered_onsets = [onset_times[0]]\n",
        "        for t in onset_times[1:]:\n",
        "            if t - filtered_onsets[-1] >= min_time_between_onsets:\n",
        "                filtered_onsets.append(t)\n",
        "        onset_times = np.array(filtered_onsets)\n",
        "\n",
        "    return onset_times\n",
        "\n",
        "# --- Process tracks (Guitars untouched; Vocals from df_notes['Note_onset']) ---\n",
        "tracks = {\n",
        "    'Vocals': y_vocals,\n",
        "    'Guitars': y_percussive if y_percussive is not None else y_guitars,\n",
        "}\n",
        "\n",
        "onsets = {}\n",
        "for name, ysig in tracks.items():\n",
        "    params = track_params.get(name, {})\n",
        "\n",
        "    if name == 'Vocals':\n",
        "        # Use pre-analysed onset times from df_notes['Note_onset'] without removing duplicates\n",
        "        t_max = len(ysig) / sr if (ysig is not None and sr is not None) else None\n",
        "        ptimes = get_vocal_onsets_from_df(\n",
        "            df_notes,\n",
        "            col='Note_onset',\n",
        "            t_max=t_max,\n",
        "            sort_times=True,       # set False to preserve original df order\n",
        "            remove_negative=True,\n",
        "            remove_nans=True\n",
        "        )\n",
        "\n",
        "        # No spectral flux for vocals in this pathway\n",
        "        flux = None\n",
        "        flux_t = None\n",
        "        # Placeholder index array to keep structure consistent\n",
        "        pidx = np.arange(len(ptimes), dtype=int)\n",
        "\n",
        "    else:\n",
        "        # --- UNCHANGED GUITARS PATH ---\n",
        "        flux, flux_t = compute_flux(ysig, sr, hop_length, n_fft)\n",
        "        pidx, props = detect_peaks_from_flux(\n",
        "            flux, sr, hop_length,\n",
        "            min_peak_distance_s=params.get('min_peak_distance_s', 0.05),\n",
        "            threshold_std=params.get('threshold_std', 0.5),\n",
        "            prominence_factor=params.get('prominence_factor', 0.25)\n",
        "        )\n",
        "        ptimes = flux_t[pidx]\n",
        "\n",
        "    # --- Count peaks per beat interval (unchanged) ---\n",
        "    beat_counts = []\n",
        "    for b in range(len(beat_times) - 1):\n",
        "        t0, t1 = beat_times[b], beat_times[b + 1]\n",
        "        count = np.sum((ptimes >= t0) & (ptimes < t1))\n",
        "        beat_counts.append(count)\n",
        "\n",
        "    onsets[name] = {\n",
        "        'flux': flux,              # None for vocals\n",
        "        'flux_times': flux_t,      # None for vocals\n",
        "        'peaks_idx': pidx,         # 0..N-1 for vocals\n",
        "        'peak_times': ptimes,      # key output for aggregation/plots\n",
        "        'counts': np.array(beat_counts)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cexeM9GleD4a",
      "metadata": {
        "id": "cexeM9GleD4a"
      },
      "source": [
        "## 7) Dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3zdtgCN9eD4a",
      "metadata": {
        "id": "3zdtgCN9eD4a"
      },
      "outputs": [],
      "source": [
        "# Compute RMS dB for each track\n",
        "rms_voice = librosa.feature.rms(y=y_vocals, frame_length=n_fft, hop_length=hop_length)[0]\n",
        "rms_guitars = librosa.feature.rms(y=y_guitars, frame_length=n_fft, hop_length=hop_length)[0]\n",
        "rms_full = librosa.feature.rms(y=y_full, frame_length=n_fft, hop_length=hop_length)[0]\n",
        "\n",
        "# Convert to dB\n",
        "rms_voice_db = librosa.amplitude_to_db(rms_voice, ref=np.max)\n",
        "rms_guitars_db = librosa.amplitude_to_db(rms_guitars, ref=np.max)\n",
        "rms_full_db = librosa.amplitude_to_db(rms_full, ref=np.max)\n",
        "\n",
        "# Frame times\n",
        "frame_t = librosa.frames_to_time(np.arange(len(rms_voice_db)), sr=sr, hop_length=hop_length)\n",
        "\n",
        "# Apply unified beat-level aggregation\n",
        "loudness_voice_raw   = aggregate_to_beats(frame_t, rms_voice_db, beat_times)\n",
        "loudness_guitars_raw = aggregate_to_beats(frame_t, rms_guitars_db, beat_times)\n",
        "loudness_full_raw    = aggregate_to_beats(frame_t, rms_full_db, beat_times)\n",
        "\n",
        "loudness_threshold_db = -40.0\n",
        "voice_mask = loudness_voice_raw < loudness_threshold_db\n",
        "guitar_mask = loudness_guitars_raw < loudness_threshold_db"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hf1kvdZ1eD4a",
      "metadata": {
        "id": "hf1kvdZ1eD4a"
      },
      "source": [
        "## 8) Export JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "owrNJxr4eD4a",
      "metadata": {
        "id": "owrNJxr4eD4a"
      },
      "outputs": [],
      "source": [
        "def complex_array_to_realimag(arr):\n",
        "    if arr is None or len(arr)==0:\n",
        "        return None\n",
        "    return {'real': np.real(arr).tolist(), 'imag': np.imag(arr).tolist()}\n",
        "\n",
        "def tiv_object_to_magphase(tiv_obj):\n",
        "    if tiv_obj is None:\n",
        "        return None\n",
        "    vec = np.asarray(tiv_obj.vector)\n",
        "    return {'mag': np.abs(vec).tolist(), 'phase': np.angle(vec).tolist()}\n",
        "\n",
        "def safe_series(df, col):\n",
        "    return df[col].tolist() if (df is not None and col in df.columns) else []\n",
        "\n",
        "plot_name = os.path.basename(GOOGLE_DRIVE_DATA_PATH.rstrip('/'))\n",
        "json_filename = f\"{plot_name}.json\"\n",
        "\n",
        "# Extract year and artist from PROJECT_NAME\n",
        "project_year = None\n",
        "artist_name = None\n",
        "match = re.match(r'^(\\d{4})_(.+)/', PROJECT_NAME)\n",
        "if match:\n",
        "    project_year = int(match.group(1))\n",
        "    artist_name = match.group(2)\n",
        "\n",
        "\n",
        "export_data = {\n",
        "    'metadata': {\n",
        "        'title': plot_name,\n",
        "        'sample_rate': int(sr),\n",
        "        'project_year': project_year,\n",
        "        'artist': artist_name,\n",
        "        'created_at': str(datetime.datetime.utcnow()),\n",
        "    },\n",
        "    'structural': {\n",
        "        'phrase_times':  safe_series(df_phrases, 'Initial_Time'),\n",
        "        'phrase_durations':  safe_series(df_phrases, 'Duration'),\n",
        "        'phrase_labels': safe_series(df_phrases, 'Label'),\n",
        "        'section_times':  safe_series(df_sections, 'Initial_Time'),\n",
        "        'section_durations': safe_series(df_sections, 'Duration'),\n",
        "        'section_labels': safe_series(df_sections, 'Label'),\n",
        "    },\n",
        "    'rhythmic': {\n",
        "        'beat_times': _nan_to_none_list(bpm_series['beat_times']),\n",
        "        'metrical_position': safe_series(df_beats, 'Metrical_Position'),\n",
        "        'bpm_median': float(bpm_series['median_bpm']) if np.isfinite(bpm_series['median_bpm']) else None,\n",
        "        'bpms_raw': _nan_to_none_list(bpm_series['bpms_raw']),\n",
        "        'tempo_deviations': _nan_to_none_list(bpm_series['bpm_diff_raw']), # bpm_diff_aligned_raw this is the same. check why it exists!!\n",
        "        'voice_rhythmic_density': _nan_to_none_list(onsets['Vocals']['counts']) if 'onsets' in globals() else [],\n",
        "        'guitars_rhythmic_density': _nan_to_none_list(onsets['Guitars']['counts']) if 'onsets' in globals() else [],\n",
        "    },\n",
        "    'harmonic': {\n",
        "        'chroma': chroma_beats.tolist(),\n",
        "        'chroma_times': _nan_to_none_list(beat_times[:-1]),\n",
        "        'chroma_global_sec2': global_chroma_beats_sec2.tolist(),\n",
        "        'tiv_beats': complex_array_to_realimag(tiv_beats),\n",
        "        'tiv_global_sec2': tiv_object_to_magphase(global_tiv_beats),\n",
        "        'key_global': str(key_global),\n",
        "        'key_section2': str(key_section2),\n",
        "        'chromaticity': safe_series(df_qualities, 'Chromaticity'),\n",
        "        'diatonicity':  safe_series(df_qualities, 'Diatonicity'),\n",
        "        'dyadicity':    safe_series(df_qualities, 'Dyadicity'),\n",
        "        'triadicity':   safe_series(df_qualities, 'Triadicity'),\n",
        "        'dim_quality':  safe_series(df_qualities, 'Dim_Quality'),\n",
        "        'wholetoneness':safe_series(df_qualities, 'Wholetoneness'),\n",
        "        'tonal_dissonance': safe_series(df_qualities, 'Tonal_Dissonance'),\n",
        "        'tonal_dispersion': safe_series(df_qualities, 'Tonal_Dispersion'),\n",
        "        'hcf': _nan_to_none_list(hcf_raw_beats),\n",
        "    },\n",
        "    'melodic': {\n",
        "        'voice_melodic_contour': _nan_to_none_list(melodic_centroid_raw),\n",
        "        'guitars_harmonic_contour': _nan_to_none_list(harmonic_centroid_raw)\n",
        "    },\n",
        "    'dynamic': {\n",
        "        'voice_loudness': _nan_to_none_list(loudness_voice_raw),\n",
        "        'guitars_loudness': _nan_to_none_list(loudness_guitars_raw),\n",
        "        'full_loudness': _nan_to_none_list(loudness_full_raw)\n",
        "    },\n",
        "}\n",
        "\n",
        "with open(json_filename, 'w') as f:\n",
        "    json.dump(export_data, f, indent=2)\n",
        "print(f\"Saved JSON to {json_filename}\")\n",
        "\n",
        "from google.colab import files\n",
        "try:\n",
        "    files.download(json_filename)\n",
        "except Exception as e:\n",
        "    print(f\"Could not initiate download: {e}\")\n",
        "    print(f\"You can manually download the file '{json_filename}' from the file browser.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aBBAI_hSsfv_",
      "metadata": {
        "id": "aBBAI_hSsfv_"
      },
      "source": [
        "## 9) Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ku6NoNNMn_lD",
      "metadata": {
        "id": "ku6NoNNMn_lD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "import os\n",
        "\n",
        "# Signficance Level Parameter\n",
        "significance_level = 0.05\n",
        "\n",
        "# Apply EMD\n",
        "emd_data = {}\n",
        "raw_features = {\n",
        "    'Tempo Deviation': bpm_diff_aligned_raw,\n",
        "    'Voice Rhythmic Density': onsets['Vocals']['counts'].astype(float),\n",
        "    'Guitars Rhythmic Density': onsets['Guitars']['counts'].astype(float),\n",
        "    'Voice Loudness': loudness_voice_raw,\n",
        "    'Guitars Loudness': loudness_guitars_raw,\n",
        "    'Tonal Dissonance': df_qualities['Tonal_Dissonance'].values,\n",
        "    'Tonal Dispersion': df_qualities['Tonal_Dispersion'].values,\n",
        "    #'Harmonic Changes': hcf_raw_beats,\n",
        "    'Melodic Contour': melodic_centroid_raw,\n",
        "    'Harmonic Contour': harmonic_centroid_raw,\n",
        "}\n",
        "\n",
        "for name, values in raw_features.items():\n",
        "    try:\n",
        "        emd = EMD()\n",
        "        imfs = emd(values)\n",
        "        num_imfs = imfs.shape[0]\n",
        "\n",
        "        if num_imfs > 1:\n",
        "            emd_data[name] = np.sum(imfs[2:], axis=0)\n",
        "        else:\n",
        "            print(f\"Warning: Not enough IMFs for {name}. Using original signal.\")\n",
        "            emd_data[name] = values\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error applying EMD to {name}: {e}\")\n",
        "        emd_data[name] = values\n",
        "\n",
        "\n",
        "# Apply Loudness Masking\n",
        "emd_data_masked = {\n",
        "    'Tempo Deviation': emd_data['Tempo Deviation'],\n",
        "    'Voice Rhythmic Density': apply_mask(emd_data['Voice Rhythmic Density'], voice_mask),\n",
        "    'Guitars Rhythmic Density': apply_mask(emd_data['Guitars Rhythmic Density'], guitar_mask),\n",
        "    'Voice Loudness': apply_mask(emd_data['Voice Loudness'], voice_mask),\n",
        "    'Guitars Loudness': apply_mask(emd_data['Guitars Loudness'], guitar_mask),\n",
        "    'Tonal Dissonance': emd_data['Tonal Dissonance'],\n",
        "    'Tonal Dispersion': emd_data['Tonal Dispersion'],\n",
        "    #'Harmonic Changes': emd_data['Harmonic Changes'],\n",
        "    'Melodic Contour': apply_mask(emd_data['Melodic Contour'], voice_mask),\n",
        "    'Harmonic Contour': apply_mask(emd_data['Harmonic Contour'], guitar_mask),\n",
        "}\n",
        "\n",
        "# Create dataframe and compute correlations\n",
        "df_emd = pd.DataFrame(emd_data_masked)\n",
        "corr_matrix = df_emd.corr(method='pearson')\n",
        "\n",
        "# Compute p values\n",
        "p_values = pd.DataFrame(np.ones(corr_matrix.shape), columns=corr_matrix.columns, index=corr_matrix.index)\n",
        "for row in corr_matrix.columns:\n",
        "    for col in corr_matrix.columns:\n",
        "        if row != col:\n",
        "            _, p = pearsonr(df_emd[row], df_emd[col])\n",
        "            p_values.loc[row, col] = p\n",
        "\n",
        "# Statistical significance matrix\n",
        "annot_matrix = corr_matrix.round(2).astype(str)\n",
        "for row in corr_matrix.columns:\n",
        "    for col in corr_matrix.columns:\n",
        "        if row != col and p_values.loc[row, col] < significance_level:\n",
        "            annot_matrix.loc[row, col] += '*'\n",
        "\n",
        "# Plot\n",
        "os.makedirs(\"saved_plots\", exist_ok=True)\n",
        "plt.figure(figsize=(9, 8))\n",
        "sns.heatmap(corr_matrix, annot=annot_matrix, fmt='', cmap=\"coolwarm\", center=0, vmin=-1, vmax=1)\n",
        "plt.title(\"Features Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"saved_plots/plot_6.pdf\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SM8-M5UFtNNW",
      "metadata": {
        "id": "SM8-M5UFtNNW"
      },
      "source": [
        "## 10) Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hMLMweDdDG-4",
      "metadata": {
        "id": "hMLMweDdDG-4"
      },
      "outputs": [],
      "source": [
        "def minmax_normalize(x):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    finite = np.isfinite(x)\n",
        "    if not np.any(finite):\n",
        "        return np.zeros_like(x)\n",
        "    lo, hi = np.nanmin(x[finite]), np.nanmax(x[finite])\n",
        "    if hi - lo < 1e-9:\n",
        "        y = np.zeros_like(x)\n",
        "    else:\n",
        "        y = (x - lo) / (hi - lo)\n",
        "    y[~finite] = np.nan # Keep NaNs as NaN after normalization\n",
        "    return y\n",
        "\n",
        "def format_axes(ax, x_axis, df_sections, df_phrases, title=None, mode=\"time\"):\n",
        "    def sec_to_minsec(t):\n",
        "        m = int(t // 60)\n",
        "        s = int(round(t % 60))\n",
        "        return f\"{m}:{s:02d}\"\n",
        "\n",
        "    x_axis = np.asarray(x_axis)\n",
        "    if x_axis.size == 0:\n",
        "        return\n",
        "\n",
        "    n_ticks = 10\n",
        "    # Ensure tick positions are within the range of x_axis\n",
        "    tick_positions = np.linspace(x_axis[0] if x_axis.size > 0 else 0, x_axis[-1] if x_axis.size > 0 else 1, n_ticks)\n",
        "\n",
        "    if mode == \"beats\":\n",
        "        ax.set_xticks(tick_positions)\n",
        "        # Find corresponding beat numbers for time tick positions\n",
        "        # This assumes beat_times is a monotonically increasing array of times for each beat\n",
        "        beat_indices = np.searchsorted(beat_times, tick_positions)\n",
        "        # Ensure indices are within bounds of beat_times if needed, or use beat numbers directly if x_axis is beat index\n",
        "        beat_labels = beat_indices + 1 # Beat numbers are typically 1-indexed\n",
        "        ax.set_xticklabels([f\"{b}\" for b in beat_labels], fontsize=9)\n",
        "        ax.set_xlabel(\"Beat\")\n",
        "\n",
        "        ax_top = ax.secondary_xaxis('top')\n",
        "        ax_top.set_xticks(tick_positions)\n",
        "        ax_top.set_xticklabels([sec_to_minsec(t) for t in tick_positions], fontsize=9)\n",
        "        ax_top.set_xlabel(\"Time (mm:ss)\")\n",
        "    else: # mode == \"time\"\n",
        "        ax.set_xticks(tick_positions)\n",
        "        ax.set_xticklabels([sec_to_minsec(t) for t in tick_positions], fontsize=9)\n",
        "        ax.set_xlabel(\"Time (mm:ss)\")\n",
        "\n",
        "        ax_top = ax.secondary_xaxis('top')\n",
        "        ax_top.set_xticks(tick_positions)\n",
        "         # Find corresponding beat numbers for time tick positions\n",
        "        beat_indices = np.searchsorted(beat_times, tick_positions)\n",
        "        beat_labels = beat_indices + 1 # Beat numbers are typically 1-indexed\n",
        "        ax_top.set_xticklabels([f\"{b}\" for b in beat_labels], fontsize=9)\n",
        "        ax_top.set_xlabel(\"Beat\")\n",
        "\n",
        "\n",
        "    if df_sections is not None and all(c in df_sections.columns for c in [\"Initial_Time\", \"Label\"]):\n",
        "        for time, label in zip(df_sections[\"Initial_Time\"], df_sections[\"Label\"]):\n",
        "            ax.axvline(x=time, color=\"black\", lw=1.2, alpha=0.9)\n",
        "            ax.text(time, -0.18, label, rotation=90, ha=\"center\", va=\"top\",\n",
        "                    fontsize=8, color=\"black\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
        "\n",
        "    if df_phrases is not None and all(c in df_phrases.columns for c in [\"Initial_Time\", \"Label\"]):\n",
        "        for t, lab in zip(df_phrases[\"Initial_Time\"], df_phrases[\"Label\"]):\n",
        "            ax.axvline(x=t, color=\"lightgrey\", lw=1.0, alpha=0.7)\n",
        "            ax.text(t, 1.15, lab, rotation=90, ha=\"center\", va=\"bottom\", # Adjusted va and y position\n",
        "                    fontsize=8, color=\"grey\", transform=ax.get_xaxis_transform(), clip_on=False)\n",
        "\n",
        "\n",
        "    if title:\n",
        "        ax.set_title(title, pad=70) # Increased pad for title\n",
        "\n",
        "    ax.margins(x=0.05)\n",
        "    ax.grid(False) # Ensure grid is off by default\n",
        "\n",
        "def plot(variables, norm=False, smoothing=0, x_axis=None, df_sections=None, df_phrases=None,\n",
        "         title=None, mode=\"time\", plot_index=None, peaks=None, y_label=None):\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "    def get_variable_array(name):\n",
        "        try:\n",
        "            return np.asarray(eval(name), dtype=float)\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing variable '{name}': {e}\")\n",
        "            return None\n",
        "\n",
        "    if isinstance(variables, list):\n",
        "        fig, ax = plt.subplots(figsize=(18, 6), constrained_layout=True)\n",
        "\n",
        "        global_min, global_max = np.inf, -np.inf\n",
        "\n",
        "        for var in variables:\n",
        "            if isinstance(var, tuple):\n",
        "                if len(var) == 4:\n",
        "                    name, nrm, smooth, label = var\n",
        "                else:\n",
        "                    name, nrm, smooth = var\n",
        "                    label = name\n",
        "            else:\n",
        "                name, nrm, smooth, label = var, norm, smoothing, var\n",
        "\n",
        "            y = get_variable_array(name)\n",
        "\n",
        "            if y is None or len(y) == 0:\n",
        "                print(f\"Variable '{name}' not found or empty.\")\n",
        "                continue\n",
        "\n",
        "            y_plot = np.copy(y)\n",
        "\n",
        "            if nrm:\n",
        "                y_plot = minmax_normalize(y_plot)\n",
        "            if smooth > 0:\n",
        "                finite_mask = np.isfinite(y_plot)\n",
        "                if np.any(finite_mask):\n",
        "                    y_plot[finite_mask] = gaussian_filter1d(y_plot[finite_mask], sigma=smooth)\n",
        "\n",
        "            if x_axis is not None:\n",
        "                x_axis = np.asarray(x_axis)\n",
        "                min_len = min(len(x_axis), len(y_plot))\n",
        "                x_vals = x_axis[:min_len]\n",
        "                y_plot = y_plot[:min_len]\n",
        "            else:\n",
        "                x_vals = np.arange(len(y_plot))\n",
        "\n",
        "            y_masked = np.ma.masked_invalid(y_plot)\n",
        "            ax.plot(x_vals, y_masked, label=label)\n",
        "\n",
        "            finite_y_plot = y_plot[np.isfinite(y_plot)]\n",
        "            if finite_y_plot.size > 0:\n",
        "                if not nrm:\n",
        "                    global_min = min(global_min, np.min(finite_y_plot))\n",
        "                    global_max = max(global_max, np.max(finite_y_plot))\n",
        "\n",
        "            if peaks and name in peaks:\n",
        "                peak_indices = peaks[name]\n",
        "                valid_peak_indices = peak_indices[peak_indices < len(x_vals)]\n",
        "                peak_times = x_vals[valid_peak_indices]\n",
        "                peak_values = y_plot[valid_peak_indices]\n",
        "                ax.scatter(peak_times, peak_values, color='red', label=f\"{label} Peaks\")\n",
        "\n",
        "        if not norm and np.isfinite(global_min) and np.isfinite(global_max):\n",
        "            y_range = global_max - global_min\n",
        "            if y_range < 1e-9:\n",
        "                ax.set_ylim(global_min - 0.1, global_max + 0.1)\n",
        "            else:\n",
        "                ax.set_ylim(global_min - y_range * 0.05, global_max + y_range * 0.05)\n",
        "        elif norm:\n",
        "            ax.set_ylim(-0.05, 1.05)\n",
        "\n",
        "        if x_axis is not None and isinstance(x_axis, (list, np.ndarray)) and len(x_axis) > 0:\n",
        "            format_axes(ax, x_axis, df_sections, df_phrases, title=title, mode=mode)\n",
        "\n",
        "        if y_label is not None:\n",
        "            ax.set_ylabel(y_label)\n",
        "\n",
        "        ax.legend()\n",
        "\n",
        "        if plot_index is not None:\n",
        "            os.makedirs(\"./saved_plots\", exist_ok=True)\n",
        "            plot_path = os.path.join(\"./saved_plots\", f\"plot_{plot_index}.pdf\")\n",
        "            plt.savefig(plot_path, bbox_inches=\"tight\")\n",
        "            print(f\"Saved plot to {plot_path}\")\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suxkEjrXR10j",
      "metadata": {
        "id": "suxkEjrXR10j"
      },
      "outputs": [],
      "source": [
        "plot([\n",
        "    (\"bpm_series['bpms_raw']\", False, 0, \"BPM\")],\n",
        "     title=\"Tempo\", y_label=\"BPM\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=7)\n",
        "\n",
        "plot([\n",
        "    (\"bpm_diff_aligned_raw\", False, 0, \"Tempo Deviations\")],\n",
        "     title=\"Tempo Deviations\", y_label=\"BPM Deviation\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=8)\n",
        "\n",
        "plot([\n",
        "    (\"df_qualities['Tonal_Dissonance']\", False, 0, \"Tonal Dissonance\"),\n",
        "    (\"df_qualities['Tonal_Dispersion']\", False, 0, \"Tonal Dispersion\")\n",
        "], title=\"Harmonic Features\", y_label=\"Tonal Distances & Dissonance\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=9)\n",
        "\n",
        "plot([\n",
        "    (\"apply_mask(loudness_guitars_raw, guitar_mask)\", False, 0, \"Guitars\"),\n",
        "    (\"apply_mask(loudness_voice_raw, voice_mask)\", False, 0, \"Voice\")\n",
        "], title=\"Loudness\", y_label=\"Decibels\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=10)\n",
        "\n",
        "plot([\n",
        "    (\"apply_mask(melodic_centroid_raw, voice_mask)\", False, 0, \"Melodic Voice Contour\"),\n",
        "    (\"apply_mask(harmonic_centroid_raw, guitar_mask)\", False, 0, \"Harmonic Guitars Contour\")\n",
        "], title=\"Melodic Voice and Harmonic Guitars Contour\", y_label=\"Pitch (Hz/MIDI)\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=11)\n",
        "\n",
        "plot([\n",
        "    (\"apply_mask(onsets['Vocals']['counts'], voice_mask)\", False, 0, \"Voice\"),\n",
        "    (\"apply_mask(onsets['Guitars']['counts'], guitar_mask)\", False, 0, \"Guitars\")\n",
        "], title=\"Rhythmic Density\", y_label=\"Onset Counts\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=12)\n",
        "\n",
        "plot([\n",
        "    (\"bpm_diff_aligned_raw\", True, 0, \"Tempo Deviations\"),\n",
        "    (\"df_qualities['Tonal_Dissonance']\", False, 0, \"Tonal Dissonance\"),\n",
        "    (\"df_qualities['Tonal_Dispersion']\", False, 0, \"Tonal Dispersion\")\n",
        "], title=\"Rhythmic and Harmonic Features\", y_label=\"Norm. Tempo Dev./Tonal Values\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=13)\n",
        "\n",
        "plot([\n",
        "    (\"bpm_diff_aligned_raw\", True, 0, \"Tempo Deviations\"),\n",
        "    (\"apply_mask(loudness_guitars_raw, guitar_mask)\", True, 0, \"Guitars Loudness\"),\n",
        "    (\"apply_mask(loudness_voice_raw, voice_mask)\", True, 0, \"Voice Loudness\")\n",
        "], title=\"Loudness Curves and Tempo Deviations\", y_label=\"Normalized Values\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=14)\n",
        "\n",
        "plot([\n",
        "    (\"bpm_diff_aligned_raw\", True, 0, \"Tempo Deviations\"),\n",
        "    (\"apply_mask(melodic_centroid_raw, voice_mask)\", True, 0, \"Melodic Voice Contour\"),\n",
        "    (\"apply_mask(harmonic_centroid_raw, guitar_mask)\", True, 0, \"Harmonic Guitars Contour\")\n",
        "], title=\"Melodic/Harmonic Contours and Tempo Deviations\", y_label=\"Normalized Values\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=15)\n",
        "\n",
        "plot([\n",
        "    (\"bpm_diff_aligned_raw\", True, 1, \"Tempo Deviations\"),\n",
        "    (\"apply_mask(onsets['Guitars']['counts'], guitar_mask)\", True, 1, \"Rhythmic Density: Guitars\"),\n",
        "    (\"apply_mask(onsets['Vocals']['counts'], voice_mask)\", True, 1, \"Rhythmic Density: Vocals\")\n",
        "], title=\"Rhythmic Density and Tempo Deviations\", y_label=\"Normalized Values\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=16)\n",
        "\n",
        "plot([\n",
        "    (\"apply_mask(melodic_centroid_raw, voice_mask)\", True, 0, \"Melodic Voice Contour\"),\n",
        "    (\"apply_mask(loudness_voice_raw, voice_mask)\", True, 0, \"Loudness: Vocals\")\n",
        "], title=\"Melodic Voice Contour and Voice Loudness\", y_label=\"Normalized Values\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=17)\n",
        "\n",
        "plot([\n",
        "    (\"df_qualities['Tonal_Dissonance']\", True, 0, \"Tonal Dissonance\"),\n",
        "    (\"apply_mask(harmonic_centroid_raw, guitar_mask)\", True, 0, \"Harmonic Guitars Contour\")\n",
        "], title=\"Tonal Dissonance and Harmonic Guitars Contour\", y_label=\"Normalized Values\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual Analysis (Outliers Detection)"
      ],
      "metadata": {
        "id": "8gfMg9yqntKL"
      },
      "id": "8gfMg9yqntKL"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "# Parameters\n",
        "normalize_curves = True  # Set to False if you want raw values\n",
        "z_threshold = 2.5        # Z-score threshold for outliers\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"saved_plots\", exist_ok=True)\n",
        "plot_counter = 18  # Starting index\n",
        "\n",
        "# Data dictionary\n",
        "data_for_distance = {\n",
        "    'Tempo Deviation': emd_data_masked['Tempo Deviation'],\n",
        "    'Voice Rhythmic Density': emd_data_masked['Voice Rhythmic Density'],\n",
        "    'Guitars Rhythmic Density': emd_data_masked['Guitars Rhythmic Density'],\n",
        "    'Voice Loudness': emd_data_masked['Voice Loudness'],\n",
        "    'Guitars Loudness': emd_data_masked['Guitars Loudness'],\n",
        "    'Tonal Dissonance': emd_data_masked['Tonal Dissonance'],\n",
        "    'Tonal Dispersion': emd_data_masked['Tonal Dispersion'],\n",
        "    'Melodic Contour': emd_data_masked['Melodic Contour'],\n",
        "    'Harmonic Contour': emd_data_masked['Harmonic Contour'],\n",
        "}\n",
        "\n",
        "for var_a, var_b in itertools.combinations(data_for_distance.keys(), 2):\n",
        "    a, b = data_for_distance[var_a], data_for_distance[var_b]\n",
        "    if len(a) == 0 or len(b) == 0:\n",
        "        print(f\"Skipping ({var_a}, {var_b}): empty series.\")\n",
        "        continue\n",
        "\n",
        "    # Apply masks\n",
        "    if \"Voice\" in var_a:\n",
        "        a = apply_mask(a, voice_mask)\n",
        "    elif \"Guitars\" in var_a:\n",
        "        a = apply_mask(a, guitar_mask)\n",
        "\n",
        "    if \"Voice\" in var_b:\n",
        "        b = apply_mask(b, voice_mask)\n",
        "    elif \"Guitars\" in var_b:\n",
        "        b = apply_mask(b, guitar_mask)\n",
        "\n",
        "    # Synchronize lengths\n",
        "    min_len = min(len(a), len(b))\n",
        "    a_sync, b_sync = np.asarray(a[:min_len]), np.asarray(b[:min_len])\n",
        "    time_axis = beat_times[:min_len]\n",
        "\n",
        "    # Preserve NaNs in residuals\n",
        "    residuals = np.full_like(b_sync, np.nan, dtype=float)\n",
        "    valid_mask = np.isfinite(a_sync) & np.isfinite(b_sync)\n",
        "    if np.sum(valid_mask) < 2:\n",
        "        print(f\"Skipping ({var_a}, {var_b}): insufficient valid data.\")\n",
        "        continue\n",
        "\n",
        "    # Correlation check\n",
        "    corr = corr_matrix.loc[var_a, var_b] if var_a in corr_matrix.columns and var_b in corr_matrix.index else 0\n",
        "    if not np.isfinite(corr) or abs(corr) < 0.6:\n",
        "        print(f\"Skipping ({var_a}, {var_b}): correlation {corr:.2f} < 0.6 or NaN.\")\n",
        "        continue\n",
        "\n",
        "    # Optional normalization\n",
        "    if normalize_curves:\n",
        "        a_valid = (a_sync[valid_mask] - np.mean(a_sync[valid_mask])) / np.std(a_sync[valid_mask])\n",
        "        b_valid = (b_sync[valid_mask] - np.mean(b_sync[valid_mask])) / np.std(b_sync[valid_mask])\n",
        "    else:\n",
        "        a_valid = a_sync[valid_mask]\n",
        "        b_valid = b_sync[valid_mask]\n",
        "\n",
        "    # Linear regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(a_valid.reshape(-1, 1), b_valid)\n",
        "    predicted = model.predict(a_valid.reshape(-1, 1))\n",
        "    residuals[valid_mask] = b_valid - predicted\n",
        "\n",
        "    # Z-score outlier detection\n",
        "    finite_vals = residuals[np.isfinite(residuals)]\n",
        "    z_scores = (finite_vals - np.mean(finite_vals)) / np.std(finite_vals)\n",
        "    pos_idx = np.where(z_scores > z_threshold)[0]\n",
        "    neg_idx = np.where(z_scores < -z_threshold)[0]\n",
        "    pos_times = time_axis[valid_mask][pos_idx]\n",
        "    neg_times = time_axis[valid_mask][neg_idx]\n",
        "\n",
        "    # Plot without interpolation across NaNs\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    start = None\n",
        "    for i in range(len(residuals)):\n",
        "        if np.isfinite(residuals[i]):\n",
        "            if start is None:\n",
        "                start = i\n",
        "        else:\n",
        "            if start is not None:\n",
        "                plt.plot(time_axis[start:i], residuals[start:i], color='blue', label=\"Residuals\" if start == 0 else \"\")\n",
        "                start = None\n",
        "    if start is not None:\n",
        "        plt.plot(time_axis[start:], residuals[start:], color='blue', label=\"Residuals\")\n",
        "\n",
        "    # Highlight positive and negative Z-score outliers\n",
        "    plt.scatter(pos_times, residuals[valid_mask][pos_idx], color='red', marker='o', s=80, label=f'Positive Z>|{z_threshold}|')\n",
        "    plt.scatter(neg_times, residuals[valid_mask][neg_idx], color='green', marker='o', s=80, label=f'Negative Z<-|{z_threshold}|')\n",
        "\n",
        "    # Format axes\n",
        "    format_axes(plt.gca(), time_axis, df_sections, df_phrases,\n",
        "                title=f\"{var_a} vs. {var_b} (EMD Corr: {corr:.2f})\", mode=\"time\")\n",
        "    plt.grid(False)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and show plot\n",
        "    plot_path = os.path.join(\"saved_plots\", f\"plot_{plot_counter}.pdf\")\n",
        "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
        "    print(f\"Saved plot to {plot_path}\")\n",
        "    plt.show()\n",
        "    plot_counter += 1"
      ],
      "metadata": {
        "id": "XaDkLEdLnohk"
      },
      "id": "XaDkLEdLnohk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "xbv15hdB9yNE",
      "metadata": {
        "id": "xbv15hdB9yNE"
      },
      "source": [
        "## 11) Additional Plots (TIV Qualities, Tonnetz and Keyscape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Violin Plot of Tonal Qualities\n",
        "\n",
        "if 'df_qualities' in locals() and not df_qualities.empty:\n",
        "    qualities_to_plot = [\n",
        "        'Chromaticity', 'Dyadicity', 'Triadicity', 'Diatonicity',\n",
        "        'Dim_Quality', 'Wholetoneness']\n",
        "    qualities_to_plot = [q for q in qualities_to_plot if q in df_qualities.columns]\n",
        "\n",
        "    if qualities_to_plot:\n",
        "        df_qualities_melted = df_qualities[qualities_to_plot].melt(var_name='Quality Type', value_name='Value')\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.violinplot(x='Quality Type', y='Value', data=df_qualities_melted, inner='quartile')\n",
        "        plt.title('Distribution of Tonal Qualities')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('Quality')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"saved_plots/plot_4.pdf\", bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"None of the specified quality columns were found in df_qualities.\")\n",
        "else:\n",
        "    print(\"df_qualities not found or is empty.\")\n",
        "\n",
        "\n",
        "# Bar Plot of Global Chroma (Section 2)\n",
        "if 'global_chroma_beats_sec2' in locals() and global_chroma_beats_sec2 is not None:\n",
        "    chroma_vector = np.asarray(global_chroma_beats_sec2)\n",
        "    if chroma_vector.size == 12:\n",
        "        chroma_labels = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(chroma_labels, chroma_vector)\n",
        "        plt.ylabel('Activation')\n",
        "        plt.title('Global Chroma Vector (Section 2)')\n",
        "        plt.xlabel('Pitch Class')\n",
        "        plt.ylim(0, np.max(chroma_vector) * 1.1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"saved_plots/plot_5.pdf\", bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "    elif chroma_vector.size > 0:\n",
        "         print(f\"Global Chroma vector has size {chroma_vector.size}, expected 12 for bar plot.\")\n",
        "    else:\n",
        "        print(\"Global Chroma vector is empty.\")\n",
        "else:\n",
        "    print(\"global_chroma_beats_sec2 not found or is None.\")"
      ],
      "metadata": {
        "id": "simrMAcgRJpz"
      },
      "id": "simrMAcgRJpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rSvpJ_iA8H44",
      "metadata": {
        "id": "rSvpJ_iA8H44"
      },
      "outputs": [],
      "source": [
        "# Tonnetz From Phase Space Visualization\n",
        "\n",
        "from matplotlib.colors import Normalize, ListedColormap\n",
        "from matplotlib.collections import LineCollection\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import numpy as np # Ensure numpy is imported here if needed\n",
        "\n",
        "\n",
        "# Utility\n",
        "def wrap_angle(x):\n",
        "    \"\"\"Wrap angles to [-π, π].\"\"\"\n",
        "    return (x + np.pi) % (2*np.pi) - np.pi\n",
        "\n",
        "\n",
        "def duplicate_on_borders(x, y, labels, boundary=0.2):\n",
        "    \"\"\"Duplicate pitch classes or chords near ±π boundaries.\"\"\"\n",
        "    xs, ys, lbls = list(x), list(y), list(labels)\n",
        "    for xi, yi, li in zip(x, y, labels):\n",
        "        shifts = []\n",
        "        if xi > np.pi - boundary:   shifts.append((-2*np.pi, 0))\n",
        "        if xi < -np.pi + boundary:  shifts.append((+2*np.pi, 0))\n",
        "        if yi > np.pi - boundary:   shifts.append((0, -2*np.pi))\n",
        "        if yi < -np.pi + boundary:  shifts.append((0, +2*np.pi))\n",
        "        if (xi > np.pi - boundary and yi > np.pi - boundary):   shifts.append((-2*2*np.pi, -2*np.pi))\n",
        "        if (xi > np.pi - boundary and yi < -np.pi + boundary):  shifts.append((-2*np.pi, +2*np.pi))\n",
        "        if (xi < -np.pi + boundary and yi > np.pi - boundary):  shifts.append((+2*np.pi, -2*np.pi))\n",
        "        if (xi < -np.pi + boundary and yi < -np.pi + boundary): shifts.append((+2*np.pi, +2*np.pi))\n",
        "        for dx, dy in shifts:\n",
        "            xs.append(xi + dx)\n",
        "            ys.append(yi + dy)\n",
        "            lbls.append(li)\n",
        "    return np.array(xs), np.array(ys), lbls\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Prepare base coordinates and interactive plot setup\n",
        "# Only proceed if tiv_beats is valid\n",
        "# ------------------------------------------------------------\n",
        "if isinstance(tiv_beats, np.ndarray) and tiv_beats.size > 0 and tiv_beats.shape[1] >= 5:\n",
        "    tiv_vectors_np = tiv_beats\n",
        "\n",
        "    phase3 = np.angle(tiv_vectors_np[:, 2])  # component 3\n",
        "    phase5 = np.angle(tiv_vectors_np[:, 4])  # component 5\n",
        "\n",
        "    chroma_labels = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
        "\n",
        "    # --- convert key tuple like ('gb','min') → 'F#'\n",
        "    def key_to_pitch(key_tuple):\n",
        "        if not key_tuple or not isinstance(key_tuple, (tuple, list)) or len(key_tuple) == 0:\n",
        "            return 'C'\n",
        "        key_name = key_tuple[0].capitalize()\n",
        "        enharmonics = {\n",
        "            'Gb': 'F#', 'Db': 'C#', 'Ab': 'G#', 'Eb': 'D#', 'Bb': 'A#',\n",
        "            'Cb': 'B',  'Fb': 'E'\n",
        "        }\n",
        "        return enharmonics.get(key_name, key_name)\n",
        "\n",
        "    # Ensure key is available; if not, default to 'C'\n",
        "    center_init = key_to_pitch(globals().get('key_section2', ('C', 'maj')))\n",
        "\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Compute chord reference positions\n",
        "    # ------------------------------------------------------------\n",
        "    def chord_positions(intervals, label_func):\n",
        "        xs, ys, lbls = [], [], []\n",
        "        for i, label in enumerate(chroma_labels):\n",
        "            chord_vec = np.zeros(12)\n",
        "            for interval in intervals:\n",
        "                chord_vec[(i + interval) % 12] = 1\n",
        "            tiv_chord = tiv.from_pcp(chord_vec)\n",
        "            if tiv_chord.vector.shape[0] < 5:\n",
        "                continue\n",
        "            x, y = np.angle(tiv_chord.vector[2]), np.angle(tiv_chord.vector[4])\n",
        "            xs.append(x)\n",
        "            ys.append(y)\n",
        "            lbls.append(label_func(label))\n",
        "        return np.array(xs), np.array(ys), lbls\n",
        "\n",
        "    base_pc_x, base_pc_y, base_pc_labels = chord_positions([0], lambda l: l)\n",
        "    base_maj_x, base_maj_y, base_maj_labels = chord_positions([0,4,7], lambda l: l)\n",
        "    base_min_x, base_min_y, base_min_labels = chord_positions([0,3,7], lambda l: l.lower())\n",
        "\n",
        "\n",
        "    # ============================================================\n",
        "    # Interactive Plot Function\n",
        "    # ============================================================\n",
        "    def plot_tonnetz(center_pitch, start_beat, end_beat):\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.xlim([-np.pi-0.1, np.pi+0.1])\n",
        "        plt.ylim([-np.pi-0.1, np.pi+0.1])\n",
        "        plt.gca().set_aspect('equal')\n",
        "\n",
        "        # --- Compute centering offset ---\n",
        "        idx_center = chroma_labels.index(center_pitch)\n",
        "        tiv_center = tiv.from_pcp(np.eye(12)[idx_center])\n",
        "        cx, cy = np.angle(tiv_center.vector[2]), np.angle(tiv_center.vector[4])\n",
        "\n",
        "        # Pitch classes (with wrapping)\n",
        "        pcx, pcy, pc_labels = duplicate_on_borders(\n",
        "            wrap_angle(base_pc_x - cx),\n",
        "            wrap_angle(base_pc_y - cy),\n",
        "            base_pc_labels\n",
        "        )\n",
        "        majx, majy, maj_labels = duplicate_on_borders(\n",
        "            wrap_angle(base_maj_x - cx),\n",
        "            wrap_angle(base_maj_y - cy),\n",
        "            base_maj_labels\n",
        "        )\n",
        "        minx, miny, min_labels = duplicate_on_borders(\n",
        "            wrap_angle(base_min_x - cx),\n",
        "            wrap_angle(base_min_y - cy),\n",
        "            base_min_labels\n",
        "        )\n",
        "\n",
        "        # Audio trajectory (recentering and wrapping)\n",
        "        trajx = wrap_angle(phase3 - cx)\n",
        "        trajy = wrap_angle(phase5 - cy)\n",
        "\n",
        "        # --- Plot points ---\n",
        "        plt.scatter(pcx, pcy, c='red', s=300, marker='o', edgecolors='black', zorder=4)\n",
        "        for x, y, l in zip(pcx, pcy, pc_labels):\n",
        "            plt.text(x, y, l, fontsize=8, ha='center', va='center', zorder=5)\n",
        "\n",
        "        plt.scatter(majx, majy, s=200, c='white', edgecolors='black', marker='s', zorder=6)\n",
        "        for x, y, l in zip(majx, majy, maj_labels):\n",
        "            plt.text(x, y, l, fontsize=8, ha='center', va='center', zorder=7)\n",
        "\n",
        "        plt.scatter(minx, miny, s=200, c='white', edgecolors='black', marker='D', zorder=6)\n",
        "        for x, y, l in zip(minx, miny, min_labels):\n",
        "            plt.text(x, y, l, fontsize=8, ha='center', va='center', zorder=7)\n",
        "\n",
        "        # --- Audio trajectory ---\n",
        "        plt.scatter(trajx, trajy, alpha=0.5, s=10, zorder=2)\n",
        "        # Ensure slice indices are within bounds\n",
        "        start_idx = max(0, min(start_beat, len(trajx) - 1))\n",
        "        end_idx = max(0, min(end_beat, len(trajx) - 1))\n",
        "\n",
        "        if start_idx <= end_idx < len(trajx):\n",
        "             seg_x, seg_y = trajx[start_idx:end_idx+1], trajy[start_idx:end_idx+1]\n",
        "             if len(seg_x) > 1: # Only plot trajectory if there are at least two points\n",
        "                 pts = np.array([seg_x, seg_y]).T.reshape(-1, 1, 2)\n",
        "                 segs = np.concatenate([pts[:-1], pts[1:]], axis=1)\n",
        "                 norm = Normalize(vmin=start_beat, vmax=end_beat)\n",
        "                 lc = LineCollection(segs, cmap='viridis', norm=norm, linewidth=2, linestyle='--')\n",
        "                 lc.set_array(np.arange(start_beat, end_beat))\n",
        "                 plt.gca().add_collection(lc)\n",
        "\n",
        "\n",
        "        plt.title(f\"Tonnetz Phase Space (center: {center_pitch})\")\n",
        "        plt.xlabel(\"Phase of Component 3\")\n",
        "        plt.ylabel(\"Phase of Component 5\")\n",
        "        plt.grid(False)\n",
        "        plt.savefig(\"./saved_plots/plot_3.pdf\", bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # Widgets\n",
        "    max_beats = len(tiv_beats)\n",
        "    # Set default values for the first 8 beats (0-indexed)\n",
        "    start_box = widgets.BoundedIntText(value=0, min=0, max=max_beats-1, step=1, description=\"Start Beat\")\n",
        "    end_box   = widgets.BoundedIntText(value=min(7, max_beats-1), min=0, max=max_beats-1, step=1, description=\"End Beat\")\n",
        "    center_box = widgets.Dropdown(options=chroma_labels, value=center_init, description='Center Pitch')\n",
        "\n",
        "    # Function to update end_box max value when start_box changes\n",
        "    def update_end_box_max(change):\n",
        "        start_val = change['new']\n",
        "        end_box.max = max_beats - 1 # Always allow max_beats - 1 as max possible end\n",
        "        if end_box.value < start_val:\n",
        "            end_box.value = start_val # Ensure end is not less than start\n",
        "\n",
        "    start_box.observe(update_end_box_max, names='value')\n",
        "\n",
        "\n",
        "    # --- Dropdown de frases (Phrases Dropdown) ---\n",
        "    # Ensure df_phrases is available and not empty\n",
        "    if 'df_phrases' in globals() and df_phrases is not None and not df_phrases.empty:\n",
        "        phrase_labels = df_phrases['Label'].tolist()\n",
        "        # Add an option to clear phrase selection\n",
        "        phrase_options = ['Select Phrase'] + phrase_labels\n",
        "        phrase_dropdown = widgets.Dropdown(options=phrase_options, description='Phrase')\n",
        "\n",
        "        # Function to find beat indices\n",
        "        def find_beat_indices(initial_time, duration, beat_times):\n",
        "            # Find the beat index closest to the initial time\n",
        "            start_idx = np.argmin(np.abs(beat_times - initial_time))\n",
        "            # Find the beat index closest to the end time (initial + duration)\n",
        "            end_time = initial_time + duration\n",
        "            # We want the beat *after* the end time for the interval, so use side='right'\n",
        "            end_idx = np.searchsorted(beat_times, end_time, side='left')\n",
        "            # Adjust end_idx to be the last beat index *within* or *at* the end of the interval\n",
        "            end_idx = max(0, end_idx - 1)\n",
        "            return start_idx, end_idx\n",
        "\n",
        "\n",
        "        def on_phrase_change(change):\n",
        "            label = change['new']\n",
        "            if label == 'Select Phrase':\n",
        "                 # Optionally reset to default or do nothing\n",
        "                 start_box.value = 0\n",
        "                 end_box.value = min(7, max_beats-1)\n",
        "                 return\n",
        "\n",
        "            # Ensure df_phrases is still valid\n",
        "            if 'df_phrases' in globals() and df_phrases is not None and not df_phrases.empty:\n",
        "                phrase = df_phrases[df_phrases['Label'] == label].iloc[0]\n",
        "                # Ensure beat_times is valid before calling find_beat_indices\n",
        "                if 'beat_times' in globals() and beat_times is not None and len(beat_times) > 1:\n",
        "                    start_idx, end_idx = find_beat_indices(phrase['Initial_Time'], phrase['Duration'], beat_times)\n",
        "                    # Ensure indices are within the valid range of tiv_beats indices\n",
        "                    start_box.value = max(0, min(start_idx, max_beats - 1))\n",
        "                    end_box.value = max(0, min(end_idx, max_beats - 1))\n",
        "\n",
        "\n",
        "        phrase_dropdown.observe(on_phrase_change, names='value')\n",
        "\n",
        "        ui = widgets.VBox([\n",
        "            widgets.HBox([center_box, start_box, end_box]),\n",
        "            phrase_dropdown\n",
        "        ])\n",
        "    else:\n",
        "        # If no phrases, just display the other widgets\n",
        "        ui = widgets.HBox([center_box, start_box, end_box])\n",
        "        print(\"Warning: Phrase data not available. Phrase dropdown not displayed.\")\n",
        "\n",
        "\n",
        "    # Interactive Output\n",
        "    out = widgets.interactive_output(plot_tonnetz, {\n",
        "        'center_pitch': center_box,\n",
        "        'start_beat': start_box,\n",
        "        'end_beat': end_box\n",
        "    })\n",
        "\n",
        "    # Display Interface\n",
        "    display(ui, out)\n",
        "\n",
        "else:\n",
        "    print(\"Error: tiv_beats not found, is empty, or does not have enough components to plot Tonnetz.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "snyDPR4b8aVm",
      "metadata": {
        "id": "snyDPR4b8aVm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import colorsys\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from collections import Counter\n",
        "\n",
        "# Circle of fifths ordering\n",
        "circle_maj = [\"C:maj\", \"G:maj\", \"D:maj\", \"A:maj\", \"E:maj\", \"B:maj\",\n",
        "              \"F#:maj\", \"C#:maj\", \"G#:maj\", \"D#:maj\", \"A#:maj\", \"F:maj\"]\n",
        "circle_min = [\"A:min\", \"E:min\", \"B:min\", \"F#:min\", \"C#:min\", \"G#:min\",\n",
        "              \"D#:min\", \"A#:min\", \"F:min\", \"C:min\", \"G:min\", \"D:min\"]\n",
        "\n",
        "circle_keys = circle_maj + circle_min\n",
        "key_to_idx = {k: i for i, k in enumerate(circle_keys)}\n",
        "idx_to_key = {i: k for k, i in key_to_idx.items()}\n",
        "\n",
        "# Enharmonic normalization\n",
        "ENHARMONIC_FLAT_TO_SHARP = {\n",
        "    'Cb': 'B',  'Db': 'C#', 'Eb': 'D#', 'Fb': 'E',\n",
        "    'Gb': 'F#', 'Ab': 'G#', 'Bb': 'A#'\n",
        "}\n",
        "ENHARMONIC_OTHER = {'B#': 'C', 'E#': 'F'}\n",
        "\n",
        "def canonical_tonic(raw):\n",
        "    if raw is None:\n",
        "        return None\n",
        "    s = str(raw).strip().replace('♭', 'b').replace('♯', '#')\n",
        "    root = s[0].upper()\n",
        "    acc = s[1:] if len(s) > 1 else ''\n",
        "    acc = acc.replace('B', 'b') if acc.lower() == 'b' else acc\n",
        "    tonic = root + acc\n",
        "    if tonic in ENHARMONIC_FLAT_TO_SHARP:\n",
        "        return ENHARMONIC_FLAT_TO_SHARP[tonic]\n",
        "    if tonic in ENHARMONIC_OTHER:\n",
        "        return ENHARMONIC_OTHER[tonic]\n",
        "    if len(tonic) == 2 and tonic[1] in ('#', 'b'):\n",
        "        return tonic[0] + tonic[1]\n",
        "    return tonic\n",
        "\n",
        "def canonical_quality(raw_q):\n",
        "    if raw_q is None:\n",
        "        return None\n",
        "    s = str(raw_q).strip().lower()\n",
        "    if s in ('maj', 'major', 'mjr', 'ma'):\n",
        "        return 'maj'\n",
        "    if s in ('min', 'minor', 'm', 'mi'):\n",
        "        return 'min'\n",
        "    if s.startswith('m'):\n",
        "        return 'min'\n",
        "    return 'maj'\n",
        "\n",
        "def normalize_key_output(raw):\n",
        "    if raw is None:\n",
        "        return None\n",
        "    tonic = None\n",
        "    quality = None\n",
        "    if isinstance(raw, (list, tuple)):\n",
        "        if len(raw) >= 1:\n",
        "            tonic = raw[0]\n",
        "        if len(raw) >= 2:\n",
        "            quality = raw[1]\n",
        "    elif isinstance(raw, dict):\n",
        "        tonic = raw.get('tonic') or raw.get('key') or raw.get('root') or raw.get('label') or raw.get('name')\n",
        "        quality = raw.get('quality') or raw.get('mode') or raw.get('type') or raw.get('label_mode')\n",
        "    else:\n",
        "        s = str(raw).strip()\n",
        "        if ':' in s:\n",
        "            tonic, quality = s.split(':', 1)\n",
        "        elif ' ' in s:\n",
        "            tonic, quality = s.split(None, 1)\n",
        "        else:\n",
        "            tonic = s\n",
        "    tonic_c = canonical_tonic(tonic)\n",
        "    quality_c = canonical_quality(quality)\n",
        "    if tonic_c is None or quality_c is None:\n",
        "        return None\n",
        "    return f\"{tonic_c}:{quality_c}\"\n",
        "\n",
        "def infer_and_normalize_keys(tiv_beats_objs, mode=\"temperley\", verbose=False):\n",
        "    normalized = []\n",
        "    for i, t in enumerate(tiv_beats_objs):\n",
        "        try:\n",
        "            raw = t.key(mode=mode)\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"Beat {i}: ERROR calling .key(): {e}\")\n",
        "            normalized.append(None)\n",
        "            continue\n",
        "        nk = normalize_key_output(raw)\n",
        "        if verbose:\n",
        "            print(f\"Beat {i}: raw={raw} -> normalized={nk}\")\n",
        "        normalized.append(nk)\n",
        "    return normalized\n",
        "\n",
        "def compute_keyscape_from_keyseq(key_seq):\n",
        "    N = len(key_seq)\n",
        "    scape_matrix = np.full((N, N), np.nan)\n",
        "    lengths = np.arange(1, N + 1)\n",
        "    centers = np.arange(N)\n",
        "    for s in range(N):\n",
        "        for t in range(s, N):\n",
        "            length = t - s + 1\n",
        "            center = (s + t) // 2\n",
        "            segment = key_seq[s:t+1]\n",
        "            valid = [k for k in segment if (k is not None and k in key_to_idx)]\n",
        "            if not valid:\n",
        "                continue\n",
        "            cnt = Counter(valid)\n",
        "            best_key = cnt.most_common(1)[0][0]\n",
        "            scape_matrix[length-1, center] = key_to_idx[best_key]\n",
        "    return scape_matrix, centers, lengths\n",
        "\n",
        "def make_major_minor_colors(major_brightness=0.95, minor_brightness=0.45):\n",
        "    major_colors = []\n",
        "    minor_colors = []\n",
        "    for i in range(12):\n",
        "        hue = i / 12.0\n",
        "        r_maj, g_maj, b_maj = colorsys.hsv_to_rgb(hue, 0.85, major_brightness)\n",
        "        major_colors.append([r_maj, g_maj, b_maj, 1.0])\n",
        "        r_min, g_min, b_min = colorsys.hsv_to_rgb(hue, 0.85, minor_brightness)\n",
        "        minor_colors.append([r_min, g_min, b_min, 1.0])\n",
        "    return major_colors, minor_colors\n",
        "\n",
        "def make_full_cmap(major_colors, minor_colors):\n",
        "    return ListedColormap(major_colors + minor_colors)\n",
        "\n",
        "def plot_keyscape_circle(scape_matrix, centers, lengths, fname=None):\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    scape_masked = np.ma.masked_invalid(scape_matrix)\n",
        "    major_colors, minor_colors = make_major_minor_colors()\n",
        "    cmap = make_full_cmap(major_colors, minor_colors)\n",
        "    im = ax.imshow(scape_masked, origin='lower', aspect='auto',\n",
        "                   extent=[centers[0], centers[-1], lengths[0], lengths[-1]],\n",
        "                   cmap=cmap, vmin=0, vmax=len(key_to_idx)-1, interpolation='nearest')\n",
        "    ax.set_xlabel(\"Beat\", fontsize=12)\n",
        "    ax.set_ylabel(\"Segment length (beats)\", fontsize=12)\n",
        "    ax.set_title(\"Keyscape\", fontsize=14, fontweight='bold')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax_major = divider.append_axes(\"right\", size=\"2.5%\", pad=0.1)\n",
        "    cax_minor = divider.append_axes(\"right\", size=\"2.5%\", pad=0.6)\n",
        "    maj_cmap = ListedColormap(major_colors)\n",
        "    norm_major = plt.matplotlib.colors.BoundaryNorm(np.arange(13) - 0.5, 12)\n",
        "    cb_major = plt.colorbar(plt.cm.ScalarMappable(norm=norm_major, cmap=maj_cmap),\n",
        "                            cax=cax_major, ticks=np.arange(12))\n",
        "    cb_major.ax.set_yticklabels(circle_maj, fontsize=9)\n",
        "    cb_major.set_label(\"Major Keys\", fontsize=10, fontweight='bold')\n",
        "    min_cmap = ListedColormap(minor_colors)\n",
        "    norm_minor = plt.matplotlib.colors.BoundaryNorm(np.arange(13) - 0.5, 12)\n",
        "    cb_minor = plt.colorbar(plt.cm.ScalarMappable(norm=norm_minor, cmap=min_cmap),\n",
        "                            cax=cax_minor, ticks=np.arange(12))\n",
        "    cb_minor.ax.set_yticklabels(circle_min, fontsize=9)\n",
        "    cb_minor.set_label(\"Relative Minor Keys\", fontsize=10, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    if fname:\n",
        "        plt.savefig(fname, bbox_inches=\"tight\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "# 1. Inferir e normalizar as tonalidades\n",
        "key_seq = infer_and_normalize_keys(tiv_beats_objs, mode=\"temperley\", verbose=False)\n",
        "\n",
        "# 2. Calcular a matriz Keyscape\n",
        "scape_matrix, centers, lengths = compute_keyscape_from_keyseq(key_seq)\n",
        "\n",
        "# 3. Visualizar\n",
        "plot_keyscape_circle(scape_matrix, centers, lengths, fname=\"saved_plots/plot_2.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NUJ3ixbYBpjZ",
      "metadata": {
        "id": "NUJ3ixbYBpjZ"
      },
      "source": [
        "## 12) Audios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oPdHvWOhBn-E",
      "metadata": {
        "id": "oPdHvWOhBn-E"
      },
      "outputs": [],
      "source": [
        "audio_output = False\n",
        "\n",
        "# Create multiple audio displays\n",
        "if audio_output:\n",
        "  # Display song\n",
        "  print(\"Original Song:\")\n",
        "  display(Audio(y_full, rate=sr))\n",
        "\n",
        "  # Display original vocals\n",
        "  print(\"Original Vocals:\")\n",
        "  display(Audio(y_vocals, rate=sr))\n",
        "\n",
        "  # Display original guitars\n",
        "  print(\"\\nOriginal Guitars:\")\n",
        "  display(Audio(y_guitars, rate=sr))\n",
        "\n",
        "  # Display harmonic component of guitars\n",
        "  print(\"\\nHarmonic Component of Guitars:\")\n",
        "  display(Audio(y_harmonic, rate=sr))\n",
        "\n",
        "  # Display percussive component of guitars\n",
        "  print(\"\\nPercussive Component of Guitars:\")\n",
        "  display(Audio(y_percussive, rate=sr))\n",
        "\n",
        "  # Prepare audio with clicks\n",
        "\n",
        "  # Create a click sound\n",
        "  click_duration = 0.01  # seconds\n",
        "  click_frequency = 1000  # Hz\n",
        "  click_samples = int(click_duration * sr)\n",
        "  click_wave = 0.5 * np.sin(2 * np.pi * click_frequency * np.linspace(0, click_duration, click_samples, endpoint=False))\n",
        "  click_amplitude = 0.5 # Use a consistent amplitude\n",
        "\n",
        "  def add_clicks_to_audio(y_audio, peak_times, sr, click_wave, click_amplitude):\n",
        "      \"\"\"Adds clicks to an audio signal at specified peak times.\"\"\"\n",
        "      clicks_audio = np.zeros_like(y_audio)\n",
        "      for peak_time in peak_times:\n",
        "          peak_sample = int(peak_time * sr)\n",
        "          start_sample = peak_sample\n",
        "          end_sample = min(len(clicks_audio), start_sample + len(click_wave))\n",
        "          if start_sample < end_sample:\n",
        "              clicks_audio[start_sample:end_sample] += click_wave[0:end_sample-start_sample] * click_amplitude\n",
        "      return y_audio + clicks_audio\n",
        "\n",
        "  # Display vocals with onset clicks\n",
        "  if 'onsets' in globals() and 'Vocals' in onsets and 'peak_times' in onsets['Vocals']:\n",
        "      print(\"\\nVocals with Onset Clicks:\")\n",
        "      mixed_vocals_clicks = add_clicks_to_audio(y_vocals, onsets['Vocals']['peak_times'], sr, click_wave, click_amplitude)\n",
        "      mixed_vocals_clicks = mixed_vocals_clicks / np.max(np.abs(mixed_vocals_clicks)) # Normalize\n",
        "      display(Audio(mixed_vocals_clicks, rate=sr))\n",
        "  else:\n",
        "      print(\"\\nVocals onsets not available.\")\n",
        "\n",
        "\n",
        "  # Display guitars with onset clicks\n",
        "  if 'onsets' in globals() and 'Guitars' in onsets and 'peak_times' in onsets['Guitars']:\n",
        "      print(\"\\nGuitars with Onset Clicks:\")\n",
        "      # Use onsets['Guitars']['peak_times'] for guitar onsets\n",
        "      mixed_guitars_clicks = add_clicks_to_audio(y_guitars, onsets['Guitars']['peak_times'], sr, click_wave, click_amplitude)\n",
        "      mixed_guitars_clicks = mixed_guitars_clicks / np.max(np.abs(mixed_guitars_clicks)) # Normalize\n",
        "      display(Audio(mixed_guitars_clicks, rate=sr))\n",
        "  else:\n",
        "      print(\"\\nGuitars onsets not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation pipeline"
      ],
      "metadata": {
        "id": "e5YHdjT1W9de"
      },
      "id": "e5YHdjT1W9de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Ground-truth Chromas and TIVs"
      ],
      "metadata": {
        "id": "L5_QX6NKbakD"
      },
      "id": "L5_QX6NKbakD"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "\n",
        "# --- Chord to Chroma Mapping ---\n",
        "chroma_mapping = {\n",
        "    'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3, 'E': 4, 'F': 5,\n",
        "    'F#': 6, 'Gb': 6, 'G': 7, 'G#': 8, 'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, 'B': 11,\n",
        "    'N': -1\n",
        "}\n",
        "\n",
        "# Pitch class distributions\n",
        "quality_patterns = {\n",
        "    'maj': np.array([1,0,0,0,1,0,0,1,0,0,0,0]),\n",
        "    'min': np.array([1,0,0,1,0,0,0,1,0,0,0,0]),\n",
        "    '7': np.array([1,0,0,0,1,0,0,1,0,0,1,0]),\n",
        "    'maj7': np.array([1,0,0,0,1,0,0,1,0,0,0,1]),\n",
        "    'min7': np.array([1,0,0,1,0,0,0,1,0,0,1,0]),\n",
        "    'dim': np.array([1,0,0,1,0,0,1,0,0,0,0,0]),\n",
        "    'dim7': np.array([1,0,0,1,0,0,1,0,0,1,0,0]),\n",
        "    'aug': np.array([1,0,0,0,1,0,0,0,1,0,0,0]),\n",
        "    'sus2': np.array([1,0,1,0,0,0,0,1,0,0,0,0]),\n",
        "    'sus4': np.array([1,0,0,0,0,1,0,1,0,0,0,0]),\n",
        "    'maj6': np.array([1,0,0,0,1,0,0,1,0,0,0,1]),\n",
        "    'min6': np.array([1,0,0,1,0,0,0,1,0,0,0,1]),\n",
        "    'maj7b5': np.array([1,0,0,0,1,0,1,0,0,0,0,1]),\n",
        "    '': np.array([1,0,0,0,0,0,0,0,0,0,0,0])\n",
        "}\n",
        "\n",
        "def chord_label_to_chroma(label: str) -> np.ndarray:\n",
        "    if label == 'N':\n",
        "        return np.zeros(12)\n",
        "    parts = label.strip().split()\n",
        "    root_label = parts[0] if parts else ''\n",
        "    quality_str = \" \".join(parts[1:]) if len(parts) > 1 else ''\n",
        "    root_idx = chroma_mapping.get(root_label, -1)\n",
        "    pattern = quality_patterns.get(quality_str.lower(), quality_patterns[''])\n",
        "    return np.roll(pattern, root_idx) if root_idx != -1 else np.zeros(12)\n",
        "\n",
        "# --- Ground Truth Chromagrams ---\n",
        "chord_intervals = np.append(chord_times_seconds, chord_times_seconds[-1] + 10.0)\n",
        "n_frames = int(len(y_full) / hop_length) + 1\n",
        "frame_times = librosa.frames_to_time(np.arange(n_frames), sr=sr, hop_length=hop_length)\n",
        "ground_truth_chroma_framewise = np.zeros((12, n_frames))\n",
        "for i, t in enumerate(frame_times):\n",
        "    idx = np.searchsorted(chord_intervals, t, side='right') - 1\n",
        "    if 0 <= idx < len(chord_types):\n",
        "        ground_truth_chroma_framewise[:, i] = chord_label_to_chroma(chord_types[idx])\n",
        "\n",
        "n_beats = len(beat_times) - 1\n",
        "ground_truth_chroma_beatsync = np.zeros((12, n_beats))\n",
        "for b in range(n_beats):\n",
        "    mid_time = 0.5 * (beat_times[b] + beat_times[b+1])\n",
        "    idx = np.searchsorted(chord_intervals, mid_time, side='right') - 1\n",
        "    if 0 <= idx < len(chord_types):\n",
        "        ground_truth_chroma_beatsync[:, b] = chord_label_to_chroma(chord_types[idx])\n",
        "\n",
        "# Section-Specific (2) Global Chroma\n",
        "sec_row = df_sections.iloc[1]\n",
        "sec_start, sec_end = sec_row['Initial_Time'], sec_row['Initial_Time'] + sec_row['Duration']\n",
        "mask_frames = (frame_times >= sec_start) & (frame_times < sec_end)\n",
        "global_chroma_frames_gt = np.sum(ground_truth_chroma_framewise[:, mask_frames], axis=1) if mask_frames.any() else None\n",
        "beat_times_eff = beat_times[:ground_truth_chroma_beatsync.shape[1]]\n",
        "mask_beats = (beat_times_eff >= sec_start) & (beat_times_eff < sec_end)\n",
        "global_chroma_beats_gt = np.sum(ground_truth_chroma_beatsync[:, mask_beats], axis=1) if mask_beats.any() else None\n",
        "\n",
        "# Global TIV, Tonal Dispersion, Dissonance\n",
        "if ground_truth_chroma_beatsync is not None and ground_truth_chroma_beatsync.size > 0:\n",
        "    ground_truth_tiv_list = []\n",
        "    for i in range(ground_truth_chroma_beatsync.shape[1]):\n",
        "        try:\n",
        "            tiv_vec = tiv.from_pcp(ground_truth_chroma_beatsync[:, i], data_type='symbolic')\n",
        "            ground_truth_tiv_list.append(tiv_vec)\n",
        "        except:\n",
        "            continue\n",
        "    global_chroma_gt = np.sum(ground_truth_chroma_beatsync, axis=1)\n",
        "    try:\n",
        "        global_tiv_gt = tiv.from_pcp(global_chroma_gt)\n",
        "    except:\n",
        "        global_tiv_gt = None\n",
        "\n",
        "    tonal_disp_gt = [\n",
        "        cosine_distance_complex(global_tiv_gt.vector, vec.vector)\n",
        "        for vec in ground_truth_tiv_list\n",
        "    ] if global_tiv_gt else [np.nan] * len(ground_truth_tiv_list)\n",
        "\n",
        "    quality_data_gt = []\n",
        "    for vec, disp in zip(ground_truth_tiv_list, tonal_disp_gt):\n",
        "        quality_data_gt.append({\n",
        "            'Chromaticity_GT': vec.chromaticity(),\n",
        "            'Diatonicity_GT': vec.diatonicity(),\n",
        "            'Dyadicity_GT': vec.dyadicity(),\n",
        "            'Triadicity_GT': vec.triadicity(),\n",
        "            'Dim_Quality_GT': vec.dim_quality(),\n",
        "            'Wholetoneness_GT': vec.wholetoneness(),\n",
        "            'Dissonance_GT': vec.dissonance(),\n",
        "            'Tonal_Dispersion_GT': disp\n",
        "        })\n",
        "\n",
        "    df_qualities_gt = pd.DataFrame(quality_data_gt)\n",
        "    tonal_disp_gt = df_qualities_gt['Tonal_Dispersion_GT'].to_numpy()\n",
        "    dissonance_gt = df_qualities_gt['Dissonance_GT'].to_numpy()\n",
        "\n",
        "# Ground Truth HCF Computation\n",
        "def compute_ground_truth_hcf_from_chroma(chroma, method):\n",
        "    if chroma is None or chroma.size == 0:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    # Convert chroma to TIVs\n",
        "    tiv_list = [tiv.from_pcp(chroma[:, i], data_type='symbolic') for i in range(chroma.shape[1])]\n",
        "    tiv_matrix = np.array([t.vector for t in tiv_list]).T  # shape: (dim, time)\n",
        "\n",
        "    # Compute raw HCF using same method as audio\n",
        "    hcf_raw = hcf_raw_from_tivs(tiv_matrix, method)\n",
        "\n",
        "    return hcf_raw\n",
        "\n",
        "# Beat-synchronous ground truth HCF\n",
        "ground_truth_hcf_beats_raw = compute_ground_truth_hcf_from_chroma(\n",
        "    chroma=ground_truth_chroma_beatsync,\n",
        "    method=hcf_method\n",
        ")\n",
        "\n",
        "# Framewise ground truth HCF\n",
        "ground_truth_hcf_frames = compute_ground_truth_hcf_from_chroma(\n",
        "    chroma=ground_truth_chroma_framewise,\n",
        "    method=hcf_method\n",
        ")"
      ],
      "metadata": {
        "id": "Ta4hkC5OW5lu"
      },
      "id": "Ta4hkC5OW5lu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Plotting HCF (Beat-Synchronized)\n",
        "plot([\n",
        "    ('ground_truth_hcf_beats_raw', True, 0, \"HCF: Ground Truth\"),\n",
        "    ('hcf_raw_beats', True, 0, \"HCF: Audio\")\n",
        "], title=\"Ground Truth vs. Calculated HCF (Beat-Synchronized)\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=None)\n",
        "\n",
        "# Compute Pearson correlation and p-value for beat-synchronized HCF\n",
        "# Ensure both arrays have the same length\n",
        "corr_beats, p_value_beats = pearsonr(ground_truth_hcf_beats_raw, hcf_raw_beats)\n",
        "r_squared_beats = corr_beats**2\n",
        "\n",
        "\n",
        "log_message(f\"Beat-Synchronized HCF:\")\n",
        "log_message(f\"Pearson Correlation Coefficient (R): {corr_beats:.4f}\")\n",
        "log_message(f\"R-squared (R^2): {r_squared_beats:.4f}\")\n",
        "log_message(f\"P-value: {p_value_beats:.4f}\")\n",
        "log_message(\"-\" * 20)\n",
        "\n",
        "print(f\"Beat-Synchronized HCF:\")\n",
        "print(f\"Pearson Correlation Coefficient (R): {corr_beats:.4f}\")\n",
        "print(f\"R-squared (R^2): {r_squared_beats:.4f}\")\n",
        "print(f\"P-value: {p_value_beats:.4f}\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Plotting HCF (Frame-Level)\n",
        "frame_times_hcf = librosa.frames_to_time(np.arange(len(hcf_raw_frames)), sr=sr, hop_length=hop_length)\n",
        "\n",
        "plot([\n",
        "    ('ground_truth_hcf_frames', True, 0, \"HCF: Ground Truth\"),\n",
        "    ('hcf_raw_frames', True, 20, \"HCF: Audio\")\n",
        "], title=\"Ground Truth vs. Calculated HCF (Frame-Level)\", x_axis=frame_times_hcf, df_sections=df_sections, df_phrases=df_phrases, mode=\"time\", plot_index=None)\n",
        "\n",
        "\n",
        "# Compute Pearson correlation and p-value for frame-level HCF\n",
        "corr_frames, p_value_frames = pearsonr(ground_truth_hcf_frames, hcf_raw_frames)\n",
        "r_squared_frames = corr_frames**2\n",
        "\n",
        "log_message(f\"Frame-Level HCF:\")\n",
        "log_message(f\"Pearson Correlation Coefficient (R): {corr_frames:.4f}\")\n",
        "log_message(f\"R-squared (R^2): {r_squared_frames:.4f}\")\n",
        "log_message(f\"P-value: {p_value_frames:.4f}\")\n",
        "log_message(\"-\" * 20)\n",
        "\n",
        "print(f\"Frame-Level HCF:\")\n",
        "print(f\"Pearson Correlation Coefficient (R): {corr_frames:.4f}\")\n",
        "print(f\"R-squared (R^2): {r_squared_frames:.4f}\")\n",
        "print(f\"P-value: {p_value_frames:.4f}\")"
      ],
      "metadata": {
        "id": "zlbzXWsIFbIM"
      },
      "id": "zlbzXWsIFbIM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Ensure chromas have the same length (should be n_beats)\n",
        "min_len_chroma = min(chroma_beats.shape[1], ground_truth_chroma_beatsync.shape[1])\n",
        "chroma_beats_sync = chroma_beats[:, :min_len_chroma]\n",
        "ground_truth_chroma_beatsync_sync = ground_truth_chroma_beatsync[:, :min_len_chroma]\n",
        "\n",
        "# Calculate the difference\n",
        "chroma_difference = chroma_beats_sync - ground_truth_chroma_beatsync_sync\n",
        "chroma_absolute_difference = np.abs(chroma_difference)\n",
        "\n",
        "# Determine the min and max values across all chromas for consistent color scaling\n",
        "# For 'viridis' which is good for magnitudes, we can set vmin to 0\n",
        "vmin = 0\n",
        "vmax = max(chroma_beats_sync.max(), ground_truth_chroma_beatsync_sync.max(), chroma_absolute_difference.max())\n",
        "\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
        "\n",
        "# Plot Calculated Chroma\n",
        "librosa.display.specshow(chroma_beats_sync, sr=sr, hop_length=hop_length, x_axis='time', y_axis='chroma', ax=axes[0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "axes[0].set_title('Calculated Beat-Synchronized Chroma')\n",
        "axes[0].set_ylabel('Pitch Class')\n",
        "axes[0].set_yticks(np.arange(12))\n",
        "axes[0].set_yticklabels(['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'])\n",
        "\n",
        "\n",
        "# Plot Ground Truth Chroma\n",
        "librosa.display.specshow(ground_truth_chroma_beatsync_sync, sr=sr, hop_length=hop_length, x_axis='time', y_axis='chroma', ax=axes[1], cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "axes[1].set_title('Ground Truth Beat-Synchronized Chroma')\n",
        "axes[1].set_ylabel('Pitch Class')\n",
        "axes[1].set_yticks(np.arange(12))\n",
        "axes[1].set_yticklabels(['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'])\n",
        "\n",
        "\n",
        "# Plot Chroma Difference\n",
        "img = librosa.display.specshow(chroma_absolute_difference, sr=sr, hop_length=hop_length, x_axis='time', y_axis='chroma', ax=axes[2], cmap='viridis', vmin=vmin, vmax=vmax)\n",
        "axes[2].set_title('Beat-Synchronized Chroma Absolute Difference (Calculated - Ground Truth)')\n",
        "axes[2].set_ylabel('Pitch Class')\n",
        "axes[2].set_yticks(np.arange(12))\n",
        "axes[2].set_yticklabels(['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'])\n",
        "\n",
        "# Add a colorbar axis and create the colorbar\n",
        "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7]) # [left, bottom, width, height]\n",
        "fig.colorbar(img, cax=cbar_ax, label='Scale')\n",
        "\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 0.9, 1]) # Adjust tight_layout to make space for the colorbar\n",
        "plt.savefig(\"saved_plots/plot_1.pdf\", bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Compute correlation and sum of differences\n",
        "# Flatten the arrays for correlation calculation\n",
        "chroma_beats_flat = chroma_beats_sync.flatten()\n",
        "ground_truth_chroma_beatsync_flat = ground_truth_chroma_beatsync_sync.flatten()\n",
        "\n",
        "# Remove NaNs if any (though unlikely for chromas after processing)\n",
        "mask = np.isfinite(chroma_beats_flat) & np.isfinite(ground_truth_chroma_beatsync_flat)\n",
        "chroma_beats_flat = chroma_beats_flat[mask]\n",
        "ground_truth_chroma_beatsync_flat = ground_truth_chroma_beatsync_flat[mask]\n",
        "\n",
        "\n",
        "correlation_coefficient, p_value = pearsonr(chroma_beats_flat, ground_truth_chroma_beatsync_flat)\n",
        "r_squared = correlation_coefficient**2\n",
        "\n",
        "sum_of_absolute_differences = np.sum(np.abs(chroma_difference))\n",
        "sum_of_squared_differences = np.sum(chroma_difference**2)\n",
        "\n",
        "log_message(f\"Beat-Synchronized Chroma Comparison:\")\n",
        "log_message(f\"Pearson Correlation Coefficient (R): {correlation_coefficient:.4f}\")\n",
        "log_message(f\"R-squared (R^2): {r_squared:.4f}\")\n",
        "log_message(f\"P-value: {p_value:.4f}\")\n",
        "log_message(f\"Sum of Absolute Differences: {sum_of_absolute_differences:.4f}\")\n",
        "log_message(f\"Sum of Squared Differences: {sum_of_squared_differences:.4f}\")\n",
        "log_message(\"-\" * 20)\n",
        "\n",
        "\n",
        "print(f\"Beat-Synchronized Chroma Comparison:\")\n",
        "print(f\"Pearson Correlation Coefficient (R): {correlation_coefficient:.4f}\")\n",
        "print(f\"R-squared (R^2): {r_squared:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Sum of Absolute Differences: {sum_of_absolute_differences:.4f}\")\n",
        "print(f\"Sum of Squared Differences: {sum_of_squared_differences:.4f}\")"
      ],
      "metadata": {
        "id": "TrC4RUNwHJF1"
      },
      "id": "TrC4RUNwHJF1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "JSBzPc0GeD4a",
      "metadata": {
        "id": "JSBzPc0GeD4a"
      },
      "source": [
        "## 2) Sensory Dissonance vs. Tonal Dissonance & Tonal Dispersion (audio vs. ground truth)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ImZfCypqeD4a",
      "metadata": {
        "id": "ImZfCypqeD4a"
      },
      "outputs": [],
      "source": [
        "# Compute STFT once on full audio\n",
        "S = np.abs(librosa.stft(y_full, n_fft=n_fft, hop_length=hop_length, window=window))\n",
        "fft_freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
        "\n",
        "# Compute sensory dissonance curve (frame-level)\n",
        "sens_curve = []\n",
        "for t in range(S.shape[1]):\n",
        "    amps = S[:, t]\n",
        "    if np.all(amps == 0):\n",
        "        sens_curve.append(0.0)\n",
        "        continue\n",
        "    idx = np.argpartition(amps, -N_partials)[-N_partials:] if N_partials < len(amps) else np.arange(len(amps))\n",
        "    f_frame = fft_freqs[idx]\n",
        "    a_frame = amps[idx]\n",
        "    a_frame = a_frame / (np.max(a_frame) + 1e-12)\n",
        "    try:\n",
        "        sens_curve.append(dissonance(f_frame, a_frame, model='sethares1993'))\n",
        "    except Exception:\n",
        "        sens_curve.append(np.nan)\n",
        "\n",
        "sens_curve = np.asarray(sens_curve)\n",
        "frame_t = librosa.frames_to_time(np.arange(S.shape[1]), sr=sr, hop_length=hop_length)\n",
        "\n",
        "# Apply aggregation to sensory dissonance\n",
        "sensory_dissonance_beats_raw = aggregate_to_beats(frame_t, sens_curve, beat_times)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the two dissonance measures\n",
        "plot([\n",
        "    ('sensory_dissonance_beats_raw', True, 1, \"Sensory Dissonance\"),\n",
        "    ('df_qualities[\"Tonal_Dissonance\"]', True, 1, \"Tonal Dissonance\")\n",
        "], title=\"Sensory vs. Tonal Dissonance (Beat-Synchronized)\", x_axis=beat_times, df_sections=df_sections, df_phrases=df_phrases, plot_index=None)\n",
        "\n",
        "# Compute Pearson correlation and p-value\n",
        "correlation_coefficient, p_value = pearsonr(sensory_dissonance_beats_raw, df_qualities[\"Tonal_Dissonance\"])\n",
        "r_squared = correlation_coefficient**2\n",
        "\n",
        "log_message(f\"Sensory Dissonance and Tonal Dissonance:\")\n",
        "log_message(f\"Pearson Correlation Coefficient (R): {correlation_coefficient:.4f}\")\n",
        "log_message(f\"R-squared (R^2): {r_squared:.4f}\")\n",
        "log_message(f\"P-value: {p_value:.4f}\")\n",
        "log_message(\"-\" * 20)\n",
        "\n",
        "print(f\"Pearson Correlation Coefficient (R): {correlation_coefficient:.4f}\")\n",
        "print(f\"R-squared (R^2): {r_squared:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "VI_F0i6F5ovp"
      },
      "id": "VI_F0i6F5ovp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both arrays have the same length\n",
        "min_len_dispersion = min(len(df_qualities['Tonal_Dispersion']), len(df_qualities_gt['Tonal_Dispersion_GT']))\n",
        "tonal_dispersion_audio_sync = df_qualities['Tonal_Dispersion'].values[:min_len_dispersion]\n",
        "tonal_dispersion_gt_sync = df_qualities_gt['Tonal_Dispersion_GT'].values[:min_len_dispersion]\n",
        "\n",
        "# Assign to global variables so plot() can access them via eval()\n",
        "global_tonal_dispersion_audio_sync = tonal_dispersion_audio_sync\n",
        "global_tonal_dispersion_gt_sync = tonal_dispersion_gt_sync\n",
        "\n",
        "\n",
        "# Compute Pearson correlation and p-value\n",
        "correlation_coefficient_dispersion, p_value_dispersion = pearsonr(global_tonal_dispersion_audio_sync, global_tonal_dispersion_gt_sync)\n",
        "r_squared_dispersion = correlation_coefficient_dispersion**2\n",
        "\n",
        "log_message(f\"Tonal Dispersion (Audio vs. Ground Truth):\")\n",
        "log_message(f\"Pearson Correlation Coefficient (R): {correlation_coefficient_dispersion:.4f}\")\n",
        "log_message(f\"R-squared (R^2): {r_squared_dispersion:.4f}\")\n",
        "log_message(f\"P-value: {p_value_dispersion:.4f}\")\n",
        "log_message(\"-\" * 20)\n",
        "\n",
        "print(f\"Tonal Dispersion (Audio vs. Ground Truth):\")\n",
        "print(f\"Pearson Correlation Coefficient (R): {correlation_coefficient_dispersion:.4f}\")\n",
        "print(f\"R-squared (R^2): {r_squared_dispersion:.4f}\")\n",
        "print(f\"P-value: {p_value_dispersion:.4f}\")\n",
        "\n",
        "# Plotting the two tonal dispersion measures\n",
        "# Pass the names of the global variables as strings to plot()\n",
        "plot([\n",
        "    (\"global_tonal_dispersion_audio_sync\", False, 1, \"Tonal Dispersion (Audio)\"),\n",
        "    (\"global_tonal_dispersion_gt_sync\", False, 1, \"Tonal Dispersion (Ground Truth)\")\n",
        "], title=\"Tonal Dispersion (Audio vs. Ground Truth) - Beat-Synchronized\", x_axis=beat_times[:min_len_dispersion], df_sections=df_sections, df_phrases=df_phrases, plot_index=None)"
      ],
      "metadata": {
        "id": "c2sC-7x3AwwS"
      },
      "id": "c2sC-7x3AwwS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Report"
      ],
      "metadata": {
        "id": "poMgLuzn0eRy"
      },
      "id": "poMgLuzn0eRy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define project name and safe filename\n",
        "safe_project_name = PROJECT_NAME.replace('/', '_').replace(' ', '_')\n",
        "out_pdf = f\"{safe_project_name}_Report.pdf\"\n",
        "\n",
        "# Create PDF\n",
        "pdf = fitz.open()\n",
        "\n",
        "# Add title page with project name\n",
        "title_page = pdf.new_page()\n",
        "title_text = f\"Report\\nProject: {PROJECT_NAME}\"\n",
        "title_page.insert_textbox(fitz.Rect(50, 50, 550, 200), title_text, fontsize=20, align=1)\n",
        "\n",
        "# Add log messages (optional)\n",
        "log_file = \"./execution_log.txt\"\n",
        "if os.path.exists(log_file):\n",
        "    with open(log_file, \"r\") as f:\n",
        "        log_text = f.read()\n",
        "    page = pdf.new_page()\n",
        "    page.insert_textbox(fitz.Rect(50, 50, 550, 800), log_text, fontsize=11)\n",
        "\n",
        "# Add plots from directory sequentially\n",
        "plot_dir = \"./saved_plots\"\n",
        "if os.path.exists(plot_dir):\n",
        "    # Get all pdf and png files\n",
        "    plot_files = [f for f in os.listdir(plot_dir) if f.endswith(\".pdf\") or f.endswith(\".png\")]\n",
        "\n",
        "    # Sort files numerically based on the plot index\n",
        "    def sort_key(fname):\n",
        "        match = re.search(r'plot_(\\d+)', fname)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "        return float('inf') # Put files without a clear plot index at the end\n",
        "\n",
        "    plot_files_sorted = sorted(plot_files, key=sort_key)\n",
        "\n",
        "    for i, fname in enumerate(plot_files_sorted):\n",
        "        fpath = os.path.join(plot_dir, fname)\n",
        "        if fname.endswith(\".pdf\"):\n",
        "            try:\n",
        "                plot_pdf = fitz.open(fpath)\n",
        "                pdf.insert_pdf(plot_pdf)\n",
        "                plot_pdf.close() # Close the opened PDF to free resources\n",
        "            except Exception as e:\n",
        "                 print(f\"Error processing PDF plot {fname}: {e}\")\n",
        "        elif fname.endswith(\".png\"):\n",
        "            try:\n",
        "                img = fitz.open(fpath)\n",
        "                rect = img[0].rect\n",
        "                page = pdf.new_page(width=rect.width, height=rect.height)\n",
        "                page.insert_image(rect, filename=fpath)\n",
        "                img.close() # Close the opened image to free resources\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing PNG plot {fname}: {e}\")\n",
        "\n",
        "\n",
        "# Save combined PDF\n",
        "pdf.save(out_pdf)\n",
        "print(f\"Combined report saved to {out_pdf}\")\n",
        "\n",
        "# Offer to download the file\n",
        "try:\n",
        "    files.download(out_pdf)\n",
        "except Exception as e:\n",
        "    print(f\"Could not initiate download: {e}\")\n",
        "    print(f\"You can manually download the file '{out_pdf}' from the file browser.\")"
      ],
      "metadata": {
        "id": "BQDj-zdFhUMP"
      },
      "id": "BQDj-zdFhUMP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yK94WsD0eD4V",
        "b67-8kLgeD4X",
        "8i5U07ZGeD4Y",
        "gw7BiuTseD4Y",
        "tJnjjkeHeD4Z",
        "pyl-8DnDeD4a",
        "GpTXdFwFeD4Z",
        "cexeM9GleD4a",
        "hf1kvdZ1eD4a",
        "aBBAI_hSsfv_",
        "SM8-M5UFtNNW",
        "8gfMg9yqntKL",
        "NUJ3ixbYBpjZ",
        "e5YHdjT1W9de",
        "L5_QX6NKbakD",
        "JSBzPc0GeD4a",
        "poMgLuzn0eRy"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
